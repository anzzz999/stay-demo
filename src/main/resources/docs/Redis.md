## Redis



优点：读写性能优异，支持持久化，支持事务（redisconntion、lua），数据结构丰富，支持主从/集群

缺点：容量受限，灾备恢复较差



项目用上： 存储字典、单号递增、@Cacheable存储数据、存储token、分布式锁

String:单号递增、token、分布式锁、@Cacheable

SET：判断这个人有没有出过团

HASH:存取字典key、value

Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求

| 数据类型 | 可以存储的值           | 操作                                                         |
| -------- | ---------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 |
| LIST     | 列表                   | 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 |
| SET      | 无序集合               | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 |
| ZSET     | 有序集合               | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 |



Redis 提供了RDB和AOF两种持久化方式。默认是只开启RDB，当Redis重启时，它会优先使用AOF文件来还原数据集。

**RDB持久化（快照持久化）**

RDB持久化：将某个节点的所有数据都保存在硬盘上。

创建快照的几种方式：

1.save命令:快照创建完毕之前不会再响应任何其他命令。

2.bgsave命令:开辟子进程去处理，主线程去处理命令请求

3.主从复制

4.shutdown：执行一个SAVE命令，阻塞所有客户端，不再执行客户端发送的任何命令，并在SAVE命令执行完毕之后关闭服务器

**如果系统真的发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于即使丢失一部分数据也不会造成一些大问题的应用程序。不能接受这个缺点的话，可以考虑AOF持久化。**

**AOF持久化**

AOF持久化：将写命令添加到AOF文件的末尾

与快照持久化相比，**AOF持久化的实时性更好**，因此已成为主流的持久化方案。

在Redis的配置文件中存在三种同步方式

|   选项   |                  同步频率                   |
| :------: | :-----------------------------------------: |
|  always  | 每个写命令都同步，这样会严重降低Redis的速度 |
| everysec |                每秒同步一次                 |
|    no    |          让操作系统来决定何时同步           |

重写/压缩AOF
AOF虽然在某个角度可以将数据丢失降低到最小而且对性能影响也很小，但是极端的情况下，体积不断增大的AOF文件很可能会用完硬盘空间。另外，如果AOF体积过大，那么还原操作执行时间就可能会非常长。

为了解决AOF体积过大的问题，**用户可以向Redis发送 BGREWRITEAOF命令 ，这个命令会通过移除AOF文件中的冗余命令来重写（rewrite）AOF文件来减小AOF文件的体积**。

Redis 4.0 对持久化机制的优化
Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性较差。



#### 缓存雪崩

缓存雪崩：指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。

**解决方案**

1. **过期时间打散。**缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. **加互斥锁**。一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
3. **热点数据不过期**。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。



关于互斥锁的选择，网上看到的大部分文章都是选择 Redis 分布式锁，因为这个可以保证只有一个请求会走到数据库，这是一种思路。

但是其实仔细想想的话，这边其实没有必要保证只有一个请求走到数据库，只要保证走到数据库的请求能大大降低即可，所以还有另一个思路是 JVM 锁。

JVM 锁保证了在单台服务器上只有一个请求走到数据库，通常来说已经足够保证数据库的压力大大降低，同时在性能上比分布式锁更好。

需要注意的是，无论是使用“分布式锁”，还是“JVM 锁”，加锁时要按 key 维度去加锁。

我看网上很多文章都是使用一个“固定的 key”加锁，这样会导致不同的 key 之间也会互相阻塞，造成性能严重损耗。






#### 缓存穿透

缓存穿透：指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

**解决方案**

1. **接口层增加校验**。如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. **缓存空值**。从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
3. **布隆过滤器**。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库。



**布隆过滤器的特点是判断不存在的，则一定不存在；判断存在的，大概率存在，但也有小概率不存在。**并且这个概率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。

布隆过滤器由一个 bitSet 和 一组 Hash 函数（算法）组成，是一种空间效率极高的概率型算法和数据结构，主要用来判断一个元素是否在集合中存在。



#### 缓存击穿

缓存击穿：指缓存中没有但数据库中有的数据（一般是缓存时间到期）。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

**解决方案**

1. 设置热点数据永远不过期。
2. 加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。



#### redis过期键淘汰策略

1.立即删除  

2.定时删除

3.惰性删除



**立即删除对cpu是最不友好的**。因为删除操作会占用cpu的时间，如果刚好碰上了cpu很忙的时候，比如正在做交集或排序等计算的时候，就会给cpu造成额外的压力。

惰性删除的缺点很明显:**浪费内存**。

定时删除是一个折中的办法，每隔一段时间执行一次删除操作。

redis使用的过期键值删除策略是：**惰性删除加上定期删除，两者配合使用**。



主从情况下：
从库发现过期直接返回空。当主库定期删除或惰性删除时，同步到从库，从库数据才真正删除。

原因： 避免主从同步出现混乱



#### redis数据淘汰策略

|     策略     |                         描述                         |                           应用场景                           |
| :----------: | :--------------------------------------------------: | :----------------------------------------------------------: |
| volatile-lru | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 | 如果设置了过期时间，且分热数据与冷数据，推荐使用 volatile-lru 策略。 |
| volatile-ttl |   从已设置过期时间的数据集中挑选将要过期的数据淘汰   | 如果让 Redis 根据 TTL 来筛选需要删除的key，请使用 volatile-ttl 策略。 |
| allkeys-lru  |       从所有数据集中挑选最近最少使用的数据淘汰       | 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 |

##### 淘汰策略的内部实现

- 客户端执行一个命令，导致 Redis 中的数据增加，占用更多内存
- Redis 检查内存使用量，如果超出 maxmemory 限制，根据策略清除部分 key
- 继续执行下一条命令，以此类推



#### 事务

**Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务(transaction)功能。**事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，可以减少客户端与服务器之间的网络通信次数从而提升性能。



#### 声明式缓存(注解)

##### Spring

https://www.cnblogs.com/coding-one/p/12402543.html)

spring 缓存抽象提供了以下一些注解来实现**声明式缓存**：

（通过拦截器Interceptor 和SpringAOP实现的）

| @Cacheable   | 触发缓存填充                       |
| ------------ | ---------------------------------- |
| @CacheEvict  | 触发缓存清除                       |
| @CachePut    | 在不影响方法执行的情况下更新缓存   |
| @Caching     | 重新组合应用于同一个方法的多个缓存 |
| @CacheConfig | 在类级别共享一些缓存相关的公共设置 |



**@Cacheable 缓存数据**

@Cacheable 提供两个参数来指定缓存名：value、cacheNames，二者选其一即可。

@Cacheable 支持同一个方法关联多个缓存。这种情况下，当执行方法之前，这些关联的每一个缓存都会被检查，而且只要至少其中一个缓存命中了，那么这个缓存中的值就会被返回。示例：

```java
@Cacheable({"menu", "menuById"})
```

当我们在声明 @Cacheable 时不指定 key 参数，则该缓存名下的所有 key 会使用 KeyGenerator 根据参数 自动生成。spring 有一个默认的 SimpleKeyGenerator ，在 spring boot 自动化配置中，这个会被默认注入。

相较于使用 KeyGenerator 生成，spring 官方更推荐显式指定 key 的方式，即指定 @Cacheable 的 key 参数。 

**key 和 keyGenerator 参数是互斥的，同时指定两个会导致异常**。

 **sync**是否同步，true/false。在一个多线程的环境中，某些操作可能被相同的参数并发地调用，这样同一个 value 值可能被多次计算（或多次访问 db），这样就达不到缓存的目的。

**condition**调用前判断，缓存的条件。

**unless**执行后判断，不缓存的条件。

示例：

```java
@Cacheable(cacheNames = {"testableCache"}, key = "'id-' + #id",  condition = "true", unless = "#result.data == null" )
```

redis存储的名称: testableCache::id-“id”

![image-20210308153206615](Redis.assets/image-20210308153206615.png)



**@CachePut** **更新缓存数据**

**@CacheEvict  删除缓存数据**



##### Jetcache

阿里巴巴开源的通用缓存访问框架JetCache，GitHub：https://github.com/alibaba/jetcache

JetCache是一个基于Java的缓存系统封装，提供统一的API和注解来简化缓存的使用。 JetCache提供了比SpringCache更加强大的注解，Spring Cache在对具体key缓存失效时间的设置不是很友好。 JetCache可以原生的支持TTL、两级缓存、分布式自动刷新，还提供了`Cache`接口用于手工缓存操作。





### 布隆过滤器

#### （不存在的一定不存在，存在的可能存在）



什么是布隆过滤器？

我们可以把它看作由**二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。**相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。



给你一个数据，如何判断给你的数据在不在其中。如果服务器的内存足够大，那么用HashMap是一个不错的解决方案，理论上的时间复杂度可以达到O(1)，但是现在数据的大小已经远远超出了服务器的内存，所以无法使用HashMap，这个时候就可以使用“布隆过滤器”来解决这个问题。但是还是同样的，会有一定的“误判率”。

仅从布隆过滤器本身而言，根本没有存放完整的数据，只是运用一系列随机映射函数计算出位置，然后填充二进制向量。

布隆过滤器的优缺点：

- 优点：**由于存放的不是完整的数据，所以占用的内存很少，而且新增，查询速度够快；**
- 缺点： **随着数据的增加，误判率随之增加；无法做到删除数据；只能判断数据是否一定不存在，而无法判断数据是否一定存在。**

使用guava实现布隆过滤器是把数据放在本地内存中，无法实现布隆过滤器的共享（共享方便集群进行判断），我们还可以把数据放在redis中，用 redis来实现布隆过滤器，我们要使用的数据结构是bitmap，你可能会有疑问，redis支持五种数据结构：String，List，Hash，Set，ZSet，没有bitmap呀。没错，实际上bitmap的本质还是String。





### 1、Redis 是单线程还是多线程？

redis 4.0 之前，redis 是***\*完全单线程的\****。

redis 4.0 时，redis 引入了多线程，但是**额外的线程只是用于后台处理**

redis 6.0 中，**多线程主要用于网络 I/O 阶段**，也就是接收命令和写回结果阶段，而在执行命令阶段，还是由单线程串行执行。由于执行时还是串行，因此无需考虑并发安全问题。



### 2、为什么 Redis 是单线程？

因为 redis 是完全基于内存操作的，通常情况下CPU不会是redis的瓶颈，**redis 的瓶颈最有可能是机器内存的大小或者网络带宽**。

既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为**如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗**。


### 3、Redis 为什么使用单进程、单线程也很快

主要有以下几点：

1、基于内存的操作

2、使用了 I/O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器

3、单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。

4、以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字符串、压缩列表等

### 4、Sorted Set 为什么使用跳跃表，而不是红黑树？

主要有以下几个原因：

1）跳表的性能和红黑树差不多。

2）跳表更容易实现和调试。



### 5、为什么是让缓存失效，而不是更新缓存

案例如下，有两个并发的写请求，流程如下：

![img](https://img-blog.csdnimg.cn/img_convert/93d63e4ac2c2a20e76d6a1a0b6d9b338.png)

分析：由于是删除缓存，所以不存在数据不一致的情况。



### 6、如何保证数据库和缓存的数据一致性

在上文的案例中，无论是先操作数据库，还是先操作缓存，都会存在脏数据的情况，有办法避免吗？

答案是有的，由于数据库和缓存是两个不同的数据源，要保证其数据一致性，其实就是**典型的分布式事务场景，可以引入分布式事务来解决，常见的有：2PC、TCC、MQ事务消息等。**

但是**引入分布式事务必然会带来性能上的影响，这与我们当初引入缓存来提升性能的目的是相违背的**。

所以**在实际使用中，通常不会去保证缓存和数据库的强一致性，而是做出一定的牺牲，保证两者数据的最终一致性。**

**如果是实在无法接受脏数据的场景，则比较合理的方式是放弃使用缓存，直接走数据库。**

保证数据库和缓存数据最终一致性的常用方案如下：

1）更新数据库，数据库产生 binlog。

2）监听和消费 binlog，执行失效缓存操作。

3）如果步骤2失效缓存失败，则引入重试机制，将失败的数据通过MQ方式进行重试，同时考虑是否需要引入幂等机制。

![img](https://img-blog.csdnimg.cn/img_convert/bb890384f07c5006146f0b369489c4f2.png)

兜底：当出现未知的问题时，及时告警通知，人为介入处理。









### 7、**redis延时双删**（数据库和缓存双写一致性方案）

https://www.it610.com/article/1306087917600411648.htm



（1）先淘汰缓存；

（2）再写数据库（这两步和原来一样）；

（3）休眠1秒，再次淘汰缓存；

这么做，可以将1秒内所造成的缓存脏数据，再次删除！



双删是为了**确保缓存和数据库的数据一致性**

延时是确保 **修改数据库 -> 清空缓存前，其他事务的更改缓存操作已经执行完。**



解决第一个问题：在线程 A 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。 

解决第二个问题：线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。 

这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。

但问题来了，这个「延迟删除」缓存，延迟时间到底设置要多久呢？

 问题1：**延迟时间要大于「主从复制」的延迟时间** 

 问题2：**延迟时间要大于线程 B 读取数据库 + 写入缓存的时间** 

但是，这个时间在分布式和高并发场景下，其实是很难评估的。 很多时候，我们都是凭借经验大致估算这个延迟时间，例如延迟 1-5s，**只能尽可能地降低不一致的概率。** 所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。 **所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。**



在这里我也分享 4 点心得给你： 

1、性能和一致性不能同时满足，为了性能考虑，通常会采用「最终一致性」的方案 

2、掌握缓存和数据库一致性问题，核心问题有 3 点：缓存利用率、并发、缓存 + 数据库一起成功问题 

3、失败场景下要保证一致性，常见手段就是「重试」，同步重试会影响吞吐量，所以通常会采用异步重试的方案 

4、订阅变更日志的思想，本质是把权威数据源（例如 MySQL）当做 leader 副本，让其它异质系统（例如 Redis / Elasticsearch）成为它的 follower 副 本，通过同步变更日志的方式，保证 leader 和 follower 之间保持一致



![redis缓存为什么要延时双删_第4张图片](https://img.it610.com/image/info8/41cae99b178248a1b6d1d8948d7b2d65.jpg)









#### 字符串 string

Redis 中的字符串是一种 **动态字符串**，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 ArrayList，有一个字符数组，从源码的 sds.h/sdshdr 文件 中可以看到 Redis 底层对于字符串的定义 SDS，即 Simple Dynamic String 结构。

#### 列表 list

Redis 的列表相当于 Java 语言中的 **LinkedList**，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。

#### 字典 hash

Redis 中的字典相当于 Java 中的 **HashMap**，内部实现也差不多类似，都是通过 **"数组 + 链表"** 的链地址法来解决部分 **哈希冲突**，同时这样的结构也吸收了两种不同数据结构的优点。

#### 集合 set

Redis 的集合相当于 Java 语言中的 **HashSet**，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

#### 有序列表 zset

这可能使 Redis 最具特色的一个数据结构了，它类似于 Java 中 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以为每个 value 赋予一个 score 值，用来代表排序的权重。

它的内部实现用的是一种叫做 「**跳跃表**」 的数据结构。





### redis模式

#### 一. 主从

通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了**避免单点故障**，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。

（优点）**读写分离：**

对于读占比较高的场景，可以通过把一部分流量分摊导出从节点(salve) 来减轻主节点（master）压力，同时需要主要只对主节点执行写操作，如下图：

（缺点）当使用从节点响应读请求时，业务端可能会遇到以下问题：

**复制数据延迟**
**读到过期数据**
**从节点故障**



```
主从数据库的配置
master  slave
主不用配置，从redis的conf文件加入 slaveof ip port 就可以了
或者从redis启动时  redis-server --port 6380 --slaveof 127.0.0.1 6379
    从数据库一般是只读，可以改为可写，但写入的数据很容易被主同步没，所以还是只读就可以。
也可以在运行是使用slaveof ip port命令，停止原来的主，切换成刚刚设置的主  slaveof no one会把自己变成主

复制原理
当从数据库启动时，会向主数据库发送sync命令，主数据库接收到sync后开始在后台报错快照rdb，在保存快照期间受到的命名缓存起来，当快照完成时，主数据库会将快照和缓存的命令一块发送给从。复制初始化结束。
之后，主每受到1个命令就同步发送给从。
当出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库。增量复制

主从复制是乐观复制，当客户端发送写执行给主，主执行完立即将结果返回客户端，并异步的把命令发送给从，从而不影响性能。也可以设置至少同步给多少个从主才可写。
无硬盘复制:如果硬盘效率低将会影响复制性能，2.8之后可以设置无硬盘复制，repl-diskless-sync yes
```



#### 二. 哨兵(sentinel)

当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然而整个过程相对麻烦且需要人工介入，难以实现自动化。 为此，Redis 2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。
**哨兵的作用就是监控redis主、从数据库是否正常运行，主出现故障自动将从数据库转换为主数据库。**

顾名思义，哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个。

    （1）监控主数据库和从数据库是否正常运行。
    （2）主数据库出现故障时自动将从数据库转换为主数据库。

![img](https://img-blog.csdn.net/20160909152623127)

可以用**info replication查看主从情况**

```
例子：
1主2从  1哨兵,可以用命令起也可以用配置文件里
可以使用双哨兵，更安全，
redis-server --port 6379
redis-server --port 6380 --slaveof 192.168.0.167 6379
redis-server --port 6381 --slaveof 192.168.0.167 6379


redis-sentinel sentinel.conf
哨兵配置文件
    sentinel.conf
        sentinel monitor mymaster 192.168.0.167 6379 1 

其中mymaster表示要监控的主数据库的名字，可以自己定义一个。这个名字必须仅由大小写字母、数字和“.-_”这 3 个字符组成。后两个参数表示主数据库的地址和端口号，这里我们要监控的是主数据库6379。
注意:

    1、使用时不能用127.0.0.1，需要用真实IP，不然java程序通过哨兵会连到java程序所在的机器(127.0.0.1 )
    
    2、配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自动发现所有复制该主数据库的从数据库

这样哨兵就能监控主6379和从6380、6381，一旦6379挂掉，哨兵就会在2个从中选择一个作为主，根据优先级选，如果一样就选个id小的，当6379再起来就作为从存在。
主从切换过程：

（1）      slave leader升级为master
（2）      其他slave修改为新master的slave
（3）      客户端修改连接
（4）      老的master如果重启成功，变为新master的slave


哨兵监控1主2从，停掉主，哨兵会选出1个从作为主，变成1主1从。然而当我把原来的主再起来，它不会作为从，只是个独立的节点。

如果在新的主刚被选出来时，我把原来的主起来，它就能成为新主的从节点。
如果在新的主选出来过一会再起原来的主，就不能成为新主的从节点
或者在老的主起来后，重启哨兵也能把它变成从，哨兵配置文件里有，哨兵会执行“+convert-to-slave”

```



#### 三. 集群(**redis cluster**)

即使使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用集群，就是分布式存储。即每台redis存储不同的内容，
共有16384个slot（2的14次方个）。每个redis分得一些slot，hash_slot = crc16(key) mod 16384 找到对应slot，键是可用键，如果有{}则取{}内的作为可用键，否则整个键是可用键
**集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选**。

修改每个实例的配置文件：

    cluster-enabled yes  --开启集群
    
    cluster-config-file nodes-6382.conf --集群配置文件名，每个实例配置的要不同，redis会根据文件名自动新建

**用集群工具创建集群**

```
集群过程：
首先redis-trib.rb会以客户端的形式尝试连接所有的节点，并发送PING命令以确定节点能够正常服务。如果有任何节点无法连接，则创建失败。同时发送 INFO 命令获取每个节点的运行ID以及是否开启了集群功能（即cluster_enabled为1）。 准备就绪后集群会向每个节点发送 CLUSTER MEET命令，格式为 CLUSTER MEET ip port，这个命令用来告诉当前节点指定ip和port上在运行的节点也是集群的一部分，从而使得6个节点最终可以归入一个集群。

然后redis-trib.rb会分配主从数据库节点，分配的原则是尽量保证每个主数据库运行在不同的IP地址上，同时每个从数据库和主数据库均不运行在同一IP地址上，以保证系统的容灾能力

3主3从，当1个主故障，大家会给对应的从投票，把从立为主，若没有从数据库可以恢复则redis集群就down了。

客户端连接：
使用redis-cli -c -p 任意一个端口
```

##### redis cluster 架构

　　**1)redis-cluster架构图**

![img](https://images2015.cnblogs.com/blog/17405/201607/17405-20160729120110388-883077606.jpg)

　　架构细节:

　　(1)所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.

　　(2)节点的fail是通过集群中超过半数的节点检测失效时才生效.

　　(3)客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可

　　(4)redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node<->slot<->value

 

  **2) redis-cluster选举:容错**

![img](https://images2015.cnblogs.com/blog/17405/201607/17405-20160729120154169-1347608301.jpg)

　　(1)领着选举过程是集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉.

　　(2):什么时候整个集群不可用(cluster_state:fail),当集群不可用时,所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误

  　　a:如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成进群的slot映射[0-16383]不完成时进入fail状态.

  　　b:如果进群超过半数以上master挂掉，无论是否有slave集群进入fail状态.





### Redisson

Redis分布式锁原理（二）——Redisson分布式锁源码浅析https://blog.csdn.net/h2503652646/article/details/119514951

在调用redisson的lock()方法时，我们可以传入自定义的超时时间，也可以不传，**如果不传那么将会使用Redisson默认的看门狗时间30s，需要注意的是，如果我们使用了自定义超时时间，那么Redisson不会自动为我们的锁续期，而不传时间Redisson会使用默认30s超时时间并且会自动为我们的锁进行续期。**而一般在开发中，**最佳实践其实推荐的是传入超时时间，因为这样省去了创建定时任务不断续时的过程，可能会有小伙伴会问那如果业务时间大于了超时时间怎么办，其实只需要把超时时间设的大一点就可以了，比如就30s，如果超过30s业务还没完成就该想想怎么优化业务逻辑了**。



#### 看门狗机制（watch dog）

 [redisson中的看门狗机制总结](https://www.cnblogs.com/jelly12345/p/14699492.html)

- watch dog 在当前节点存活时每10s给分布式锁的key续期 30s；
- watch dog 机制启动，且代码中没有释放锁操作时，watch dog 会不断的给锁续期；
- 如果程序释放锁操作时因为异常没有被执行，那么锁无法被释放，所以释放锁操作一定要放到 finally {} 中；
- 要使 watchLog机制生效 ，lock时 不要设置 过期时间
- watchlog的延时时间 可以由 lockWatchdogTimeout指定默认延时时间，但是不要设置太小。如100
- watchdog 会每 lockWatchdogTimeout/3时间，去延时。
- watchdog 通过 类似netty的 Future功能来实现异步延时
- watchdog 最终还是通过 lua脚本来进行延时



### BigKey

#### 拒绝bigkey

在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey。

##### 1.字符串类型：

它的big体现在单个value值很大，**一般认为超过10KB就是bigkey**。

##### 2.集合类型:(hash,list,set,zset等)

哈希、列表、集合、有序集合，它们的big体现在元素个数太多。
一般来说hash、list、set、zset元素**个数不要超过5000**。
反例：一个包含200万个元素的list。

#### 优化bigkey

**1.一个字拆,大拆小**

**2.避开危险操作**

如果必须使用bigkey的话,那操作的时候避开hgetall、lrange、smembers、zrange、sinter等全数据查询的命令,有遍历的需求可以使用hscan、sscan、zscan代替(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。

**3.合理使用数据类型(推荐)**

实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)

**4.控制key的生命周期，redis不是垃圾桶(推荐)**

建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。

### 杂记

redis执行批量命令

1.RedisTemplate使用*PipeLine*管道命令

**减少请求次数，将多条请求命令合成一次请求通过管道发给redis server，再通过回调函数一次性接收多个命令的结果，减少网络IO次数**，在高并发情况下可带来明显性能提升。注意的是，redis server是单线程，**多个命令合成一次请求到达redis server依然还是顺序一个个执行的，仅仅只是减少了请求IO次数**。

```java
// 1.executePipelined 重写 入参 RedisCallback 的doInRedis方法
		List<Object> resultList = redis.executePipelined(new RedisCallback<Object>() {
 
			@Override
			public String doInRedis(RedisConnection connection) throws DataAccessException {
				// 2.connection 打开管道
				connection.openPipeline();
				// 3.connection 给本次管道内添加 要一次性执行的多条命令
            	for (int i = 0; i < 20; i++) {
                	connection.zIncrBy("im.test".getBytes(), 1.0, "prod_0_1410063315498532866".getBytes());
                	connection.zIncrBy("im.test".getBytes(), 1.0, "prod_0_1410063313262968834".getBytes());
                	connection.zIncrBy("im.test".getBytes(), 1.0, "prod_0_1440314158867456002".getBytes());
            	}
				// 4.关闭管道 不需要close 否则拿不到返回值
				// connection.closePipeline();
				// 这里一定要返回null，最终pipeline的执行结果，才会返回给最外层
             	 // 返回null即可，因为返回值会被管道的返回值覆盖，外层取不到这里的返回值
				return null;
			}
		});
```



选择数据库

select index  

select 8 



String

set key value
setnx key  value  key不存在才可用 相当于add操作
set key value xx  key存在 相当于update操作

批量操作
mget  k1 k2 k3
mset  k1 v1 k2 v2 k3 v3

getset key newvalue  设置新值返回旧值
append key value  追加值
strlen key 返回字符串的长度（注意中文）

incrbyfloat key 3.5 增加key对应的值3.5

getrange key start end 获取字符串指定下标所有的值

setrange key index value 设置指定下标的对应的值

Hash 
哈希命令都以h开头
hget key field  
hset key field value
hdel key field 
hgetall key 获取所有
 hexists key field   判断hash key 是否有field  复杂度o(1)
 hlen key 获取key的filed数量 复杂度o(1)
 批量  o(n)
 hmset key field value field value
 hmget key field field

 list(列表) 有序 可重复 左右两边弹入弹出
 增 
 lpush/rpush key value1 value2 value3..
 linsert key before|after value newvalue 在list指定的值前后插入newvalue
 删
 lpop/rpop key 
 lrem key count value 
 （count>0 从左到右 删除 count个 value  count<0 从右到左 count=0 全删）
 ltrim key start end 按索引范围修剪列表 
查 
 lrange key start end(包含end) 获取列表指定索引范围所有item
 lindex key index
 llen key 获取列表的长度
 改
 lset key index newvalue  设置列表指定索引值为 newvalue

 LRUSH + LPOP =Stack
 LRUSH + RPOP = Queue
 LPUSH + LTRIM = Capped Collection 控制列表大小
 LPUSH + BRPOP =Message Queue

 SET(集合，特点：无序，无重复，集合间操作)
 sadd  key element1 element2 增加 
 srem  key element1 删除
 scard key  计算几个大小
 sismember key value 判断it是否在集合中
 srandmember key count  从集合中随机挑count个元素（不会破坏集合数据）
 spop key  从集合中随机弹出一个元素
 smembers key 返回集合中的所有元素（无序，小心使用）

集合间
sdiff key1 key2 差集
sinter  key1 key2 交集
sunion key1 key2 并集

+ store destkey  将结果保存在 destkey 中
  tips
  SADD 标签
  spop/srandmember 随机数应用
  sadd + sinter 社交相关应用 共同关注的人

zset（有序集合）
key score value
user  1   an_zzz
zadd key score element (可以多对) 增加 o(n)
zrem key element(可以多个) 删除 o(1)
zscore key element 返回元素的分数 (可以多对)
zincrby key increScore element  增加或减少元素分数 o(1)
zcard key 返回元素个数
zrank 获取排名 从小到大，从0开始
zrange key start end [WITHSCORES] 返回指定索引范围内的升序元素[分值]o(long(n)+m)
zrangebyscore key minScore maxScore [WITHSCORES]  返回指定分数范围内的升序元素[分值]
zcount key minScore maxScore 返回指定分数范围内的元素个数
zremrangebyrank key start end 删除指定排名内的升序元素
zremrangebyscore key minScore maxScore 删除指定分数内的升序元素


慢查询参数
首先来关注下慢日志分析对应的两个参数：

1、slowlog-log-slower-than：预设阀值，即记录超过多少时间的记录，默认为10000微秒，即10毫秒。可设置为1000

2、slowlog-max-len：记录慢查询的条数，默认为128条，当超过设置的条数时最早进入队列的将被移除。线上建议增大数值，如：1000，这样可减少队列移除的频率。

config set 设置 

持久化方式
快照 ==》 MySQL dump ,redis RDB
写日志 ==》 MySQL binlog , redis AOF

RDB   
  save(同步)   文件策略：存在老的RDB文件，新替换老 复杂度：O(n)        阻塞？：是（阻塞客户端命令）
  bgsave(异步) 文件策略：与save相同                复杂度：与save相同  阻塞？：是（阻塞发生在fork,fork消耗内存）
  自动生成RDB （自动配置满足任一条件就会执行）
  触发机制：主从复制 shutdown
   RDB   缺点：耗时、耗性能  不可控、丢失数据

AOF
  always             不丢失数据    				IO开销大
  everysec（每秒）	 每秒一次fsync，保护磁盘	丢一秒数据
  no （OS决定fsync）  不用管					不可控

主从复制
指令        无需重启，但不便于管理
slaveof ip:端口
slaveof no one
配置文件   统一配置，需要重启
slaveof ip port
slaveof-read-only yes  只读

规避全量复制
1.第一次全量复制
2.节点运行ID不匹配
3.复制缓冲区不足 网络中断等。。

规避复制风暴

sentinel

三个定时任务
1.每10秒info 
 发现slave节点  确认主从关系
2.每2秒发布订阅 
 每2秒每个sentinel通过master节点的channel交换信息（pub/sub）
3.心态检测
 每1秒每个sentinel对其他sentinel和redis执行ping

 主观下线：每个sentinel节点对redis节点失败的“偏见”
 客观下线：所有sentinel节点对redis节点失败“达成共识”（超过quorum个统一）

 数据分布概念 
  1.节点取余分区
  2.一致性哈希分区
  3.虚拟槽哈希分布

  redis集群

  准备节点 --> meet操作 --> 分配槽 --> 配置主从

  集群伸缩 = 槽和数据在节点之间的移动

  加入集群的作用
  1.为他迁移槽和数据实现扩容
  2.作为从节点负责故障转移

  收缩集群
  1.下线迁移槽
  2.忘记节点
  3.关闭节点

  客户端路由
  moved 和 ask
  两者都是客户端重定向
  moved:槽已经确定迁移
  ask:槽还在迁移中

  数据倾斜
  1.节点和槽分配不均匀
  2.不同槽对应键值数差异较大
  3.包含bigkey
  4.内存相关配置不一致





### 01 redis基本架构：一个键值数据库包含什么？

#### 可以存哪些数据？

不同键值数据库支持的key类型一般差异不大，而value类型则有较大差别。我们在对键值数据库进行选型时，一个重要的考虑因素是它支持的value类型。例如**，Memcached支持的value类型仅为String类型，而Redis支持的value类型包括了String、哈希表、列表、集合等。**Redis能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的value。

大体来说，一个键值数据库包括了**访问框架、索引模块、操作模块和存储模块**四部分

<img src="https://img-blog.csdnimg.cn/1b8cb7478445410b8ea627adf4839c75.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5aO55bCP5L-K,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />



#### 采用什么访问模式？

访问模式通常有两种：一种是通过函数库调用的方式供外部应用使用，比如，上图中的libsimplekv.so，就是以动态链接库的形式链接到我们自己的程序中，提供键值存储功能；另一种是通过网络框架以Socket通信的形式对外提供键值对操作，这种形式可以提供广泛的键值存储服务。在上图中，我们可以看到，网络框架中包括Socket Server和协议解析。

不同的键值数据库服务器和客户端交互的协议并不相同，我们在对键值数据库进行二次开发、新增功能时，必须要了解和掌握键值数据库的通信协议，这样才能开发出兼容的客户端。

实际的键值数据库也基本采用上述两种方式，例如，**RocksDB以动态链接库的形式使用，而Memcached和Redis则是通过网络框架访问。**

#### 如何定位键值对的位置？

当SimpleKV解析了客户端发来的请求，知道了要进行的键值对操作，此时，SimpleKV需要查找所要操作的键值对是否存在，这依赖于键值数据库的索引模块。索引的作用是让键值数据库根据key找到相应value的存储位置，进而执行操作。

索引的类型有很多，常见的有哈希表、B+树、字典树等。不同的索引结构在性能、空间消耗、并发控制等方面具有不同的特征。如果你看过其他键值数据库，就会发现，不同键值数据库采用的索引并不相同，例如，**Memcached和Redis采用哈希表作为key-value索引，而RocksDB则采用跳表作为内存中key-value的索引。**

**一般而言，内存键值数据库（例如Redis）采用哈希表作为索引，很大一部分原因在于，其键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表O(1)的操作复杂度相匹配。**

SimpleKV的索引根据key找到value的存储位置即可。但是，和SimpleKV不同，**对于Redis而言，很有意思的一点是，它的value支持多种类型，当我们通过索引找到一个key所对应的value后，仍然需要从value的复杂结构（例如集合和列表）中进一步找到我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。**

#### 不同操作的具体逻辑是怎样的？

SimpleKV的**索引模块负责根据key找到相应的value的存储位置。**对于不同的操作来说，找到存储位置之后，需要进一步执行的操作的具体逻辑会有所差异。SimpleKV的操作模块就实现了不同操作的具体逻辑：

对于GET/SCAN操作而言，此时根据value的存储位置返回value值即可；
对于PUT一个新的键值对数据而言，SimpleKV需要为该键值对分配内存空间；
对于DELETE操作，SimpleKV需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。
不知道你注意到没有，对于PUT和DELETE两种操作来说，除了新写入和删除键值对，还需要分配和释放内存。这就不得不提SimpleKV的存储模块了。

#### 如何实现重启后快速提供服务？

SimpleKV采用了常用的内存分配器glibc的malloc和free，因此，SimpleKV并不需要特别考虑内存空间的管理问题。但是，键值数据库的键值对通常大小不一，glibc的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。

因此，**分配器是键值数据库中的一个关键因素。对于以内存存储为主的Redis而言，这点尤为重要。Redis的内存分配器提供了多种选择，分配效率也不一样，后面我会具体讲一讲这个问题。**SimpleKV虽然依赖于内存保存数据，提供快速访问，但是，我也希望SimpleKV**重启后能快速重新提供服务，所以，我在SimpleKV的存储模块中增加了持久化功能。**



#### 小结

<img src="https://img-blog.csdnimg.cn/f281a7821c4c4ae2b47a42a61a6de53f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5aO55bCP5L-K,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />

从这张对比图中，我们可以看到，从SimpleKV演进到Redis，有以下几个重要变化：

* Redis主要**通过网络框架进行访问**，而不再是动态库了，这也使得Redis可以作为一个基础性的网络服务进行访问，扩大了Redis的应用范围。
* Redis数据模型中的**value类型很丰富**，因此也带来了更多的操作接口，例如面向列表的LPUSH/LPOP，面向集合的SADD/SREM等。在下节课，我将和你聊聊这些value模型背后的数据结构和操作效率，以及它们对Redis性能的影响。
* Redis的**持久化模块能支持两种方式：日志（AOF）和快照（RDB）**，这两种持久化方式具有不同的优劣势，影响到Redis的访问性能和可靠性。
* SimpleKV是个简单的单机键值数据库，但是，**Redis支持高可靠集群和高可扩展集群**，因此，Redis中包含了相应的集群功能支撑模块。



### 02 Redis的慢操作

#### 一、Redis数据类型的底层实现

**底层数据结构**一共有 **6** 种，分别是**简单动态字符串、双向链表、压缩列表、哈希表、跳表、整数数组**。它们和**数据类型**的对应关系如下图所示：

<img src="https://img-blog.csdnimg.cn/b68e70c00312416582949f0aa4e36de2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis数据类型和底层数据结构的对应关系" style="zoom:67%;" />

String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。这四种类型称为集合类型，它们的特点是**一个键对应了一个集合的数据**。



#### 二、键和值的结构组织

为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。哈希表就是一个数组，数组的每个元素称为一个哈希桶。一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。

其实，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。

如图，哈希桶中的 entry 元素中保存了key和value指针，分别指向了实际的键和值，即使值是一个集合，也可以通过value指针被查找到。

<img src="https://img-blog.csdnimg.cn/a444e1eaeb7e48008947a5dec9686a12.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="全局哈希表" style="zoom:67%;" />

因为这个哈希表保存了所有的键值对，所以把它称为全局哈希表。哈希表的最大好处是可以用 O(1) 的时间复杂度来快速查找到键值对。只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素。

这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。不管哈希表里有 10 万个键还是 100 万个键，只需要一次计算就能找到相应的键。

#### 三、哈希表操作变慢的原因

往哈希表中写入更多数据时，哈希冲突是不可避免的问题。即两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。哈希桶的个数通常要少于 key 的数量，难免会有一些 key 的哈希值对应到了同一个哈希桶中。

##### 3.1、链式哈希

Redis 解决哈希冲突的方式是链式哈希。指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。

如图，entry1、entry2 和 entry3 都需要保存在哈希桶 3 中，导致了哈希冲突。此时，entry1 元素会通过一个next指针指向 entry2，同样，entry2 也会通过next指针 指向 entry3。即使哈希桶 3 中的元素有 100 个，也可以通过 entry 元素中的指针把它们连起来。这就形成了一个链表，也叫作哈希冲突链。

##### 3.2、rehash

哈希冲突链上的元素只能通过指针逐一查找再操作。**如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低**。

**为了避免这个问题，Redis 会对哈希表做 rehash 操作。增加哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突**。

Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：

给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
释放哈希表 1 的空间。

用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。

##### 3.3、渐进式rehash

**第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求，无法快速访问数据了。**

为了避免这个问题，Redis 采用了**渐进式 rehash**。**在第二步拷贝数据时，Redis每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。**如图：

<img src="https://img-blog.csdnimg.cn/675241ea329a4c7fa513e6575d6a476b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="渐进式rehash" style="zoom:67%;" />

把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。

#### 四、集合类型数据操作效率

**String 类型**找到哈希桶就能直接增删改查了，**哈希表**的 **O(1)** 操作复杂度也就是它的复杂度了。

集合类型即使找到哈希桶了，还要在集合中再进一步操作。集合类型的值，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。

集合的操作效率的影响因素

1. **集合的底层数据结构有关**。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。
2. **操作本身的执行特点有关**，比如读写一个元素的操作要比读写所有元素的效率高。

#### 五、集合类型的底层数据结构

集合类型的底层数据结构主要有 5 种：**整数数组、双向链表、哈希表、压缩列表和跳表。**

哈希表上文已述，**整数数组和双向链表操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度是 O(N)，操作效率比较低**。

压缩列表像一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，**压缩列表在表头有三个字段 zlbytes（列表长度）、zltail（列表尾的偏移量） 和 zllen（entry 个数）；压缩列表在表尾还有一个 zlend，表示列表结束**。

<img src="https://img-blog.csdnimg.cn/be50c0b995c24238be6833755d52c99e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="压缩列表" style="zoom:67%;" />

**压缩列表查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。查找其他元素是逐个查找，复杂度就是 O(N) 了。**

**跳表在链表的基础上，增加了多级索引**，通过索引位置的几个跳转，**实现数据的快速定位**，当数据量很大时，**跳表的查找复杂度就是 O(logN)**， 如图：

<img src="https://img-blog.csdnimg.cn/b95bf6a165574b319936e07ed21712ac.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="跳表" style="zoom:67%;" />



按照查找的时间复杂度给这些数据结构分下类了：<img src="https://img-blog.csdnimg.cn/fdb75520d5e64b96a413aafda40712bf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="数据结构的时间复杂度" style="zoom:67%;" />



#### 六、不同操作的复杂度

集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。**复杂度的高低是我们选择集合类型的重要依据**。

提前规避高复杂度操作的四句口诀：

**单元素操作是基础；**
**范围操作非常耗时；**
**统计操作通常高效；**
**例外情况只有几个。**

第一，**单元素操作是指每一种集合类型对单个数据实现的增删改查操作**。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、 SREM、SRANDMEMBER 复杂度也是 O(1)。

注意：集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元 素时，复杂度就从 O(1) 变成 O(M) 了。

第二，**范围操作是指集合类型中的遍历操作**，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时尽量避免。

不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），实现了渐进式遍历，每次只返回有限数量的数据。相比于 HGETALL、SMEMBERS 避免了一次性返回所有元素而导致的 Redis 阻塞。

第三，**统计操作是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)**，这是因为当**集合类型采用压缩列表、双向链表、整数数组这些数据结构时，专门记录了元素的个数统计**，因此可以高效地完成相关操作。

第四，例外情况是指**某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量**。 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作是在列表的头尾增删元素，**可以通过偏移量直接定位，所以复杂度也只有 O(1)**，可以实现快速操作。

#### 总结

Redis 的底层数据结构包括了用来保存每个键和值的全局哈希表结构，**支持集合类型实现的双向链表、压缩列表、整数数组、哈希表、跳表这五大底层结构**。

Redis 能快速操作键值的原因：

* O(1) 复杂度的哈希表被广泛使用，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定；
* Sorted Set 用了 O(logN) 复杂度的跳表。

不过，集合类型的范围操作要遍历底层数据结构，复杂度通常是 O(N)。建议用其他命令来替代，例如**可以用 SCAN 来代替， 避免在 Redis 内部产生费时的全集合遍历操作**。

**List 类型两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。建议因地制宜地使用 List 类型。例如，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO 队列场景，而不是作为一个可以随机读写的集合。**



Q：整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么Redis还会把他们作为底层数据结构呢？

A：

1、**内存利用率**，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。

2、**数组对CPU高速缓存支持更友好**，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。

Q：如果在数组上是随机访问，对CPU高速缓存还友好不？

A：Redis底层的使用数组和压缩链表对数据大小限制在64个字节以下，当大于64个字节会改变存储数据的数据结构，所以随机访问对于CPU高速缓存没啥影响



### 03 Redis的高性能IO模型

[Redis](https://so.csdn.net/so/search?q=Redis&spm=1001.2101.3001.7020) 是单线程是指 **Redis 的网络 IO**和**键值对读写**是由一个线程来完成的。但 Redis 的**持久化、异步删除、集群数据同步等**，其实是由**额外的线程执行**的。所以严格来说Redis 并不是单线程的。

#### 一、Redis 用单线程的原因

Redis 为什么用单线程，就要先了解多线程的开销。

##### 1.1 多线程的开销

**使用多线程，可以增加系统吞吐率、增加系统扩展性。在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。**下面的左图是采用多线程时的理想结果。

**但是通常情况下采用多线程后，如果没有良好的系统设计，实际得到的结果是右图。刚开始增加线程数时，系统吞吐率会增加，但是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况。**

<img src="https://img-blog.csdnimg.cn/7dc8b0d7138b46e29535fa79e5d7727f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="线程数与系统吞吐率" style="zoom:67%;" />

下降原因是：

系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，**为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销**。这就是多线程编程模式面临的共享资源的并发访问控制问题。

1. 如果没有精细的设计，比如说只是简单地采用一个**粗粒度互斥锁**，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，**并行变串行**，系统吞吐率并没有随着线程的增加而增加。
2. 多线程一般会引入**同步原语**来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。

为了避免这些问题，**Redis 直接采用了单线程模式**。

#### 二、 Redis 的单线程快的原因

通常来说，单线程的处理能力要比多线程差很多，但是 Redis 却能使用单线程模型达到每秒数十万级别的处理能力，这是因为Redis 多方面设计选择的一个综合结果。

Redis 的大部分操作在**内存上完成**，再加上它采用了**高效的数据结构**，例如哈希表和跳表；
Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

##### 2.1 Redis的多路复用机制

###### 2.1.1 基本 IO 模型与阻塞点

网络操作的基本 IO 模型和潜在的**阻塞点**。以 Get 请求为例，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。

如下图，其中bind/listen、accept、recv、parse 和 send 属于网络 IO 处理，而 get 属于键值数据操作。既然 Redis 是单线程，那么最基本的一种实现是在一个线程中依次执行上面说的这些操作。

<img src="https://img-blog.csdnimg.cn/b9b8a7a25db04ee6b5b03a604f10cd22.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis基本IO模型 " style="zoom:67%;" />

这里的**网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()：**

当 Redis **监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里**，导致其他客户端无法和 Redis 建立连接。
当 Redis **通过 recv() 从一个客户端 读取数据**时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。
这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过 socket 网络模型本身支持非阻塞模式。

###### 2.1.2 非阻塞模式

**Socket 网络模型的非阻塞模式设置，主要体现在socket()、listen()、 accept() 三个关键的函数调用上。**

在 socket 模型中，不同操作调用后会返回不同的套接字类型。socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。

<img src="https://img-blog.csdnimg.cn/b6a9d676b5ac4a70b46ff00f1e56940c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis套接字类型与非阻塞设置 " style="zoom:67%;" />

**针对监听套接字，可以设置非阻塞模式**：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。

**虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。**

**针对已连接套接字，也可以设置非阻塞模式**：Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。

这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。

###### 2.1.3 基于多路复用的高性能 I/O 模型

**Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，即 select/epoll 机制。**

（redis如何使用IO多路复用）

**在 Redis 只运行单线程的情况下， 多路复用机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。**

图中的多个 FD（文件描述符） 就是刚才所说的多个套接字。 **Redis 网络框架调用 epoll 机制，让Linux内核监听这些套接字**。此时Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，不会阻塞在某一个特定的客户端请求处理上。所以Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

<img src="https://img-blog.csdnimg.cn/c5e41be4e63a464ca70c92c5557145e7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="基于多路复用的Redis高性能IO模型 " style="zoom:67%;" />

###### 2.1.4 select/epoll的事件的回调机制

**select/epoll 提供了基于事件的回调机制，针对不同事件的发生，调用相应的处理函数**。select/epoll 监测到 FD 上有请求到达时，就会触发相应的事件。

**这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理**。好处：

* **Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。**
* **Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。**

因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。

**例如现在有两个请求，这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件 和 Read 事件，此时内核就会回调 Redis 相应的 accept 和 get 函数进行处理。**

这就像病人去医院瞧病。在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以医院都设置了分诊台，分诊台会一直处理这些诊断前的工作（类似于 Linux 内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于 Redis 单线程），效率也能提升。

事件的回调机制的实现有很多种：

基于 Linux 系统下的 select 和 epoll 实现；
基于 FreeBSD 的 kqueue 实现；
基于 Solaris 的 evport 实现；
可以根据 Redis 实际运行的操作系统，选择相应的多路复用实现。

#### 总结

Redis 单线程是指网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。

单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的网络 IO 操作阻塞点。

Redis 6.0 中提出了多线程模型。



Redis 6.0 版本为什么又引入了多线程？
Redis 的瓶颈不在 CPU ，而在内存和网络，内存不够可以增加内存或通过数据结构等进行优化
但 Redis 的网络 IO 的读写占用了发部分 CPU 的时间，如果可以把网络处理改成多线程的方式，性能会有很大提升
所以总结下 Redis 6.0 版本引入多线程有两个原因
**1.充分利用服务器的多核资源**
**2.多线程分摊 Redis 同步 IO 读写负荷**

**执行命令还是由单线程顺序执行，只是处理网络数据读写采用了多线程，而且 IO 线程要么同时读 Socket ，要么同时写 Socket ，不会同时读写**



Redis 潜在的性能瓶颈在哪些地方？

Redis单线程处理IO请求性能瓶颈主要包括2个方面：

1、**任意一个请求在server中一旦发生耗时，都会影响整个server的性能**，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：
	a、操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；
	b、使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；
	c、大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；
	d、淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
	e、AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
	f、主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；
2、**并发量非常大时，单线程读写客户端IO数据存在性能瓶颈**，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。

针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。



### 04 redis-AOF日志：宕机了，Redis如何避免数据丢失？

**一旦服务器宕机，内存中的数据将全部丢失。**

我们很容易想到的一个解决方案是，从后端数据库恢复这些数据，但这种方式存在两个问题：一是，需要频繁访问数据库，会给数据库带来巨大的压力；二是，这些数据是从慢速数据库中读取出来的，性能肯定比不上从Redis中读取，导致使用这些数据的应用程序响应变慢。所以，对Redis来说，实现数据的持久化，避免从后端数据库中进行恢复，是至关重要的。

目前，**Redis的持久化主要有两大机制，即AOF日志和RDB快照。**在接下来的两节课里，我们就分别学习一下吧。这节课，我们先重点学习下AOF日志。

#### AOF日志是如何实现的？

说到日志，我们比较熟悉的是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF日志正好相反，它是写后日志，“写后”的意思是Redis是先执行命令，把数据写入内存，然后才记录日志，如下图所示：

<img src="https://img-blog.csdnimg.cn/img_convert/146736e475a218aeedf522a8ce0909da.png" alt="img" style="zoom:15%;" />

那AOF为什么要先执行命令再记日志呢？要回答这个问题，我们要先知道AOF里记录了什么内容。

传统数据库的日志，例如redo log（重做日志），记录的是修改后的数据，而AOF里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。

我们以Redis收到“set testkey testvalue”命令后记录的日志为例，看看AOF日志的内容。其中，“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有3个字节，也就是“set”命令。

<img src="https://img-blog.csdnimg.cn/img_convert/fc087fc9c6a1c2c88fa00d8eed3f5a2c.png" alt="img" style="zoom: 15%;" />

但是，**为了避免额外的检查开销，Redis在向AOF里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis在使用日志恢复数据时，就可能会出错。**

**而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。**

**除此之外，AOF还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。**

不过，AOF也有两个潜在的风险。

首先，**如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。**如果此时Redis是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果Redis是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。

**其次，AOF虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF日志也是在主线程中执行的**，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。

仔细分析的话，你就会发现，这两个风险都是和AOF写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后AOF日志写回磁盘的时机，这两个风险就解除了。

#### 三种写回策略

其实，对于这个问题，AOF机制给我们提供了三个选择，也就是AOF配置项appendfsync的三个可选值。

* Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
* Everysec，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
* No，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。我们来分析下其中的原因。

<img src="https://img-blog.csdnimg.cn/img_convert/53b69091ba9ff38c67775347b3e388ec.png" alt="img" style="zoom:67%;" />

总结一下就是：**想要获得高性能，就选择No策略；如果想要得到高可靠性保证，就选择Always策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择Everysec策略。**

AOF是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF文件会越来越大。这也就意味着，我们一定要小心AOF文件过大带来的性能问题。

这里的“性能问题”，主要在于以下三个方面：一是，文件系统本身对文件大小有限制，无法保存过大的文件；二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；三是，如果发生宕机，AOF中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到Redis的正常使用。

所以，我们就要采取一定的控制手段，这个时候，AOF重写机制就登场了。

#### 日志文件太大了怎么办？

为什么重写机制可以把日志文件变小呢? 实际上，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。

不过，虽然AOF重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的过程。这时，我们就要继续关注另一个问题了：重写会不会阻塞主线程？

#### AOF重写会阻塞吗?

**和AOF日志由主线程写回不同，重写过程是由后台线程bgrewriteaof来完成的，这也是为了避免阻塞主线程，导致数据库性能下降**。我把重写的过程总结为“**一个拷贝，两处日志**”。

**“一个拷贝”就是指，每次执行重写时，主线程fork出后台的bgrewriteaof子进程。此时，fork会把主线程的内存拷贝一份给bgrewriteaof子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。**

**“两处日志”**又是什么呢？

因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，**第一处日志就是指正在使用的AOF日志**，Redis会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个AOF日志的操作仍然是齐全的，可以用于恢复。

**而第二处日志，就是指新的AOF重写日志。**这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的AOF文件，以保证数据库最新状态的记录。此时，我们就可以用新的AOF文件替代旧文件了。

<img src="https://img-blog.csdnimg.cn/img_convert/d56c56233b8fa08d01914be51aa56b53.png" alt="img" style="zoom:50%;" />

总结来说，**每次AOF重写时，Redis会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为Redis采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。**

#### 小结

这节课，我向你介绍了Redis用于避免数据丢失的AOF方法。这个方法通过逐一记录操作命令，在恢复时再逐一执行命令的方式，保证了数据的可靠性。

这个方法看似“简单”，但也是充分考虑了对Redis性能的影响。总结来说，它提供了AOF日志的三种写回策略，分别是Always、Everysec和No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。

此外，**为了避免日志文件过大，Redis还提供了AOF重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。**

其中，三种写回策略体现了系统设计中的一个重要原则 ，即trade-off，或者称为“取舍”，指的就是在性能和可靠性保证之间做取舍。我认为，这是做系统设计和开发的一个关键哲学，我也非常希望，你能充分地理解这个原则，并在日常开发中加以应用。

不过，你可能也注意到了，落盘时机和重写机制都是在“记日志”这一过程中发挥作用的。例如，落盘时机的选择可以避免记日志时阻塞主线程，重写可以避免日志文件过大。**但是，在“用日志”的过程中，也就是使用AOF进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上Redis的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。**

那么，有没有既能避免数据丢失，又能更快地恢复的方法呢？当然有，那就是RDB快照了。



AOF潜在的阻塞风险？

问题1，**Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景**，下面依次介绍。

​	a、**fork子进程，fork这个瞬间一定是会阻塞主线程的**（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），**fork采用操作系统提供的写实复制(Copy On Write)机制**，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是**拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久**。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。

​	b、**fork出的子进程指向与父进程相同的内存地址空间**，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，**如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间**，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在**Redis机器上需要关闭Huge Page机制**。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。

为什么AOF重写不复用AOF本身的日志？

问题2，AOF重写不复用AOF本身的日志，**一个原因是父子进程写同一个文件必然会产生竞争问题**，控制竞争就意味着会影响父进程的性能。**二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。**所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。



### 05 redis内存快照：宕机后，Redis如何实现快速恢复？

上节课，我们学习了Redis避免数据丢失的AOF方法。这个方法的好处，是每次执行只需要记录操作命令，需要持久化的数据量不大。一般而言，只要你采用的不是always的持久化策略，就不会对性能造成太大影响。

但是，也正因为记录的是操作命令，而不是实际的数据，所以，用AOF方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis就会恢复得很缓慢，影响到正常使用。这当然不是理想的结果。那么，还有没有既可以保证可靠性，还能在宕机时实现快速恢复的其他方法呢？

当然有了，这就是我们今天要一起学习的**另一种持久化方法：内存快照。所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。**

对Redis来说，它实现类似照片记录效果的方式，就是**把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为RDB文件，其中，RDB就是Redis DataBase的缩写。**

和AOF相比，RDB记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把RDB文件读入内存，很快地完成恢复。听起来好像很不错，但内存快照也并不是最优选项。为什么这么说呢？

我们还要考虑两个关键问题：

对哪些数据做快照？这关系到快照的执行效率问题；
做快照时，数据还能被增删改吗？这关系到Redis是否被阻塞，能否同时正常处理请求。

#### 给哪些内存数据做快照？

Redis的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是**全量快照**，也就是说，**把内存中的所有数据都记录到磁盘中**。

对于Redis而言，它的单线程模型就决定了，我们要尽量避免所有会阻塞主线程的操作，所以，针对任何操作，我们都会提一个灵魂之问：“它会阻塞主线程吗?”RDB文件的生成是否会阻塞主线程，这就关系到是否会降低Redis的性能。

Redis提供了两个命令来生成RDB文件，分别是save和bgsave。

* save：在主线程中执行，会导致阻塞；
* **bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，这也是Redis RDB文件生成的默认配置。**

好了，这个时候，我们就可以通**过bgsave命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对Redis的性能影响**。接下来，我们要关注的问题就是，在对内存数据做快照时，这些数据还能“动”吗? 也就是说，这些数据还能被修改吗？ 这个问题非常重要，这是因为，如果数据能被修改，那就意味着Redis还能正常处理写操作。否则，所有写操作都得等到快照完了才能执行，性能一下子就降低了。

#### 快照时数据能修改吗?

举个例子。我们在时刻t给内存做快照，假设内存数据量是4GB，磁盘的写入带宽是0.2GB/s，简单来说，至少需要20s（4/0.2 = 20）才能做完。如果在时刻t+5s时，一个还没有被写入磁盘的内存数据A，被修改成了A’，那么就会破坏快照的完整性，因为A’不是时刻t时的状态。因此，和拍照类似，我们在做快照时也不希望数据“动”，也就是不能被修改。

但是，如果快照执行期间数据不能被修改，是会有潜在问题的。对于刚刚的例子来说，在做快照的20s时间里，如果这4GB的数据都不能被修改，Redis就不能处理对这些数据的写操作，那无疑就会给业务服务造成巨大的影响。

你可能会想到，可以用bgsave避免阻塞啊。这里我就要说到一个常见的误区了，**避免阻塞和正常处理写操作并不是一回事**。此时，**主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据**。

为了快照而暂停写操作，肯定是不能接受的。所以这个时候，**Redis就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作**。

简单来说，**bgsave子进程是由主线程fork生成的，可以共享主线程的所有内存数据。bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件。**

此时，如果主线程对这些数据也都是读操作（例如图中的键值对A），那么，主线程和bgsave子进程相互不影响。但是，**如果主线程要修改一块数据（例如图中的键值对C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave子进程会把这个副本数据写入RDB文件，而在这个过程中，主线程仍然可以直接修改原来的数据。**

<img src="https://img-blog.csdnimg.cn/img_convert/6a00acc569be8481bbf1f534025be0bd.png" alt="img" style="zoom:67%;" />

**这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。**

到这里，我们就解决了对“哪些数据做快照”以及“做快照时数据能否修改”这两大问题：Redis会使用bgsave对当前内存中的所有数据做快照，这个操作是子进程在后台完成的，这就允许主线程同时可以修改数据。

现在，我们再来看另一个问题：多久做一次快照？

#### 可以每秒做一次快照吗？

对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，这其中的快照间隔时间就很关键了。

如下图所示，我们先在T0时刻做了一次快照，然后又在T0+t时刻做了一次快照，在这期间，数据块5和9被修改了。如果在t这段时间内，机器宕机了，那么，只能按照T0时刻的快照进行恢复。此时，数据块5和9的修改值因为没有快照记录，就无法恢复了。

<img src="https://img-blog.csdnimg.cn/img_convert/15e8f4e7526f47fbd3a5e2dab7973529.png" alt="img" style="zoom:67%;" />

所以，要想尽可能恢复数据，t值就要尽可能小，t越小，就越像“连拍”。那么，t值可以小到什么程度呢，比如说是不是可以每秒做一次快照？毕竟，每次快照都是由bgsave子进程在后台执行，也不会阻塞主线程。

**这种想法其实是错误的。虽然bgsave执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。**

**一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力**，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。

**另一方面，bgsave子进程需要通过fork操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长**。如果频繁fork出bgsave子进程，这就会频繁阻塞主线程了。那么，有什么其他好方法吗？

此时，我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。

在第一次做完全量快照后，T1和T2时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是，我们**需要记住哪些数据被修改了**。这会带来额外的空间开销问题。为了“记住”修改，引入的额外空间开销比较大。这对于内存资源宝贵的Redis来说，有些得不偿失。

到这里，你可以发现，虽然**跟AOF相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销**，那么，还有什么方法既能利用RDB的快速恢复，又能以较小的开销做到尽量少丢数据呢？

**Redis 4.0**中提出了一个**混合使用AOF日志和内存快照的方法**。简单来说，**内存快照以一定的频率执行，在两次快照之间，使用AOF日志记录这期间的所有命令操作。**

**这样一来，快照不用很频繁地执行，这就避免了频繁fork对主线程的影响。而且，AOF日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。**

如下图所示，T1和T2时刻的修改，用AOF日志记录，等到第二次做全量快照时，就可以清空AOF日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。

<img src="https://img-blog.csdnimg.cn/img_convert/8878c0489ade670dcbdd40e9f3aa139c.png" alt="img" style="zoom:67%;" />

**这个方法既能享受到RDB文件快速恢复的好处，又能享受到AOF只记录操作命令的简单优势**，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。

#### 小结

这节课，我们学习了Redis用于避免数据丢失的内存快照方法。这个方法的优势在于，可以快速恢复数据库，也就是只需要把RDB文件直接读入内存，这就避免了AOF需要顺序、逐一重新执行操作命令带来的低效性能问题。

不过，内存快照也有它的局限性。它拍的是一张内存的“大合影”，不可避免地会耗时耗力。虽然，Redis设计了bgsave和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。而**混合使用RDB和AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。**

最后，关于AOF和RDB的选择问题，我想再给你提三点建议：

**数据不能丢失时，内存快照和AOF的混合使用是一个很好的选择；**
**如果允许分钟级别的数据丢失，可以只使用RDB；**
**如果只用AOF，优先使用everysec的配置选项，因为它在可靠性和性能之间取了一个平衡。**



### 06 Redis主从库的数据同步

#### 前言

Redis 具有高可靠性：

**数据尽量少丢失（AOF 和 RDB 保证）；**
**服务尽量少中断（增加副本冗余量）。**
即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。

Redis 的主从库模式，以保证数据副本的一致，**主从库之间采用的是读写分离的方式**：

**读操作：主库、从库都可以接收；**
**写操作：先到主库执行，然后主库将写操作同步给从库。**

<img src="https://img-blog.csdnimg.cn/3566b574191a488f9d379643db1eb308.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis主从库和读写分离 " style="zoom: 25%;" />

#### 一、采用读写分离的原因

上图中不管是主库还是从库，都能接收客户端的写操作，一个直接的问题是：如果客户端对同一个数据（例如 k1）前后修改了三次，每一次 的修改请求都发送到不同的实例上，在不同的实例上执行，那么，这个**数据在这三个实例上的副本就不一致了**（分别是 v1、v2 和 v3）。在读取这个数据的时候，就可能读取到旧的值。

如果非要保持这个数据在三个实例上一致，就要涉及到加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的开销，当然是不太能接受的。

主从库模式采用读写分离，所有数据的修改只会在主库上进行，不用协调三个实例。主库有了最新的数据后，会同步给从库，主从库的数据就是一致的。

#### 二、主从库间进行第一次同步

启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。

例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），在实例 2 上 执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：

```
replicaof 172.16.19.3 6379
```


主从库间数据第一次同步的三个阶段：

主从库间数据第一次同步的三个阶段：

![主从库第一次同步的流程 ](https://img-blog.csdnimg.cn/7318084875644e6eab9c4e1d0a132e2c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16)



**第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备**。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开 始同步了。

**从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。**psync 命令包含了主库的 runID 和复制进度 offset 两个参数。
**runID**，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实 例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设 为“？”。
**offset**，此时设为 -1，表示第一次复制。
**主库收到 psync 命令后，会用FULLRESYNC （第一次采用全量复制）响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。**
**第二阶段，主库将所有数据同步给从库。**从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。

**主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。**
**从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。**这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。
在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。**为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作**。

**第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。**当主库完成 RDB 文件发送后，就会**把此时 replication buffer 中的修改操作发给从库**，从库再重新执行这些操作。主从库就实现同步了。

#### 三、主从[级联](https://so.csdn.net/so/search?q=级联&spm=1001.2101.3001.7020)模式分担全量复制时的主库压力

通过分析主从库间第一次数据同步的过程，一次全量复制中，对于主库来说，需要完成**两个耗时的操作**：**生成 RDB 文件**和**传输 RDB 文件**。

1. 如果**从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步**。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。
2. **传输 RDB 文件也会占用主库的网络带宽**，同样会给主库的资源使用带来压力

Redis可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力， 以级联的方式分散到从库上。

<img src="https://img-blog.csdnimg.cn/8df1441104644468a54dafd107d079d8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="级联的“主-从-从”模式 " style="zoom:25%;" />



#### 四、主从库间网络断开后的增量复制

主从库间通过全量复制实现数据同步的过程，以及通过“主 - 从 - 从”模式分担主库压力的方式。那么一旦主从库完成了全量复制，它们之间就会一 直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为**基于长连接**的命令传播，**可以避免频繁建立连接的开销**。

**基于长连接的风险：最常见的就是网络断连或阻塞。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致了，客户端就可能从从库读到旧数据。**

在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，从库就会和主库重新进行一次全量复制，开销非常大。

**从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步**。它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。

**增量复制时，主从库之间保持同步依靠 repl_backlog_buffer 这个缓冲区：**

**当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。**
**repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。**

刚开始的时候，主库和从库的写读位置在一起，是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。

从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。

<img src="https://img-blog.csdnimg.cn/d34b425da21044b0ba30572450775788.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis repl_backlog_buffer的使用 " style="zoom:25%;" />

主从库的连接恢复之后：

从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库；
主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。
在网络断连阶段，主库可能会收到新的写操作命令，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。

#### 五、repl_backlog_buffer 环形缓冲区

**repl_backlog_buffer 是一个环形缓冲区，在缓冲区写满后，主库会继续写入，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。**

可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：
**缓冲空间大小 = 主库写入命令速度 *操作大小- 主从库间网络传输命令速度 * 操作大小。**
在实际应用中，考虑到可能存在一些突发的请求压力，通常需要把这个缓冲空间扩大一倍，即
repl_backlog_size = 缓冲空间大小 * 2。

举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，有 1000 个操作需要缓冲起来，至少需要 2MB 的缓冲空间。否则新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，最终把 repl_backlog_size 设为 4MB。

通过设置repl_backlog_size 的大小，增量复制时主从库的数据不一致风险就降低了。不过如果并发请求量非常 大，连两倍的缓冲空间都存不下新操作请求的话，主从库数据仍然可能不一致。建议：

1. 可以根据 Redis 所在服务器的内存资源再适当增加 repl_backlog_size 值，比如说设置成缓冲空间大小的 4 倍；
2. 使用切片集群来分担单个主库的请求压力。

#### 总结

Redis 的主从库同步的基本原理有三种模式：**全量复制、基于长连接的命令传播、增量复制**。

全量复制虽然耗时，但是从库的第一次同步，全量复制是无法避免的，建议：

1. **一个 Redis 实例的数据库不要太大**，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。
2. **避免多个从库同时和主库进行全量复制，给主库过大的同步压力**，可以采用“主 - 从 - 从”这 一级联模式，来缓解主库的压力。

**长连接复制**是主从库正常运行后的常规同步阶段。主从库之间通过命令传播实现同步。这期间如果遇到了网络断连，增量复制就派上用场了。 repl_backlog_size 如果它配置得过小，在**增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制**。通过调大repl_backlog_size 参数，可以减少从库在网络断连时全量复制的风险。

 为什么主从库间的复制不使用 AOF？

1. **RDB 文件是二进制文件**，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，**IO 效率都比记录和传输 AOF 的高**。

2. 在从库端进行恢复时，**用 RDB 的恢复效率要高于用 AOF**。

   

### 07 Redis 的哨兵机制

如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，进行相关的操作，但是如果主库发生故障了，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了。

而且，如果客户端发送的都是读操作请求，那还可以由从库继续提供服务，但是一旦有写操作请求了，按照主从库模式下的读写分离要求， 需要由主库来完成写操作。没有实例可以来服务客户端的写操作请求了，如图：

<img src="https://img-blog.csdnimg.cn/c67df24887e54bbd88f4c222021ed567.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="主库故障后从库无法服务写操作 " style="zoom: 25%;" />

无论是写服务中断，还是从库无法进行数据同步，都是不能接受的。如果主库挂了，就需要运行一个新主库，比如说把一个从库切换为主库，把它当成主库。这就涉及到三个问题：

1. 主库真的挂了吗？
2. 该选择哪个从库作为主库？
3. 怎么把新主库的相关信息通知给从库和客户端呢？

Redis 主从集群中，**哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题**。

#### 一、哨兵机制的基本流程

哨兵是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。**哨兵主要负责的就是三个任务：监控、选主、通知。**

**监控**：指哨兵进程在运行时，**周期性地给所有的主从库发送 PING 命令， 检测它们是否仍然在线运行**。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就 会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。

**选主**：**主库挂了以后，哨兵需要从多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库**。这一步完成后，现在的集群里就有了新主库。

**通知**：**哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令和新主库建立连接，并进行数据复制**。同时哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。

<img src="https://img-blog.csdnimg.cn/7c2cd07e38d241b18e2cded362138edf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="哨兵机制的三项任务与目标 " style="zoom:25%;" />

在这三个任务中，通知任务相对来说比较简单，哨兵只需要把新主库信息发给从库和客户端，让它们和新主库建立连接就行，并不涉及决策的逻辑。但是在监控和选主这两个任 务中，哨兵需要做出两个决策：

**在监控任务中，哨兵需要判断主库是否处于下线状态；**
**在选主任务中，哨兵也要决定选择哪个从库实例作为主库。**



#### 二、监控：主库的主观下线和客观下线

**主观下线**：哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。**如果哨兵发现主库或从库对 PING 命令的响应超时了，哨兵就会先把它标记 为“主观下线”。**

​	从库：**如果检测的是从库，哨兵简单地把它标记为“主观下线”就行了**，因为从库的下线影响一般不太大，集群的对外服务不会间断。
​	主库：**如果检测的是主库，哨兵还不能简单地把它标记为“主观下线”，开启主从切换**。因为很有**可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障**。可是一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。
注意误判的情况： 主库实际并没有下线，但是哨兵误以为它下线 了。**误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。**

**哨兵机制采用多实例组成的集群模式进行部署（哨兵集群）**。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。**多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低**。

**在判断主库是否下线时，不能由一个哨兵说了算**，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”。原则是：**少数服从多数**。这会进一步触发哨兵开始主从切换流程。

如图，Redis 主从集群有一个主库、三个从库，还有三个哨兵实例。左图哨兵 2 判断主库为“主观下线”，但哨兵 1 和 3 却判定主库是上线状态，主库仍然被判断为处于上线状态。右图，哨兵 1 和 2 都判断主库为“主观下线”，此 时，即使哨兵 3 仍然判断主库为上线状态，主库也被标记为“客观下线”了。

<img src="https://img-blog.csdnimg.cn/e2f74306d9be4ce8a5281921464b800a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="客观下线的判断 " style="zoom:25%;" />

**“客观下线”的标准是有 N 个哨兵实例时，要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。**可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下 线”的判断才可以，可以由 Redis 管理员自行设定）。

#### 三、选主：筛选 + 打分

<img src="https://img-blog.csdnimg.cn/88e312072752430691bc6332f89e02af.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="新主库的选择过程 " style="zoom:25%;" />



##### 3.1 筛选的条件

一般情况下，要先保证所选的从库仍然在线运行。不过在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的。例如，一个从库正常运行，把它选为新主库开始使用了。很快它的网络出了故障，就得重新选主了。这不是期望的结果。

所以，在选主时除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，说明这个从库的网络状况并不是太好，就可以把这个从库筛掉了。

使用配置项 down-after-milliseconds * 10。down-after- milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after- milliseconds 毫秒内，主从节点都没有通过网络联系上，就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。这样就过滤掉了不适合做主库的从库，完成了筛选工作。

##### 3.2 打分的规则

**分别按照三个规则依次进行三轮打分：从库优先级、从库复制进度、从库 ID 号。只要在某一轮中从库得分最高的就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。**

**第一轮：优先级最高的从库得分高。**

可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时， 哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。

**第二轮：和旧主库同步程度最接近的从库得分高。**

选择和旧主库同步最接近的那个从库作为主库，这个新主库上就有最新的数据。主从库同步时有个命令传播的过程，主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。

想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库。

当然，如果有两个从库的 slave_repl_offset 值大小是一样的，就需要给它们进行第三轮打分了。

**第三轮：ID 号小的从库得分高。**

每个实例都会有一个 ID，这个 ID 就类似于这里的从库的编号。Redis 在选主库时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。

#### 总结

**哨兵机制是实现 Redis 不间断服务的重要保证**。主从集群的数据同步是数据可靠的基础保证；而在主库发生故障时，自动的主从切换是服务不间断的关键支撑。

Redis 的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低 Redis 集群的运维开销：

1. 监控主库运行状态，并判断主库是否客观下线；
2. 在主库客观下线后，选取新主库；
3. 选出新主库后，通知从库和客户端。

为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实例通过“少数服从多数”的原则，来判断主库是否客观下线。可以部署三个哨兵，如果有两个哨兵认定主库“主观下线”，就可以开始切换过程。如果希望进一步提升判断准确率，也可以再适当增加哨兵个数，比如说使用五个哨兵。

Q:在主从切换过程中，客户端能否正常地进行请求操作呢？

A:主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是对于写请求操作，客户端就无法执行了。



### 08 Redis的哨兵集群

多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客户端。

在配置哨兵的信息时，我们只需要用到下面的这个 配置项，**设置主库的 IP 和端口**，并没有配置其他哨兵的连接信息。

```
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
例子：　sentinel monitor mymaster 192.168.0.5 6379 2
```

#### 一、基于发布 / 订阅机制的哨兵集群组成

**哨兵实例之间可以相互发现是因为 Redis 提供的发布 / 订阅机制。**

哨兵和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。**当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口**。

除了哨兵实例，自己编写的应用程序也可以通过 Redis 进行消息的发布和订阅。为了区分不同应用的消息，Redis 会以频道（类别）的形式，对这些消息进行分门别类的管理。当消息类别相同时，它们就属于同一个频道。 反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。

**在主从集群中，主库上有一个名为“_ sentinel _:hello”的频道，不同哨兵就是通过 它来相互发现，实现互相通信的。**

下图中，哨兵 1 把自己的 IP（172.16.19.3）和端口 （26579）发布到“sentinel:hello”频道上，哨兵 2 和 3 订阅了该频道。哨兵 2 和 3 就可以从这个频道直接获取哨兵 1 的 IP 地址和端口号。

哨兵 2、3 可以和哨兵 1 建立网络连接。通过这个方式，哨兵 2 和 3 也可以建立网络连接，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商。

<img src="https://img-blog.csdnimg.cn/63cc327786fe425bb3fd37680b199328.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="发布/订阅机制" style="zoom:33%;" />



#### 二、哨兵获取从库的 IP 地址和端口

哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。

这是**由哨兵向主库发送 INFO 命令来完成的**。就像下图所示，哨兵 2 给主库发送 INFO 命令，**主库接受到这个命令后，就会把从库列表返回给哨兵。**接着，**哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。**哨兵 1 和 3 可以通过相同的方法和从库建立连接，并进行监控。

<img src="https://img-blog.csdnimg.cn/38197296a8d841ac859d91d62b8f2e63.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。哨兵还需要完成把新主库的信息告诉客户端。

在实际使用哨兵时，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。 仍然可以依赖 发布/订阅 机制，来帮助我们完成哨兵和客户端间的信息同步。

#### 三、基于 发布/订阅 机制的客户端事件通知

**哨兵是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务**。每个哨兵实例也提供 发布/订阅 机制，**客户端可以从哨兵订阅消息。**哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

重要的频道 汇总在了一起，涉及几个关键事件，包括**主库下线判断、新主库选定、从库重新配置**：

<img src="https://img-blog.csdnimg.cn/5c166b22ae8e4c78baba5819a422208a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

可以让客户端从哨兵这里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。可以在客户端执行订阅命令，来获取不同的事件消息。

有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。

有了 发布/订阅 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了，哨兵集群的监控、选主 和通知三个任务就基本可以正常工作了。

#### 四、确定由哪个哨兵执行主从切换

确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程。

**任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down- by-addr 命令。其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相 当于赞成票，N 相当于反对票。**

一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。例如，现在有 5 个哨兵， quorum 配置的是 3，一个哨兵需要 3 张赞成票，就可以标记主库为“客观下 线”了。这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。

<img src="https://img-blog.csdnimg.cn/a5f087306e36423fa039f01da8f9584c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：

1. 拿到半数以上的 赞成票；
2. 拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

拿以 3 个哨 兵为例，假设此时的 quorum 设置为 2，一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。
如图展示一下 3 个哨兵、quorum 为 2 的选举 过程：

![在这里插入图片描述](https://img-blog.csdnimg.cn/aaa8daca79804e6ca1cb23ae78b4dc1b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16)

**如果 S3 没有拿到 2 票 Y，那么这轮投票就不会产生 Leader。哨兵集群会等待一段时间 （也就是哨兵故障转移超时时间的 2 倍），再重新选举。**因为哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。如果网络压力较大或有短时堵塞， 就可能导致没有一个哨兵能拿到半数以上的赞成票。所以等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。

需要注意的是，如果哨兵集群只有 2 个实例，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。如果有个哨兵挂掉了，此时的集群是无法进行主从库切换的。通常我们至少会配置 3 个哨兵实例。

#### 总结

哨兵集群的这些关键机制：

**基于 发布/订阅 机制的哨兵集群组成过程；**
**基于 INFO 命令的从库列表，这可以帮助哨兵和从库建立连接；**
**基于哨兵自身的 发布/订阅 功能，这实现了客户端和哨兵之间的事件通知**
主从切换时，哨兵集群在判断了主库“客观下线”后，经过投票仲裁，选举一个 Leader 出来，由它负责实际的主从切换，即**由它来完成新主库的选择以及通知从库与客户端。**

**要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds**。这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库**形成共识**，也就没有及时切换主库，最终的结果就是集群服务不稳定。

Q: 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例 都发生故障了，此时Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如 果可以的话，还能进行主从库自动切换吗？
A: 因为判定主库“客观下线”的依据是**，认为主库“主观下线”的哨兵个数要大于等于 quorum 值**，现在还剩 2 个哨兵实例，个数正好等于 quorum 值，**所以还能正常判断主库是否处于“客观下线”状态**。如果一个哨兵**想要执行主从切换，就要获到半数以上的哨兵投票赞成**，也就是至少需要 3 [max(quorum， num(sentinels)/2+1)]个哨兵投票赞成。但是现在只有 2 个哨兵了，所以就**无法进行主从切换了**。



Q:哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？
A: **哨兵实例越多，误判率会越低，但是在判定主库下线和选举 Leader 时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加**，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。 如果业务层对 Redis 的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。

**调大 down-after-milliseconds 后，可能会导致**这样的情况：**主库实际已经发生故障了， 但是哨兵过了很长时间才判断出来**，这就会影响到 Redis 对业务的可用性。



### 09 Redis的切片集群

#### 前言

需求：要用 Redis 保存 5000 万个键值对，每个键值对大约是 512B， 为了能快速部署并对外提供服务，采用云主机来运行 Redis 实例，粗略地计算了一下，这些键值对所占的内存空间大约是 25GB（5000 万 *512B）。

方案：选择一台 32GB 内存的云主机来部署 Redis。因为32GB 的内存能保存所有数据，而且还留有 7GB，可以保证系统的正常运行。还采用 RDB 对数据做持久化，以确保 Redis 实例故障后，还能从 RDB 恢复数据。在使用的过程中发现Redis 的响应有时会非常慢。使用 INFO 命令查看 Redis 的 latest_fork_usec 指标值（表示最近一次 fork 的耗时），结果显示这个指标值特别高，快到秒级别了。

这跟 Redis 的持久化机制有关系。在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长**。在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致 Redis 响应变慢了。**

方案是不可行的，必须要寻找其他的方案。Redis 的切片集群。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对 Redis 主线程的阻塞影响较小。

#### 一、Redis的切片集群

切片集群（分片集群）是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。如果把 25GB 的数据平均分成 5 份（当然，也可以不做均分），使用 5 个实例来保存，每个实例只需要保存 5GB 数据。

在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。

#### 二、切片集群保存更多的数据

为了保存大量数据，使用了大内存云主机和切片集群两种方法。这两种方法分别对应着 Redis 应对数据量增多的两种方案：纵向扩展（scale up） 和横向扩展（scale out）：

**纵向扩展**：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。就像下图中，原来的实例内存是 8GB，硬盘是 50GB，纵向扩展后， 内存增加到 24GB，磁盘增加到 150GB。
**横向扩展**：横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 8GB 内存、 50GB 磁盘的实例，现在使用三个相同配置的实例。

<img src="https://img-blog.csdnimg.cn/a91ad79e291a42c48601598a8e1700b0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />



纵向扩展（scale up） 和横向扩展（scale out）的优缺点：

**纵向扩展的优点：实施起来简单。**

**纵向扩展的缺点**：

当使用 RDB 对数据进行持久化时，如果**数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞。**不需要求持久化保存 Redis 数据，纵向扩展会是一个不错的选择。
**纵向扩展会受到硬件和成本的限制**。把内存从 32GB 扩展到 64GB 还算容易，要想扩充到 1TB，就会面临硬 件容量和成本上的限制了。
**横向扩展的优点：只用增加 Redis 的实例个数就行了，不用担心单个实例的硬件和成本限制**；在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择（扩展性更好）。

横向扩展的问题：

数据切片后，在多个实例之间如何分布？
客户端怎么确定想要访问的数据在哪个实例上？

#### 三、数据切片和实例的对应分布关系

切片集群和 Redis Cluster 的联系与区别：

切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。**从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案**，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。

Redis Cluster 方案采用**哈希槽**（Hash Slot，接下来直接称 Slot）来处理数据和实例之间的映射关系。 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中**。

映射过程分为两步：

**根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值；**
**用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。**
在部署 Redis Cluster 方案时，**可以使用 cluster create 命令创建集群，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例 上的槽个数为 16384/N 个**。

可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。

假设集群中不同 Redis 实例的内存大小配置不一，如果把哈希槽均分在各个实例上，在保存相同数量的键值对时，和内存大的实例相比，内存小的实例就会有更大的容量压力。可以根据不同实例的资源配置情况，**使用 cluster addslots 命令手动分配哈希槽**（**需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作**）。

数据、哈希槽、实例这三者的映射分布情况：

<img src="https://img-blog.csdnimg.cn/8212ff33a0724574ab5268cd5edd7db1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

图中的切片集群一共有 3 个实例，同时假设有 5 个哈希槽，可以通过下面的命令手动分配哈希槽：实例 1 保存哈希槽 0 和 1，实例 2 保存哈希槽 2 和 3，实例 3 保存 哈希槽 4。

```
redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1 
redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3 
redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4 
```

在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 5 取模，再根据各自的模数结果，就可以被映射到对应的实例 1 和实例 3 上了。

#### 四、客户端定位实例获取数据

在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。要进一步定位到实例，还需要知道哈希槽分布在哪个实例上。

**客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。**

**Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。**

**客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。**当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。

集群中实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：

1. 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
2. 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

**实例之间可以通过相互传递消息，获得最新的哈希槽分配信息，但是客户端是无法主动感知这些变化的。**这就会导致，它缓存的分配信息和最新的分配信息就不一致 了。

**Redis Cluster 方案提供了一种重定向机制**，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。

**当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，这个实例会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址。**

```
GET hello:key 
(error) MOVED 13320 172.16.19.5:6379 
```

MOVED 命令表示客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。

如图，MOVED 重定向命令的使用方法。由于负载均衡， Slot 2 中的数据已经从实例 2 迁移到了实例 3，但是客户端缓存仍然记录着“Slot 2 在实例 2”的信息，所以会给实例 2 发送命令。实例 2 给客户端返回一条 MOVED 命令，把 Slot 2 的最新位置（也就是在实例 3 上），返回给客户端，客户端就会再次向实例 3 发送请求，同时还会更新本地缓存，把 Slot 2 与实例的对应关系更新过来。

<img src="https://img-blog.csdnimg.cn/6eeba98fdc494a1ba23917f840f6e398.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:50%;" />



图中，当客户端给实例 2 发送命令时，Slot 2 中的数据已经全部迁移到了实例 3。在实际应用时，如果 Slot 2 中的数据比较多，就**可能会出现一种情况：客户端向实例 2 发送请求，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。**在这种迁移部分完成的情况下，**客户端就会收到一条 ASK 报错信息**，如下所 示：

```
GET hello:key 
(error) ASK 13320 172.16.19.5:6379 
```

ASK 命令表示两层含义：

1. 表明 Slot 数据还在迁移中；
2. ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时客户端需要给实例 3 发送 ASKING 命令， 然后再发送操作命令。

**和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。**所以在上图 中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。

#### 总结

在应对数据量扩容时**，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢**。

Redis 切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是**扩展性好，不管有多少数据，切片集群都能应对**。

**集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化**，客户端发送请求时，会收到命令执行报错信息。

Redis 3.0 之前，Redis 官方并没有提供切片集群方案，但是其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的 ShardedJedis，基于代理的 Codis、Twemproxy 等。这些方案的应用早于 Redis Cluster 方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势。

Q： 为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？
A：如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。

基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，**无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多**。



### 10 Redis 的常见问题

#### Redis 什么时候做 rehash？

Redis 会使用**装载因子**（load factor）来判断是否需要做 rehash。

装载因子的计算方式是，**哈希表中所有 entry 的个数除以哈希表的哈希桶个数。**

Redis 会根据装载因子的两种情况，来触发 rehash 操作：

**装载因子≥1，哈希表被允许进行 rehash**； 如果装载因子等于 1，假设所有键值对是平均分布在哈希表 的各个桶中的，哈希表可以不用链式哈希，因为一个哈希桶正好保存了一个键值对。如果此时再有新的数据写入，哈希表就要使用链式哈希了，这会对查询性能产生影响。在进行 RDB 生成和 AOF 重写时，哈希表的 rehash 是被禁止的，这是为了避免对 RDB 和 AOF 重写造成影响。如果此时 Redis 没有在生成 RDB 和重写 AOF，就可以进行 rehash。否则的话，再有数据写入时，哈希表就要开始使用查询较慢的链式哈希了。
**装载因子≥5，表明当前保存的数据量已经远远大于哈希桶的个数**，哈希桶里会有大量的链式哈希存在，性能会受到严重影响，**就立马开始做 rehash。**
**如果装载因子小于 1，或者装载因子大于 1 但是小于 5， 同时哈希表暂时不被允许进行 rehash（例如，实例正在生成 RDB 或者重写 AOF），哈希表是不会进行 rehash 操作的。**



#### 采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？

不是的。Redis 会执行定时任务，定时任务中就包含了 rehash 操作。

**在 rehash 被触发后，即使没有收到新请求，Redis 也会定时执行一次 rehash 操作，每次执行时长不会超过 1ms**，以免对其他任务造成影响。

#### 主线程、子进程和后台线程的联系与区别

**进程和线程的区别：从操作系统的角度来看，进程一般是指资源分配单元，例如一个进程拥有自己的堆、栈、 虚存空间（页表）、文件描述符等；而线程一般是指 CPU 进行调度和执行的实体。**

主进程和主线程：一个进程启动后，没有再创建额外的线程，这样的进程一般称为主进程或主线程。

Redis 启动以后，本身就是一个进程，它会接收客户端发送的请求，并处理读写操作请求。**接收请求和处理请求操作是 Redis 的主要工作，Redis 没有再依赖于其他线程，一般把完成这个主要工作的 Redis 进程，称为主进程或主线程。**

在主线程中还可以使用 **fork 创建子进程**，或是**使用 pthread_create 创建线程**。
Redis 中用 fork 创建的子进程：

* 创建 RDB 的后台子进程，同时由它负责在主从同步时传输 RDB 给从库；
* 通过无盘复制方式传输 RDB 的子进程；
* bgrewriteaof 子进程。

Redis 使用的线程。**从 4.0 版本开始，Redis 也开始使用 pthread_create 创建线程，这些线程在创建后，一般会自行执行一些任务，例如执行异步删除任务。**相对于完成主要工作的主线程来说，可以称这些线程为后台线程。

<img src="https://img-blog.csdnimg.cn/3fcf534520f148b387a9aa8e2fa725b3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />



#### 写时复制的底层实现机制

Redis 在使用 RDB 方式进行持久化时，会用到写时复制机制：**bgsave 子进程相当于复制了原始数据，而主线程仍然可以修改原来的数据。**

**Redis 主线程 fork 出 bgsave 子进程后，bgsave 子进程实际是复制了主线程的页表。这些页表中保存了在执行 bgsave 命令时，主线程的所有数据块在内存中的物理地址。bgsave 子进程生成 RDB 时，就可以根据页表读取这些数据，再写入磁盘中。如果此时主线程接收到了新写或修改操作，主线程会使用写时复制机制，即主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射。**

<img src="https://img-blog.csdnimg.cn/cceddd84efb74c8f8d2c9620c48e728b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />



#### replication buffer 和 repl_backlog_buffer 的区别

主从复制时，Redis 会使用 replication buffer 和 repl_backlog_buffer。

**replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer。**

**repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。**

Redis 主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，**主库会先创建一个客户端，用来连接从库，然后通过这个客户端，把写操作命令发给从库。**

**在内存中，主库上的客户端就会对应一个 replication buffer。 Redis 通过 client_buffer 配置项来控制这个 buffer 的大小。**

主库会给每个从库建立一个客户端，**所以 replication buffer 不是共享的，而是每个从库都有一个对应的客户端。**

**repl_backlog_buffer 是一块专用 buffer，在 Redis 服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，不同的从库在进行恢复时，会把自己的复制进度slave_repl_offset）发给主库，主库就可以和它独立同步。**

<img src="https://img-blog.csdnimg.cn/314bb521855b4a749de95252a216ca60.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />



### 11 Redis 节省内存的数据结构

#### 一、String 类型内存开销大的原因

案例中保存了 1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和图片存储对象 ID 的记录平均用了 64 字节。

但一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。

图片 ID 和图片存储对象 ID 都是 10 位数，可以用两个 8 字节的 Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数值， 肯定可以表示 10 位数。

String 类型却用了 64 字节的原因：**除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等信息（元数据）。当实际保存的数据较小时，元数据的空间开销就显得比较大了（相对而言）。**

**当保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数**， 这种保存方式通常也叫作 int 编码方式。

但是**当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存**，如图：

<img src="https://img-blog.csdnimg.cn/5d244f141470460e805da199fa317282.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

1. **buf：字节数组，保存实际数据。**为了表示字节数组的结束，Redis 会自动在数组最后加 一个“\0”，这就会额外占用 1 个字节的开销。
2. **len**：占 4 个字节，表示 buf 的已用长度。
3. **alloc**：也占个 4 字节，**表示 buf 的实际分配长度**，一般大于 len。

在 SDS 中，buf 保存实际数据，而 len 和 alloc 本身其实是 SDS 结构体的额外开销。

**String 类型，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销。**

因为 Redis 的数据类型有很多，**不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以Redis 会用一个 RedisObject 结构体来统 一记录这些元数据，同时指向实际数据**。

**一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针**，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址，如下图：

<img src="https://img-blog.csdnimg.cn/7efdafab751b4eafbc10a410b050fb3b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。

当**保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了**，这样就不用额外的指针再指向整数了，节省了指针的空间开销。
**当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域**，这样就可以避免内存碎片。这种布局方式也被称为 **embstr 编码方式**。
**当字符串大于 44 字节时**，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并**用指针指向 SDS 结构**。 这种布局方式被称为 **raw 编码模式**。
int、embstr 和 raw 这三种编码模式：

<img src="https://img-blog.csdnimg.cn/1b6f78504d7146ceae0bee15927c6497.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />



#### 二、计算 String 类型的内存使用量

因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。

每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。每个 ID 会使用 16 字节，加起来一共是 32 字节。

Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针， 分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图：

<img src="https://img-blog.csdnimg.cn/8cb7e85932ab49569433aa8a143c4907.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。

如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字 节空间，jemalloc 则会分配 32 字节。所以dictEntry 结构就占用了 32 字节。凑齐了String 类型保存图片 ID 和图片存储对象 ID 时一共需要用 64 个字节。



#### 三、节省内存的数据结构

Redis 有一种底层数据结构叫**压缩列表（ziplist），这是一种非常节省内存的结构**。

**压缩列表的构成：表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。**

<img src="https://img-blog.csdnimg.cn/0f1b419c0ab447b6bb40f55dfcdf82a7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

压缩列表能节省内存的原因：在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。

prev_len，表示前一个 entry 的长度。
prev_len 有两种取值情况：1 字节或 5 字节。
取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以当上 一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则就取值为 5 字节。
len：表示自身长度，4 字节；
encoding：表示编码方式，1 字节；
content：保存实际数据。

**这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。**

以保存图片存储对象 ID 为例，来分析一下压缩列表是如何节省内存空间的。

每个 entry 保存一个图片存储对象 ID（8 字节），每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。一个图片的存储对象 ID 所占用的内存大小是 14 字节（1+4+1+8=14），实际分配 16 字节。

**Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。**

当用 String 类型时，一个键值对就有一个 dictEntry， 要用 32 字节空间。

当用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。

四、集合类型保存单值的键值对
在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法：就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，就可以把单值数据保存到 Hash 集合中了。

以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。

按照这种设计方法，在 Redis 中插入了一组图片 ID 及其存储对象 ID 的记录，并且用 info 命令查看了内存开销，发现增加一条记录后，内存占用只增加了 16 字节，如下 所示：

```
127.0.0.1:6379> info memory 
# Memory 
used_memory:1039120 
127.0.0.1:6379> hset 1101000 060 3302000080 (integer) 1 
127.0.0.1:6379> info memory 
# Memory 
used_memory:1039136 
```

使用 String 类型每个记录需要消耗 64 字节，这种方式却只用了 16 字节，所使用的内存空间是原来的 1/4，满足了节省内存空间的需求。

#### 五、二级编码方法中采用的 ID 长度规则

Hash 类型的两种底层实现结构：压缩列表和哈希表。 Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。
这两个阈值分别对应以下两个配置项：

* hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。
* hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。

如果往 Hash 集合中写入的元素**个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存**，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。

为了能充分使用压缩列表的精简内存布局，一般要控制保存在 Hash 集合中的元素个 。所以在刚才的二级编码中，只用图片 ID 最后 3 位作为 Hash 集合的 key，保证了 Hash 集合的元素个数不超过 1000，同时把 hash-max-ziplist-entries 设置为 1000，Hash 集合就可以一直使用压缩列表来节省内存空间了。

#### 总结

以前认为 String 是“万金油”，什么场合都适用，**但是在保存的键值对本身占用的内存空间不大时（例如图片 ID 和图片存储对象 ID），String 类型的元数据开销就占据主导了，这里面包括了 RedisObject 结构、SDS 结构、dictEntry 结构的内存开销。**

**针对这种情况，可以使用压缩列表保存数据。**当然使用 Hash 这种集合类型保存单值键值对的数据时，需要将单值数据拆分成两部分，分别作为 Hash 集合的键和值， 例如用二级编码来表示图片 ID。



### 12 Redis 常用的集合统计模式

#### 前言

需要保存这样一种信息：一个 key 对应了一 个数据集合。例如：

手机 App 中的每天的用户登录信息：一天对应一系列用户 ID 或移动设备 ID；
电商网站上商品的用户评论列表：一个商品对应了一系列的评论；
用户在手机 App 上的签到打卡信息：一天对应一系列用户的签到记录；
应用网站上的网页访问信息：一个网页对应一系列的访问点击。
**Redis 集合类型的特点就是一个键对应一系列的数据**，非常适合用来存取这些数据。除了记录信息，还需要**对集合中的数据进行统计**，例如：

在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；
在电商网站的商品评论中，需要统计评论列表中的最新评论；
在签到打卡中，需要统计一个月内连续打卡的用户数；
在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。
面临的用户数量以及访问量都是巨大的，比如百万、千万级别的用户数量，或者千万级别、甚至亿级别的访问信息。所以必须要选择能够非常高效地统计大量数据（例如亿级）的集合类型。

#### 聚合统计

**聚合统计指统计多个集合元素的聚合结果，包括：交集统计；差集统计；并集统计**。

统计手机 App 每天的新增用户数和第二天的留存用户数，可以用一个集合记录所有登录过 App 的用户 ID，用另一个集合记录每一天登录过 App 的用户 ID。再对这两个集合做聚合统计。

累计用户 Set 中没有日期信息，是不能直接统计每天的新增用户的。 还需要把每一天登录的用户 ID，记录到一个新集合中，叫作每日用户 Set，它有两个特点：

```
key 是 user:id 以及当天日期，例如 user : id : 20200803；
```

在统计每天的新增用户时，只用计算每日用户 Set 和累计用户 Set 的差集就行。

计算累计用户 Set 和 user : id : 20200803 Set 的**并集结果**，结果保存在 user:id 这个累计用户 Set 中，如下所示：

```bash
SUNIONSTORE user:id user:id user:id:20200803 
```

user:id 这个累计用户 Set 中就有了 8 月 3 日的用户 ID。等到 8 月 4 日再统计时， 我们把 8 月 4 日登录的用户 ID 记录到 user : id : 20200804 的 Set 中。执行SDIFFSTORE 命令计算累计用户 Set 和 user : id : 20200804 Set 的**差集**，结果保存在 key 为 user:new 的 Set（新增用户Set集合） 中，如下所示：

```
SDIFFSTORE user:new user:id:20200804 user:id 
```

差集中的用户 ID 在 user : id : 20200804 的 Set 中存在，但是不在累计用户 Set 中。所以user:new 这个 Set 中记录的就是 8 月 4 日的新增用户。

计算 8 月 4 日的留存用户时，需要再计算 user : id : 20200803 和 user : id : 20200804 两个 Set 的**交集**，可以得到同时在这两个集合中的用户 ID 了，在 8 月 3 日登录也在 8 月 4 日留存的用户。执行的命令如下：

```
SINTERSTORE user:id:rem user:id:20200803 user:id:20200804 
```

**当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。**不过，我要提醒 你一下，这里有一个潜在的风险。

**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。**所以，我给你分享一个小建议：你**可以从主从集群中选择一 个从库，让它专门负责聚合计算**，或者是把数据读取到客户端，在客户端来完成聚合统 计，这样就可以规避阻塞主库实例和其他从库实例的风险了。

#### 排序统计

最新评论列表包含了所有评论中的最新留言，要求集合类型能对元素保序，集合中的元素可以按序排列，对元素保序的集合类型叫作有序集合。

在 Redis 常用的 4 个集合类型中（List、Hash、Set、Sorted Set），**List 和 Sorted Set 就属于有序集合**。

**List 是按照元素进入 List 的顺序进行排序的，Sorted Set 可以根据元素的权重来排序，可以自己来决定每个元素的权重值**。比如说可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。

每个商品对应一个 List，包含了对这个商品的所有评论，而且会按照评论时间保存这些评论，每来一个新评论，用 LPUSH 命令把它插入 List 的队头。

在只有一页评论的时候，可以看到最新的评论，但是在实际应用中，网站一般会分页显示最新的评论列表，**一旦涉及到分页操作，List 就可能会出现问题了。**

假设当前的评论 List 是{A, B, C, D, E, F}（其中，A 是最新的评论，以此类推，F 是最早的评论），在展示第一页的 3 个评论时，我们可以用下面的命令，得到最新的三条评论 A、 B、C

然后，再用下面的命令获取第二页的 3 个评论，也就是 D、E、F。

但是，如果在展示第二页前，又产生了一个新评论 G，评论 G 就会被 LPUSH 命令插入到 评论 List 的队头，评论 List 就变成了{G, A, B, C, D, E, F}。再用刚才的命令获取第二页评论时，评论 C 又被展示出来了，也就是 C、D、E。

```
LRANGE product1 3 5 
1) "C" 
2) "D" 
3) "E" 
```

**C 又被展示出来的原因：List 是通过元素在 List 中的位置来排序的，当有一个新元素插入时，原先的元素在 List 中的位置都后移了一位，**比如说原来在第 1 位的元素现在排在了第 2 位。对比新元素插入前后，**List 相同位置上的元素就会发生变化，用 LRANGE 读取时，就会读到旧元素。**

**Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。**

**可以按评论时间的先后给每条评论设置一个权重值**，然后再把评论保存到 Sorted Set 中。**Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素**。即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。

假设越新的评论权重越大，目前最新评论的权重是 N，执行下面的命令时，就可以获得最新的 10 条评论：

```
ZRANGEBYSCORE comments N-9 N
```

**面对需要展示最新列表、排行榜等场景时，数据更新频繁或者需要分页显示，优先考虑使用 Sorted Set。**

#### 值状态统计

二值状态统计，二值状态就是指集合元素的取值就只有 0 和 1 两种。在签到打卡的场景中，只用记录签到（1）或未签到（0）是非常典型的二值状态，在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。**可以选择 Bitmap。这是 Redis 提供的扩展数据类型。**

**Bitmap 的实现原理：**

**Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。 String 类型是会保存为二进制的字节数组，所以Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。把 Bitmap 看作是一个 bit 数组。**

Bitmap 提供了 **GETBIT/SETBIT 操作**，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。Bitmap 的偏移量是从 0 开始算的，也就是说 offset 的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。 Bitmap 还提供了 **BITCOUNT** 操作，用来统计这个 bit 数组中所有“1”的个数。

假设要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，操作步骤：

执行下面的命令，记录该用户 8 月 3 号已签到。

检查该用户 8 月 3 日是否签到。

统计该用户在 8 月份的签到次数。

```
GETBIT uid:sign:3000:202008 2
```

统计该用户在 8 月份的签到次数。


可以得到该用户在 8 月份的签到情况了。

```
BITCOUNT uid:sign:3000:202008
```


可以得到该用户在 8 月份的签到情况了。

```
SETBIT uid:sign:3000:202008 2 1
```

检查该用户 8 月 3 日是否签到。

统计该用户在 8 月份的签到次数。
BITCOUNT uid:sign:3000:202008
可以得到该用户在 8 月份的签到情况了。

```
GETBIT uid:sign:3000:202008 2
```

统计该用户在 8 月份的签到次数。

可以得到该用户在 8 月份的签到情况了。

```
BITCOUNT uid:sign:3000:202008
```

可以得到该用户在 8 月份的签到情况了。

记录了 1 亿个用户 10 天的签到情况，统计出这 10 天连续签到的用户总数：

**Bitmap 支持用 BITOP 命令对多个 Bitmap 按位 做“与”“或”“异或”的操作，操作的结果会保存到一个新的 Bitmap 中。**

以按位“与”操作为例来具体解释一下。下图中，三个 Bitmap bm1、 bm2 和 bm3，对应 bit 位做“与”操作，结果保存到了一个新的 Bitmap 中（示例中，这 个结果 Bitmap 的 key 被设为“resmap”）。

<img src="https://img-blog.csdnimg.cn/40457dc7c67f46c98a566af65676ca68.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

统计 1 亿个用户连续 10 天的签到情况，可以把**每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit 对应一个用户当天的签到情况。**

对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。只有 10 天都签到的用户对应的 bit 位上的值才会是 1。可以用 BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了。

可以计算一下记录了 10 天签到情况后的内存开销：

每天使用 1 个 1 亿位的 Bitmap，大约占 12MB 的内存（10^8/8/1024/1024），10 天的 Bitmap 的内存开销约为 120MB，内存压力不算太大。在实际应用时，最好对 Bitmap 设置过期时间，让 Redis 自动删除不再需要的签到记录，以节省内存开销。

需要统计数据的二值状态**，例如商品有没有、用户在不在等，就可以使用 Bitmap**，因为它**只用一个 bit 位就能表示 0 或 1**。**在记录海量数据时，Bitmap 能够有效地节省内存空间。**

#### 基数统计

基数统计指统计一个集合中不重复的元素个数（统计网页的 UV）。

网页 UV 的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，看到**有去重需求时，优先想到用 Set 类型**。

有一个用户 user1 访问 page1 时，把这个信息加到 Set 中：

```
SADD page1:uv user1
```


用户 1 再来访问时，Set 的去重功能就保证了不会重复记录用户 1 的访问次数，用户 1 就算是一个独立访客。需要统计 UV 时，可以直接用 SCARD 命令，这个命令会返回一个集合中的元素个数。

如果 page1 非常火爆，UV 达到了千万，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，**如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。**

用 Hash 类型记录 UV：

例如，把用户 ID 作为 Hash 集合的 key，当用户访问页面时，用 HSET 命令，对这个用户 ID 记录一个值“1”，表示一个独立访客，用户 1 访问 page1 后，记录为 1 个独立访客，如下所示：

```
HSET page1:uv user1 1
```

即使用户 1 多次访问页面，重复执行这个 HSET 命令，也只会把 user1 的值设置为 1，仍然只记为 1 个独立访客。当要统计 UV 时，我们可以用 HLEN 命令统计 Hash 集合中的所有元素个数。

**和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间。**

Redis 提供的 HyperLogLog 了：

**HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。**

**Redis 中每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数**。和元素越多就越耗费内存的 Set 和 Hash 类型相比，**HyperLogLog 就非常节省空间**。

统计 UV 时，用 PFADD 命令把访问页面的每个用户都添加到 HyperLogLog 中。

```
PFADD page1:uv user1 user2 user3 user4 user5
```


用 PFCOUNT 命令直接获得 page1 的 UV 值了，返回 HyperLogLog 的统计结果。

用 PFCOUNT 命令直接获得 page1 的 UV 值了，返回 HyperLogLog 的统计结果。

```
PFCOUNT page1:uv
```


**HyperLogLog 的统计规则是基于概率完成的，给出的统计结果是有一定误差的，标准误算率是 0.81%。**使用HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大， 但是**如果需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。**

HyperLogLog 的统计规则是基于概率完成的，给出的统计结果是有一定误差的，标准误算率是 0.81%。使用HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大， 但是如果需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。

#### 总结

这节课，我们结合统计新增用户数和留存用户数、最新评论列表、用户签到数以及网页独 立访客量这 4 种典型场景，学习了集合类型的 4 种统计模式，分别是聚合统计、排序统计、二值状态统计和基数统计。为了方便你掌握，我把 Set、Sorted Set、Hash、List、 Bitmap、HyperLogLog 的支持情况和优缺点汇总在了下面的表格里，希望你把这张表格 保存下来，时不时地复习一下。

<img src="https://img-blog.csdnimg.cn/eabc4e6519ac43f39b2a6cde26372ef4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:50%;" />

Set 和 Sorted Set 都支持多种聚合统计，但是只有 Set 支持差集计算来说。

Bitmap 也能做多个 Bitmap 间的聚合计算，包括与、或和异或操作。

当需要进行排序统计时，List 中的元素虽然有序，但是一旦有新元素插入，原来的元素在 List 中的位置就会移动，按位置读取的排序结果可能就不准确了。而 Sorted Set 本身是按照集合元素的权重排序，可以准确地按序获取结果，所以优先使用它。

记录的数据只有 0 和 1 两个值的状态，Bitmap 会是一个很好的选择，因为 Bitmap 对于一个数据只用 1 个 bit 记录，可以节省内存。

基数统计，如果集合元素量达到亿级别而且不需要精确统计时，使用 HyperLogLog。

### 13 [Redis](https://so.csdn.net/so/search?q=Redis&spm=1001.2101.3001.7020) 的扩展类型GEO和自定义数据类型

#### 前言

在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于**位置信息服务（Location-Based Service，LBS）**的应用。**LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中**。

五大基本数据类型， String List Hash Set SortedSet； 除此之外还有三种扩展数据类型： Bitmap， HyperLogLog 以及 GEO

对于一个 LBS 应用来说，**除了记录经纬度信息**，还需要根据用户的经纬度信息在车辆的 Hash 集合中**进行范围查询**。一旦涉及到范围查询，就意味着集合中的元素需要有序，但 Hash 类型的元素是无序的，显然不能满足我们的要求。

Sorted Set 类型也支持一个 key 对应一个 value 的记录模式，其中，key 就是 Sorted Set 中的元素，而 value 则是元素的权重分数。更重要的是，**Sorted Set 可以根据元素的权重分数排序，支持范围查询。**这就能满足 LBS 服务中查找相邻位置的需求了。**实际上，GEO 类型的底层数据结构就是用 Sorted Set 来实现的。**

用 Sorted Set 来保存车辆的经纬度信息时，Sorted Set 的元素是车辆 ID，元素的权重分数是经纬度信息，如下图所示：

<img src="https://static001.geekbang.org/resource/image/a9/4e/a9a6bc78ea3bb652ef1404020dd2934e.jpg" alt="img" style="zoom:33%;" />

这时问题来了，**Sorted Set 元素的权重分数是一个浮点数**（float 类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的，那具体该怎么进行保存呢？这就要用到 GEO 类型中的 GeoHash 编码了。

#### GeoHash 的编码方法

为了能高效地对经纬度进行比较，Redis 采用了业界广泛使用的 GeoHash 编码方法，这个方法的基本原理就是“**二分区间，区间编码**”。当我们要对一组经纬度进行 GeoHash 编码时，我们要**先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。**

我们把经度值 116.37 定位在[112.5, 123.75]这个区间，并且得到了经度值的 5 位编码值，即 11010。这个编码过程如下表所示：

<img src="https://static001.geekbang.org/resource/image/3c/f2/3cb007yy63c820d6dd2e4999608683f2.jpg" alt="img" style="zoom:25%;" />

对纬度的编码方式，和对经度的一样，只是纬度的范围是[-90，90]，下面这张表显示了对纬度值 39.86 的编码过程。

<img src="https://static001.geekbang.org/resource/image/65/6d/65f41469866cb94963b4c9afbf2b016d.jpg" alt="img" style="zoom:25%;" />

当一组经纬度值都编完码后，我们再把它们的各自编码值组合在一起，组合的规则是：**最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从 0 开始，奇数位从 1 开始。**

<img src="https://static001.geekbang.org/resource/image/4a/87/4a8296e841f18ed4f3a554703ebd5887.jpg" alt="img" style="zoom:25%;" />

用了 GeoHash 编码后，原来无法用一个权重分数表示的一组经纬度（116.37，39.86）就可以用 1110011101 这一个值来表示，就可以保存为 Sorted Set 的权重分数了。当然，使用 GeoHash 编码后，我们相当于把整个地理空间划分成了一个个方格，每个方格对应了 GeoHash 中的一个分区。举个例子。我们把经度区间[-180,180]做一次二分区，把纬度区间[-90,90]做一次二分区，就会得到 4 个分区。我们来看下它们的经度和纬度范围以及对应的 GeoHash 组合编码。

<img src="https://static001.geekbang.org/resource/image/2a/74/2a2a650086acf9700c0603a4be8ceb74.jpg" alt="img" style="zoom:25%;" />

不过，我要提醒你一句，**有的编码值虽然在大小上接近，但实际对应的方格却距离比较远。**例如，我们用 4 位来做 GeoHash 编码，把经度区间[-180,180]和纬度区间[-90,90]各分成了 4 个分区，一共 16 个分区，对应了 16 个方格。编码值为 0111 和 1000 的两个方格就离得比较远，如下图所示：

<img src="https://static001.geekbang.org/resource/image/0d/ba/0d64c9765ab72a50abef16a0275bc0ba.jpg" alt="img" style="zoom:25%;" />

所以，**为了避免查询不准确问题，我们可以同时查询给定经纬度所在的方格周围的 4 个或 8 个方格。**

好了，到这里，我们就知道了，GEO 类型是把经纬度所在的区间编码作为 Sorted Set 中元素的权重分数，把和经纬度相关的车辆 ID 作为 Sorted Set 中元素本身的值保存下来，这样相邻经纬度的查询就可以通过编码值的大小范围查询来实现了。接下来，我们再来聊聊具体如何操作 GEO 类型。

#### 如何操作 GEO 类型

在使用 GEO 类型时，我们经常会用到两个命令，分别是 **GEOADD** 和 **GEORADIUS**。

* 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中；
* GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围。

我还是以叫车应用的车辆匹配场景为例，介绍下具体如何使用这两个命令。假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：

```
GEOADD cars:locations 116.034579 39.030452 33
```

当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。

```
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

另外，我们还可以进一步限定返回的车辆信息。比如，我们**可以使用 ASC 选项，让返回的车辆信息按照距离这个中心位置从近到远的方式来排序，以方便选择最近的车辆；还可以使用 COUNT 选项，指定返回的车辆信息的数量。**毕竟，5 公里范围内的车辆可能有很多，如果返回全部信息，会占用比较多的数据带宽，这个选项可以帮助控制返回的数据量，节省带宽。可以看到，**使用 GEO 数据类型可以非常轻松地操作经纬度这种信息。**

接下来，我就再向你介绍下 Redis 扩展数据类型的终极版——自定义的数据类型。这样，你就可以定制符合自己需求的数据类型了，不管你的应用场景怎么变化，你都不用担心没有合适的数据类型。

#### 如何自定义数据类型？

为了实现自定义数据类型，首先，我们需要了解 Redis 的基本对象结构 RedisObject，因为 **Redis 键值对中的每一个值都是用 RedisObject 保存的**。我在第 11 讲中说过，**RedisObject 包括元数据和指针。其中，元数据的一个功能就是用来区分不同的数据类型，指针用来指向具体的数据类型的值。所以，要想开发新数据类型，我们就先来了解下 RedisObject 的元数据和指针。**

**Redis 的基本对象结构RedisObject 的内部组成包括了 type、encoding、lru 和 refcount 4 个元数据，以及 1 个ptr指针。**

* type：表示值的类型，涵盖了我们前面学习的五大基本类型；
* encoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等；
* lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对；
* refcount：记录了对象的引用计数；
* *ptr：是指向数据的指针。

<img src="https://static001.geekbang.org/resource/image/05/af/05c2d546e507d8a863c002e2173c71af.jpg" alt="img" style="zoom:25%;" />

RedisObject 结构借助\*ptr指针，就可以指向不同的数据类型，例如，\*ptr指向一个 SDS 或一个跳表，就表示键值对中的值是 String 类型或 Sorted Set 类型。所以，我们在定义了新的数据类型后，也只要在 RedisObject 中设置好新类型的 type 和 encoding，再用*ptr指向新类型的实现，就行了。

开发一个新的数据类型

了解了 RedisObject 结构后，定义一个新的数据类型也就不难了。首先，我们需要为新数据类型定义好它的底层结构、type 和 encoding 属性值，然后再实现新数据类型的创建、释放函数和基本命令。接下来，我以开发一个名字叫作 NewTypeObject 的新数据类型为例，来解释下具体的 4 个操作步骤。

<img src="https://static001.geekbang.org/resource/image/88/99/88702464f8bc80ea11b26ab157926199.jpg" alt="img" style="zoom:25%;" />

#### 小结

这节课，我们学习了 Redis 的扩展数据类型 GEO。GEO 可以记录经纬度形式的地理位置信息，被广泛地应用在 LBS 服务中。GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。

GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是对二维地图做区间划分，以及对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。

GEO 属于 Redis 提供的扩展数据类型。扩展数据类型有两种实现途径：一种是基于现有的数据类型，通过数据编码或是实现新的操作的方式，来实现扩展数据类型，例如基于 Sorted Set 和 GeoHash 编码实现 GEO，以及基于 String 和位操作实现 Bitmap；另一种就是开发自定义的数据类型，具体的操作是增加新数据类型的定义，实现创建和释放函数，实现新数据类型支持的命令操作，建议你尝试着把今天学到的内容灵活地应用到你的工作场景中。



### 14 Redis 保存[时间序列](https://so.csdn.net/so/search?q=时间序列&spm=1001.2101.3001.7020)数据

#### 时间序列数据的读写特点

时间序列数据的“写要快”，Redis 的高性能写特性直接就可以满足了；
时间序列数据的“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，Redis 提供了保存时间序列数据的两种方案，分别可以基于Hash 和 Sorted Set 实现，以及基于 RedisTimeSeries 模块实现。

#### 基于 Hash 和 Sorted Set 保存时间序列数据

保证写入 Hash 和 Sorted Set 是一个原子性的操作的重要性：保证同一个时间序列数据，在 Hash 和 Sorted Set 中， 要么都保存了，要么都没保存。否则可能出现 Hash 集合中有时间序列数据，而 Sorted Set 中没有，进行范围查询时，没有办法满足查询需求了。

Redis 保证原子性的操作： **Redis 用来实现简单的事务的 MULTI 和 EXEC 命令。当多个命令及其参数本身无误时，MULTI 和 EXEC 命令可以保证执行这些命令时的原子性。**（语句有错、宕机都保证不了原子性；Pipeline可以一次发送多条命令，减少网络交互）

MULTI 命令：表示一系列原子性操作的开始。Redis收到这个命令，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。
EXEC 命令：表示一系列原子性操作的结束。Redis 收到了这个命令，表示所有要保证原子性的命令操作都已经发送完成了。Redis 开始执行刚才放到内部队列中的所有命令操作。
示意图，命令 1 到命令 N 是在 MULTI 命令后、EXEC 命令前发送的，它们会被一起执行，保证原子性：

<img src="https://img-blog.csdnimg.cn/ccaea10d078649bfb5c49836582e0f85.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

以保存设备状态信息的需求为例，我们执行下面的代码，把设备在 2020 年 8 月 3 日 9 时 5 分的温度，分别用 HSET 命令和 ZADD 命令写入 Hash 集合和 Sorted Set 集合。

```
127.0.0.1:6379> MULTI 
OK

127.0.0.1:6379> HSET device:temperature 202008030911 26.8 
QUEUED

127.0.0.1:6379> ZADD device:temperature 202008030911 26.8 
QUEUED   

127.0.0.1:6379> EXEC 
1) (integer) 1 
2) (integer) 1 
```

**Redis 收到了客户端执行的 MULTI 命令。客户端再执行 HSET 和 ZADD 命令后，Redis 返回的结果为“QUEUED”，表示这两个命令暂时入队，先不执行；执行了 EXEC 命令后，HSET 命令和 ZADD 命令才真正执行，并返回成功结果**（结果 值为 1）。

解决了时间序列数据的单点查询、范围查询问题，并使用 MUTLI 和 EXEC 命令保证了 Redis 能原子性地把数据保存到 Hash 和 Sorted Set 中。

#### 基于 RedisTimeSeries 模块保存时间序列数据

**RedisTimeSeries 是 Redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，支持在 Redis 实例上直接对数据进行按时间范围的聚合计算。**

RedisTimeSeries 不属于 Redis 的内建功能模块，使用时需要先把它的源码单独编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载，如下所示：

```
loadmodule redistimeseries.so
```

用于时间序列数据存取时，RedisTimeSeries 的操作主要有 5 个：

用 TS.CREATE 命令创建时间序列数据集合；
用 TS.ADD 命令插入数据；
用 TS.GET 命令读取最新数据；
用 TS.MGET 命令按标签过滤查询数据集合；
用 TS.RANGE 支持聚合计算的范围查询。

#### 总结

Redis 保存时间序列数据。时间序列数据的写入特点是要能快速写入，而查询的特点有三个：

**点查询**，根据一个时间戳，查询相应时间的数据；
**范围查询**，查询起始和截止时间戳范围内的数据；
**聚合计算**，针对起始和截止时间戳范围内的所有数据进行计算，例如求最大 / 最小值， 求均值等。

快速写入的要求，Redis 的高性能写特性足以应对了；
多样化的查询需求， Redis 提供了两种方案：

组合使用 Redis 内置的 Hash 和 Sorted Set 类型，把数据同时保存在 Hash 集合和 Sorted Set 集合中。既可以利用 Hash 类型实现对单键的快速查询，还能利用 Sorted Set 实现对范围查询的高效支持。 两个不足：

（1）在执行聚合计算时，需要把数据读取到客户端再进行聚合，当有大量数据要聚合时，数据传输开销大；

（2）所有的数据会在两个数据类型中各保存一份，内存开销不小。可以通过设置适当的数据过期时间，释放内存，减小内存压力。

RedisTimeSeries 模块专门为存取时间序列数据而设计的扩展模块。和第一种方案相比，RedisTimeSeries 直接在 Redis 实例上进行多种数据聚合计算，避免了大量数据在实例和客户端间传输。RedisTimeSeries 的底层数据结构使用了链表，范围查询的复杂度是 O(N) 级别的，它的 TS.GET 查询只能返回最新的数据，没有办法像第一种方案的 Hash 类型一样，可以返回任一时间点的数据。
组合使用 Hash 和 Sorted Set，或者使用 RedisTimeSeries，在支持时间序列数据存取上各有优劣势。建议：

* 如果你的部署环境中网络带宽高、Redis 实例内存大，可以优先考虑第一种方案；
* 如果部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案。



### 15 Redis 实现消息队列

以后当需要为分布式系统组件做消息队列选型时，可以根据组件通信量和消息通信速度的要求，选择出适合的 Redis 消息队列方案。

使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理。即使生产者发送消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势。

不过消息队列在存取消息时，必须要满足三个需求，分别是**消息保序**、**处理重复的消息**和**保证消息可靠性**。

#### 二、基于 List 的消息队列解决方案

**解决消息保序问题：**

List 本身就是按先进先出的顺序对数据进行存取的，使用 List 作为消息队列保存消息，已经能满足消息保序的需求了。

消费者读取数据时的性能风险：

在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP 命令（比如使用一个 while(1) 循 环）。如果有新消息写入，RPOP 命令就会返回结果，RPOP 命令返回空值，再继续循环。

即使没有新消息写入 List，消费者也要不停地调用 RPOP 命令，导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。

**Redis 提供了 BRPOP 命令。BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。**和消费者程序自己不停地调用 RPOP 命令相比，这种方式能节省 CPU 开销。

**解决重复消息处理的问题**要求：消费者程序本身能对重复消息进行判断。

1. 消息队列要能给每一个消息提供全局唯一的 ID 号；
2. 消费者程序要把已经处理过的消息的 ID 号记录下来。

**解决消息可靠性问题**：

消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。消费者程序在处理消息的过程出现了故障或宕机，会导致消息没有处理完成，消费者程序再次启动后，就没法再次从 List 中读取消息了。

**List 类型提供了 BRPOPLPUSH 命令：让消费者程序从 一个 List 中读取消息，Redis 会把这个消息再插入到另一个 List**（可以叫作备份 List）留存。消费者程序读了消息但没能正常处理，重启后可以从备份 List 中重新读取消息并进行处理了。

#### 二、基于 Streams 的消息队列解决方案

基于 List 类型满足分布式组件对消息队列的三大需求。用 List 做消息队列时可能遇到的一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。

**启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。 但是List 类型并不支持消费组的实现。**

**Redis 从 5.0 版本开始提供的 Streams 数据类型了。**

和 List 相比，Streams 同样能够满足消息队列的三大需求。还支持消费组形式的消息读取。

Streams 是 Redis 专门为消息队列设计的数据类型，提供了丰富的消息队列操作命令：

XADD：插入消息，保证有序，可以自动生成全局唯一 ID；
XREAD：用于读取消息，可以按 ID 读取数据；
XREADGROUP：按消费组形式读取消息；
XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息；
XACK 命令用于向消息队列确认消息处理已完成。

XADD 命令往消息队列中插入新消息，消息的格式是键 - 值对形式。对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。

**XREAD** 命令从消息队列中读取：

XREAD 在读取消息时可以指定一个消息 ID，从这个消息 ID 的下一条消息开始进行读取。消费者也可以在调用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。当消息队列中没有消息时设置了 block 配置项，XREAD 就会阻塞，阻塞的时长可以在 block 配置项进行设置。

```
XADD mqstream * repo 5 
"1599203861727-0" 
```

下面的命令最后的“$”符号表示读取最新的消息， 设置了 block 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。 

```
XREAD block 10000 streams mqstream $ 
(nil) 
(10.00s) 
```

这些操作是 List 也支持的， 下面是Streams 特有的功能：

Streams 使用 XGROUP 创建消费组，创建消费组之后，Streams 可以使用 XREADGROUP 命令让消费组内的消费者读取消息，执行下面的命令，创建一个名为 group1 的消费组，这个消费组消费的消息队列是 mqstream。

```
XGROUP create mqstream group1 0 
OK 
```

再执行一段命令，让 group1 消费组里的消费者 consumer1 从 mqstream 中读取所有消息，命令最后的参数“>”，表示从第一条尚未被消费的消息开始读取。 因为在 consumer1 读取消息前，group1 中没有其他消费者读取过消息，所以 consumer1 就得到 mqstream 消息队列中的所有消息了（一共 4 条）。

```
XREADGROUP group group1 consumer1 streams mqstream > 
```

消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。

为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。如果消费者没有成功处理消息，不会给 Streams 发送 XACK 命令，消息仍然会留存。消费者重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。

group2 中各个消费者已读取、但尚未确认的消息个数。其中， XPENDING 返回结果的第二、三行分别表示 group2 中所有消费者读取的消息最小 ID 和最大 ID。

```
XPENDING mqstream group2 
```

Streams 是 Redis 5.0 专门针对消息队列场景设计的数据类型，如果 Redis 是 5.0 及 5.0 以后的版本，就可以考虑把 Streams 用作消息队列了。

#### 总结

分布式系统组件使用消息队列时的三大需求：消息保序、重复消息处理和消息可靠性保证，

这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。

List 和 Streams 实现消息队列的特点和区别：

<img src="https://img-blog.csdnimg.cn/91c577bcde1e4b529e08ed7a85df7817.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

Redis 是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列就应该采用 Kafka、RabbitMQ 这些专门面向消息队列场景的软件，而 Redis 更加适合做缓存。

Redis 是一个非常轻量级的键值数据 库，部署一个 Redis 实例就是启动一个进程，部署 Redis 集群，也就是部署多个 Redis 实例。而 Kafka、RabbitMQ 部署时，涉及额外的组件，例如 Kafka 的运行就需要再部署 ZooKeeper。相比 Redis 来说，Kafka 和 RabbitMQ 一般被认为是重量级的消息队列。

所以**关于是否用 Redis 做消息队列的问题，不能一概而论，需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，Redis 只需要使用有限的内存空间就能满足消息存储的需求，Redis 的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案**。



### 16 Redis 的异步机制

命令操作、系统配置、关键机制、硬件配置等会影响 Redis 的性能，不仅要知道具体的机制，尽可能避免性能异常的情况出现，还要提前准备好应对异常的方案。

* Redis 内部的阻塞式操作；
* CPU 核和 NUMA 架构的影响；
* Redis 关键系统配置；
* Redis 内存碎片；
* Redis 缓冲区。

#### 一、Redis 的阻塞点

和 Redis 实例交互的对象，以及交互时会发生的操作：

**客户端**：网络 IO，键值对增删改查操作，数据库操作；
**磁盘**：生成 RDB 快照，记录 AOF 日志，AOF 日志重写；
**主从节点**：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件；
**切片集群实例**：向其他实例传输哈希槽信息，数据迁移。

4 类交互对象和具体的操作之间的关系：

<img src="https://img-blog.csdnimg.cn/0899bec0f27a48eda14eab0f0991c418.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

和客户端交互时的阻塞点：

 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以**网络 IO 不是导致 Redis 阻塞的因素**。

键值对的增删改查操作是 Redis 和客户端交互的主要部分，也是 Redis 主线程执行的主要任务。复杂度高的增删改查操作肯定会阻塞 Redis。

判断操作复杂度高低的标准：看操作的**复杂度是否为 O(N)**。

**Redis 的第一个阻塞点：集合全量查询和聚合操作。**

**Redis 的第二个阻塞点 :bigkey 删除操作**

集合自身的删除操作同样也有潜在的阻塞风险。删除操作的本质是要释放键值对占用的内存空间。 **释放内存**只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要**把释放掉的内存块插入一个空闲内存块的链表**，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。

释放大量内存的时机：在删除大量键值对数据的时候，删除包含了大量元素的集合，也称为 bigkey 删除。

**Redis 的第三个阻塞点：清空数据库**

既然频繁删除键值对都是潜在的阻塞点了，在 Redis 的数据库级别操作中，清空数据库（例如 FLUSHDB 和 FLUSHALL 操作）也是一个潜在的阻塞风险，因为它涉及到删除和释放所有的键值对。

**Redis 的第四个阻塞点：AOF 日志同步写**

磁盘 IO 一般都是比较费时费力的，需要重点关注。 Redis 开发者早已认识到磁盘 IO 会带来阻塞，所以**把 Redis 设计为采用子进程的方式生成 RDB 快照文件、执行 AOF 日志重写操作。由子进程负责执行，慢速的磁盘 IO 就不会阻塞主线程了。**

Redis 直接记录 AOF 日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话，会阻塞主线程。。

**Redis 的第五个阻塞点：从库加载 RDB 文件**

**切片集群实例交互时的阻塞点**

部署 Redis 切片集群时，每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过哈希槽的信息量不大，而数据迁移是渐进式执行的，这两类操作对 Redis 主线程的阻塞风险不大。

如果使用了 Redis Cluster 方案，而且同时**正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移**。当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程。

**五个阻塞点：**

- 集合全量查询和聚合操作；
- bigkey 删除；
- 清空数据库；
- AOF 日志同步写；
- 从库加载 RDB 文件。

#### 二、可以异步执行的阻塞点

为了避免阻塞式操作，Redis 提供了异步线程机制：Redis 会启动一些子线程，然后把一些任务交给这些子线程，让它们在后台完成，而不再由主线程来执行这些任务。可以避免阻塞主线程。

**异步执行对操作的要求：一个能被异步执行的操作并不是 Redis 主线程的关键路径上的操作**（客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作）。

主线程接收到操作 1 后，操作 1 并不用给客户端返回具体的数据，主线程可以把它交给后台子线程来完成，同时只要给客户端返回一个“OK”结果就行。在子线程执行操作 1 的时候，客户端又向 Redis 实例发送了操作 2，客户端是需要使用操作 2 返回的数据结果的，如果操作 2 不返回结果，那么客户端将一直处于等待状态。

**操作 1 就不算关键路径上的操作，因为它不用给客户端返回具体数据，所以可以由后台子线程异步执行。操作 2 需要把结果返回给客户端，它就是关键路径上的操作，所以主线程必须立即把这个操作执行完。**

Redis 读操作是典型的关键路径操作，因为客户端发送了读操作之后，就会等待读取的数据返回，以便进行后续的数据处理。而 Redis 的第一个阻塞点“集合全量查询 和聚合操作”都涉及到了读操作，不能进行异步操作。

删除操作并不需要给客户端返回具体的数据结果，不算是关键路径操作。“bigkey 删除”和“清空数据库”都是对数据做删除，并不在关键路径上。可以使用后台子线程来异步执行删除操作。

“AOF 日志同步写”，为了保证数据可靠性，Redis 实例需要保证 AOF 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以可以启动一个子线程来执行 AOF 日志的同步写。（**alway是主线程落盘**）

“从库加载 RDB 文件”要想对客户端提供数据存取服务，就必须把 RDB 文件加载完成。这个操作也属于关键路径上的操作，必须让从库的主线程来执行。

**除了“集合全量查询和聚合操作”和“从库加载 RDB 文 件”，其他三个阻塞点涉及的操作都不在关键路径上，可以使用 Redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 AOF 日志同步写。**

#### 三、异步的子线程机制

**Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，负责AOF 日志写操作、键值对删除、文件关闭的异步执行。**

**主线程通过一个链表形式的任务队列和子线程进行交互。**

当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。

**但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。**这种异步删除也称为**惰性删除 （lazy free）**。（主线程会把删除的key从hash表中删除，这样就找不到了，对应的value会在后台子线程进行释放和回收）

当 **AOF 日志配置成 everysec** 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，主线程就不用一直等待 AOF 日志写完了。

Redis 中的异步子线程执行机制：

<img src="https://img-blog.csdnimg.cn/c07c3d4aefe44a95826593707780a7ff.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

**异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能**，Redis 也提供了新的命令来执行这两个操作。

**键值对删除**：集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，**建议使用 UNLINK 命令**；

```
DEL key [key ...]
unlink key [key ...]

UNLINK key1 key2 key3
```

**清空数据库**：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，让后台子线程异步地清空数据库，如下所示：

```
FLUSHDB ASYNC 
FLUSHALL AYSNC 
```



查阅了lazy-free相关的源码，发现有很多细节需要补充下

1、lazy-free是4.0新增的功能，但是默认是关闭的，需要手动开启。 

2、手动开启lazy-free时，有4个选项可以控制，分别对应不同场景下，要不要开启异步释放内存机制：

 a) lazyfree-lazy-expire：key在过期删除时尝试异步释放内存 

b) lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存 

c) lazyfree-lazy-server-del：执行RENAME/MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存

d) replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存 3、即使开启了lazy-free，如果直接使用DEL命令还是会同步删除key，只有使用UNLINK命令才会可能异步删除key。 

4、这也是最关键的一点，上面提到开启lazy-free的场景，**除了replica-lazy-flush之外，其他情况都只是可能去异步释放key的内存，并不是每次必定异步释放内存的。** 开启lazy-free后，Redis在释放一个key的内存时，**首先会评估代价**，如果释放内存的代价很小，那么就直接在主线程中操作了，没必要放到异步线程中执行（不同线程传递数据也会有性能消耗）。 **什么情况才会真正异步释放内存？这和key的类型、编码方式、元素数量都有关系**（详细可参考源码中的lazyfreeGetFreeEffort函数）： 

a) 当Hash/Set底层采用哈希表存储（非ziplist/int编码存储）时，并且元素数量超过64个 

b) 当ZSet底层采用跳表存储（非ziplist编码存储）时，并且元素数量超过64个 

c) 当List链表节点数量超过64个（注意，不是元素数量，而是链表节点的数量，List的实现是在每个节点包含了若干个元素的数据，这些元素采用ziplist存储） 

只有以上这些情况，在删除key释放内存时，才会真正放到异步线程中执行，其他情况一律还是在主线程操作。 **也就是说String（不管内存占用多大）、List（少量元素）、Set（int编码存储）、Hash/ZSet（ziplist编码存储）这些情况下的key在释放内存时，依旧在主线程中操作。** 

可见，即使开启了lazy-free，String类型的bigkey，在删除时依旧有阻塞主线程的风险。所以，**即便Redis提供了lazy-free，我建议还是尽量不要在Redis中存储bigkey。** 

个人理解Redis在设计评估释放内存的代价时，不是看key的内存占用有多少，而是关注释放内存时的工作量有多大。从上面分析基本能看出，如果需要释放的内存是连续的，Redis作者认为释放内存的代价比较低，就放在主线程做。如果释放的内存不连续（大量指针类型的数据），这个代价就比较高，所以才会放在异步线程中去执行。

### 17 Redis 的性能受CPU结构影响

#### 一、主流的 CPU 架构

一个 CPU 处理器中一般有多个运行核心，把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称 L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称 L2 cache）。

物理核的私有缓存：**缓存空间只能被当前的这个物理核使用，其他的物理核无法对这个核的缓存空间进行数据存取**。

L1 和 L2 缓存是每个物理核私有的，当数据或指令保存在 L1、L2 缓存时，物理核访问它们的延迟不超过 10 纳秒，速度非常快。如果 Redis 把要运行的指令或存取的数据保存在 L1 和 L2 缓存的话，就能高速地访问这些指令和数据。

L1 和 L2 缓存的大小受限于处理器的制造技术，一般只有 KB 级别，存不下太多的数据。如果 L1、L2 缓存中没有所需的数据，应用程序就需要访问内存来获取数据。应用程序的访问内存延迟一般在百纳秒级别，是访问 L1、L2 缓存的延迟的近 10 倍，会对性能造成影响。

**不同的物理核还会共享一个共同的三级缓存**（Level 3 cache，简称为 L3 cache）。L3 缓存的存储资源比较多，几 MB 到几十 MB，让应用程序缓存更多的数据。当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。

主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。 同一个物理核的逻辑核会共享使用 L1、L2 缓存。

物理核和逻辑核，以及一级、二级缓存的关系：

<img src="https://img-blog.csdnimg.cn/f4ae28d148734d3b8bd22b4cf312e365.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

**多 CPU 架构，应用程序可以在不同的处理器上运行。**Redis 可以先在 Socket 1 上运行一段时间，然后再被调度到 Socket 2 上运行。

但是：如果应用程序先在一个 Socket 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。

**多 CPU 架构，应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，被称为：非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构）**。

主流的 CPU 多核架构和多 CPU 架构对应用程序运行的影响：

L1、L2 缓存中的指令和数据的访问速度很快，充分利用 L1、L2 缓存，可以缩短应用程序的执行时间；
**在 NUMA 架构下，应用程序从一个 Socket 上调度到另一个 Socket 上，会出现远端内存访问的情况，这会直接增加应用程序的执行时间。**

#### 二、CPU 多核对 Redis 性能的影响

在一个 CPU 核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、 CPU 核的寄存器值等），称为运行时信息。应用程序访问最频繁的指令和数据还会被缓存到 L1、L2 缓存上，以便提升执行速度。

**在多核 CPU 的场景下，一旦应用程序需要在一个新的 CPU 核上运行，运行时信息就需要重新加载到新的 CPU 核上。新的 CPU 核的 L1、L2 缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。**

CPU 多核的环境下**绑定 Redis 实例和 CPU 核**，可以降低 Redis 的尾延迟。绑核不仅对降低尾延迟有好处，也能降低平均延迟、提升吞吐率， 进而提升 Redis 性能。

#### 三、CPU 的 NUMA 架构对 Redis 性能的影响

用 Redis 时的经常做法：为了提升 Redis 的网络性能，把操作系统的网络中断处理程序和 CPU 核绑定。可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。

但是网络中断程序是要和 Redis 实例进行网络数据交互的，一旦把网络中断程序绑核后，要注意 Redis 实例是绑在哪个核上了，这会关系到 Redis 访问网络数据的效率高低。

Redis 实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过 epoll 机制触发事件通知 Redis 实例，Redis 实例再把数据从内核的内存缓冲区拷贝到自己的内存空间，如下图：

<img src="https://img-blog.csdnimg.cn/769fde0a31034d53bd89f7fa06b82256.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

CPU 的 NUMA 架构下，当网络中断处理程序、Redis 实例分别和 CPU 核绑定后的一个潜在的风险：**如果网络中断处理程序和 Redis 实例各自所绑的 CPU 核不在同一个 CPU Socket 上，Redis 实例读取网络数据时，需要跨 （走总线）CPU Socket 访问内存，会花费较多时间**。

<img src="https://img-blog.csdnimg.cn/f08a2c044cd14c09891813c0e73fc6a0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

为了避免 Redis 跨 CPU Socket 访问网络数据，把**网络中断程序和 Redis 实例绑在同一个 CPU Socket** 上，Redis 实例就可以直接从本地内存读取网络数据了，如下图：

<img src="https://img-blog.csdnimg.cn/e7b1dd1f2b6f47928dc58bb711f5de03.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:33%;" />

CPU 的 NUMA 架构对 CPU 逻辑核的编号规则，并不是先把一 个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号。

CPU 多核的场景下，用 taskset 命令把 Redis 实例和一个核绑定，可以减少 Redis 实例在不同核上被来回调度执行的开销，避免较高的尾延迟；

多 CPU 的 NUMA 架构下，把 Redis 实例和网络中断程序绑在同一个 CPU Socket 的不同核上，避免 Redis 跨 CPU Socket 访问内存中的网络数据的时间开销。

#### 四、绑核的风险和解决方案

Redis 除了主线程以外，还有用于 RDB 生成、 AOF 重写的子进程、用于惰性删除的后台线程。

Redis 实例绑到一个 CPU 逻辑核上时，就会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致 Redis 请求延迟增加。

**方案一：一个 Redis 实例对应绑一个物理核**

Redis 实例绑核时，**不把一个实例和一个逻辑核绑定，而要和一个物理核（同一个五里核的多个逻辑核）绑定**，把一个物理核的 2 个逻辑核都用上。

**方案二：优化 Redis 源码**

想进一步减少 CPU 竞争，通过修改 Redis 源码，把子进程和后台线程绑到不同的 CPU 核上。

#### 总结

多核 CPU 架构下，Redis 如果在不同的核上运行，就需要频繁地进行上下文切换，会增加 Redis 的执行时间，客户端也会观察到较高的尾延迟了。建议在 Redis 运行时，把实例和某个核绑定，能重复利用核上的 L1、L2 缓存，可以降低响应延迟。

**为了提升 Redis 的网络性能，会把网络中断处理程序和 CPU 核绑定。如果服务器使用的是 NUMA 架构，Redis 实例一旦被调度到和中断处理程序不在同 一个 CPU Socket，就要跨 CPU Socket 访问网络数据，降低 Redis 的性能。建议把 Redis 实例和网络中断处理程序绑在同一个 CPU Socket 下的不同核上，提升 Redis 的运行性能。**

除了主线程，Redis 还有用于 RDB 和 AOF 重写的子进程，以及 4.0 版本之后提供的用于惰性删除的后台线程。Redis 实例和一个逻辑核绑定后，这些子进程和后台线程会和主线程竞争 CPU 资源，也会对 Redis 性能造成影响。建议：

* 把按一个 Redis 实例一个物理核方式进行绑定，Redis 的主线程、子进程和后台线程可以共享使用一个物理核上的两个逻辑核。
* 在源码中增加绑核操作，把子进程和后台线程绑到不同的核上，避免对主线程的 CPU 资源竞争。Redis 6.0 支持 CPU 核绑定的配置操作了。



### 18 Redis 自身操作特性对性能的影响

#### 一、Redis 变慢的判定方法

**查看 Redis 的响应延迟**： 大部分时候，Redis 延迟很低，但是在某些时刻，有些 Redis 实例会出现很高的响应延 迟，甚至能达到几秒到十几秒，不过持续时间不长，这也叫延迟“毛刺”。发现 Redis 命令的执行时间突然就增长到了几秒，基本就可以认定 Redis 变慢了。

这种方法是**看 Redis 延迟的绝对值**，但是在不同的软硬件环境下，Redis 本身的绝对性能并不相同。比如，在我的环境中，延迟为 1ms 时判定 Redis 变慢了，但是你的硬件配置高，在你的运行环境下，延迟是 0.2ms 的时就可以认定 Redis 变 慢了。

**基于当前环境下的 Redis 基线性能做判断**： 基线性能指的是一个系统在低压力、无干扰下的基本性能，只由当前的软硬件配置决定。

确定基线性能的方法：从 2.8.7 版本开始，redis-cli 命令提供了–intrinsic-latency 选项，用来监测和统计测试期间内的最大延迟，这个延迟可以作为 Redis 的基线性能。测试时长可以用–intrinsic-latency 选项的参数来指定。

**基线性能和当前的操作系统、硬件配置相关。把它和 Redis 运行时的延迟结合起来，进一步判断 Redis 性能是否变慢了。 把运行时延迟和基线性能进行对比，如果观察到的 Redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了。**

为了避免网络对基线性能的影响， 这个命令需要在服务器端直接运行，只考虑服务器端软硬件环境的影响。

如果想了解网络对 Redis 性能的影响，用 iPerf 这样的工具测量从 Redis 客户端到服务器端的网络延迟。延迟有几十毫秒甚至是几百毫秒，Redis 运行的网络环境中很可能有大流量的其他应用程序在运行，导致网络拥塞了。需要协调网络运维，调整网络的流量分配了。

#### 二、Redis 变慢的应对方法

要基于对 Redis 本身的工作原理的理解，并且结合和它交互的操作系统、存储以及网络等外部系统关键机制，再借助一些辅助工具来定位原因，并制定行之有效的解决方案。

红色模块影响 Redis 性能的三大要素： **Redis 自身的操作特性、文件系统和操作系统。**

<img src="https://img-blog.csdnimg.cn/ef836d2c5d764631908d804bc26c24f6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:15%;" />



#### 三、Redis 自身操作特性的影响

Redis 提供的键值对命令操作对延迟性能的影响。**两类关键操作：慢查询命令和过期 key 操作**。

**慢查询命令**：指在 Redis 中执行速度慢的命令，导致 Redis 延迟增加。并不是所有命令都慢，这和命令操作的复杂度有关。

Redis 的不同命令的复杂度：Value 类型为 String 时，GET/SET 操作主要就是操作 Redis 的哈希表索引。操作复杂度基本是固定的 O(1)。 Value 类型为 Set 时，SORT、 SUNION/SMEMBERS 操作复杂度分别为 O(N+M*log(M)) 和 O(N)。N 为 Set 中 的元素个数，M 为 SORT 操作返回的元素个数。复杂度就增加了很多。

Redis 官方文档中对每个命令的复杂度都有介绍，需要了解某个命令的复杂度时，可以直接查询。 **Redis 性能变慢时，通过 Redis 日志或者是 latency monitor 工具，查询变慢的请求**，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。

大量的慢查询命令的两种处理方式：

* 用其他高效命令代替。需要返回一个 SET 中的所有成员时，不使用 SMEMBERS 命令，**使用 SSCAN 多次迭代返回**，避免一次返回大量数据，造成线程阻塞。
* **要执行排序、交集、并集操作时，可以在客户端完成**，不要用 SORT、 SUNION、SINTER 这些命令，以免拖慢 Redis 实例。

**业务逻辑要求使用慢查询命令，得考虑采用性能更好的 CPU，更快地完成查询命令，避免慢查询的影响。**

还有一个比较容易忽略的慢查询命令KEYS。

**过期 key 的自动删除机制**： Redis 用来回收内存空间的常用机制，本身就会引起 Redis 操作阻塞，导致性能变慢，该机制对性能有影响。

Redis 键值对的 key 可以设置过期时间。默认 Redis 每 100 毫秒会删除一些过期 key，算法如下：

* 采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；
* 如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以 下。

**ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 是 Redis 的一个参数，默认是 20**，一秒内基本有 200 个过期 key 会被删除。对清除过期 key、释放内存空间很有帮助。每秒钟删除 200 个过期 key，并不会对 Redis 造成太大影响。

触发了上面这个算法的第二条，Redis 就会一直删除以释放内存空间。删除操作是阻塞的（Redis 4.0 后可以用异步线程机制来减少阻塞影响）。**一旦该条件触发，Redis 的线程就会一直执行删除，就没办法正常服务其他的键值操作了**，就会进一步引起其他键值操作的延迟增加，Redis 就会变慢。

算法的第二条被触发的来源是频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key，会导致在同一秒内有大量的 key 同时过期。

建议和解决方法： 检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有**使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。这会造成大量 key 在同一时间过期，导致性能变慢**。

要根据实际业务的使用需求，决定 EXPIREAT 和 EXPIRE 的过期时间参数。如果一批 key 的确是同时过期，可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。

#### 总结

Redis 性能变慢带来的重要影响。

**判断 Redis 变慢的方法，一个是看响应延迟，一个是看基线性能。**

两种排查和解决 Redis 变慢的方法：

* 从慢查询命令开始排查，并且根据业务需求替换慢查询命令；

* 排查过期 key 的时间设置，并根据实际使用需求，设置不同的过期时间。

  

6.留言区收获 

1.在生产环境中，可以使用scan替代keys命令（答案来自@kaito 大佬） 	当scan在Redis在做Rehash时，会不会漏key或返回重复的key？ 

* 1.不漏keys：Redis在SCAN遍历全局哈希表时，采用**高位进位法**的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。 		https://blog.csdn.net/u014439693/article/details/108325632
* 2.key重复：这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。处理方法是在客户端直接做重复过滤 

2.在redis-cluster中，不能使用一次scan在整个集群中获取所有的key，只能通过在每个实例上单独执行scan才可以，再到客户端进行合并	

### 19 Redis 的文件系统和操作系统对性能的影响

#### 前言

**在排查时发现 Redis 没有执行大量的慢查询命令，也没有同时删除大量过期 keys，这就要关注影响性能的文件系统和操作系统。**

Redis 会持久化保存数据到磁盘，要依赖文件系统来完成，**文件系统将数据写回磁盘的机制，会直接影响到 Redis 持久化的效率**。在持久化的过程中，Redis 也还在接收其他请求，持久化的效率高低又会影响到 Redis 处理请求的性能。

Redis 是内存数据库，内存操作非常频繁，**操作系统的内存机制会直接影响到 Redis 的处理效率。Redis 的内存不够用了，操作系统会启动 swap 机制，这就会直接拖慢 Redis。**

#### 一、文件系统：AOF 模式

Redis 会采用 AOF 日志或 RDB 快照。AOF 日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的 write 和 fsync两个系统调用完成。

write 只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；而 fsync 需要把日志记录写回到磁盘后才能返回，时间较长。三种写回策略所执行的系统调用。

<img src="https://img-blog.csdnimg.cn/949b21a0fc3d410d873e4dd6b14223b7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

当写回策略配置为 everysec 和 always 时，Redis 需要调用 fsync 把日志写回磁盘。这两种写回策略的具体执行情况还不太一样。

* everysec ：Redis 允许丢失一秒的操作记录，Redis 主线程并不需要确保每个操作记录日志都写回磁盘。而且fsync 的执行时间很长，在 Redis 主线程中执行 fsync容易阻塞主线程。**当写回策略配置为 everysec 时，Redis 会使用后台的子线程异步完成 fsync 的操作。**
* always：Redis 需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时地知道每个操作是否已经完成了。**always 策略不使用后台子线程来执行**。

使用 AOF 日志时，为了避免日志文件不断增大，Redis 会执行 AOF 重写，生成体量缩小的新的 AOF 日志文件。AOF 重写本身需要的时间很长，也容易阻塞 Redis 主线程，所以**Redis 使用子进程来进行 AOF 重写**。

潜在的风险点：AOF 重写会对磁盘进行大量 IO 操作，fsync 又需要等到数据写到磁盘后才能返回，当 AOF 重写的压力比较大时，会导致 fsync 被阻塞。**虽然 fsync 是由后台子线程负责执行的，但是主线程会监控 fsync 的执行进度。** 当主线程使用后台子线程执行了一次 fsync，需要再次把新接收的操作记录写回磁盘时，**主线程发现上一次的 fsync 还没有执行完会阻塞**。**所以后台子线程执行的 fsync 频繁阻塞的话（比如 AOF 重写占用了大量的磁盘 IO 带宽），主线程也会阻塞，导致 Redis 性能变慢。**

<img src="https://img-blog.csdnimg.cn/f63ed0a7ce764e388347243a94c98a62.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

fsync 后台子线程和 AOF 重写子进程的存在，主 IO 线程一般不会被阻塞。如果在重写日志时，AOF 重写子进程的写入量比较大， fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。

排查和解决建议：
检查下 Redis 配置文件中的 appendfsync 配置项： Redis 实例使用的是哪种 AOF 日志写回策略。

高速固态盘的带宽和并发度比传统的机械硬盘的要高出 10 倍及以上。在 AOF 重写和 fsync 后台线程同时执行时，固态硬盘可以提供较为充足的磁盘 IO 资源，让 AOF 重写和 fsync 后台线程的磁盘 IO 资源竞争减少，从而降低对 Redis 的性能影响。

#### 二、操作系统：内存 swap

**内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，性能都会受到慢速磁盘读写的影响。**

Redis 是内存数据库，内存使用量大，如果没有控制好内存的使用量，或者和其他内存需求大的应用一起运行了，可能受到 swap 的影响，而导致性能变慢。

正常情况下 Redis 的操作是直接通过访问内存就能完成，一旦 swap 被触发了，Redis 的请求操作需要等到磁盘数据读写完成才行。和AOF 日志文件读写使用 fsync 线程不同，**swap 触发后影响的是 Redis 主 IO 线程，会极大地增加 Redis 的响应时间。**

触发 swap 的条件： 触发 swap 的原因主要是物理机器内存不足， Redis有两种常见的情况：

* Redis 实例自身使用了大量的内存，导致**物理机器的可用内存不足**；
* 和 Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致**分配给 Redis 实例的内存量变少**，进而触发 Redis 发生 swap。

解决思路：**增加机器的内存或者使用 Redis 集群。**

当出现百 MB，甚至 GB 级别的 swap 大小时，表明此时 Redis 实例的内存压力很大，很有可能会变慢。**swap 的大小是排查 Redis 性能变慢是否由 swap 引起的重要指标**。

发生内存 swap，最直接的解决方法是增加机器内存。如果该实例在一个 Redis 切片集群中，可以增加 Redis 集群的实例个数，来分摊每个实例服务的数据量，进而减少每个实例所需的内存量。

#### 三、操作系统：内存大页

**内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。** Linux 内核从 2.6.38 开始支持内存大页机制，**该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。**

系统的设计通常是一个取舍过程，称之为 trade-off。很多机制通常都是优势和劣势并存的。虽然**内存大页可以给 Redis 带来内存分配方面的收益**，但是 Redis 为了数据可靠性，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以 Redis 主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。**过程中 Redis 就会采用写时复制机制，一旦有数据要被修改，Redis 并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。**

如果采用了内存大页，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝 2MB 的大页。如果是常规内存页机制，只用拷贝 4KB。两者相比，**当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 Redis 正常的访存操作，最终导致性能变慢。**

关闭内存大页，首先要先排查下内存大页。方法是：在 Redis 实例运行的机器上执行如下命令:

```c
cat /sys/kernel/mm/transparent_hugepage/enabled
1
```

- always 表明内存大页机制被启动了；
- never表示内存大页机制被禁止

在实际生产环境中部署时，不要使用内存大页机制，执行下面的命令：

```在实际生产环境中部署时，不要使用内存大页机制，执行下面的命令：
echo never /sys/kernel/mm/transparent_hugepage/enabled
```

#### 总结

遇到 Redis 性能变慢时 9 个检查点的 Checklist：

1. 获取 Redis 实例在当前环境下的基线性能。
2. 是否用了慢查询命令？是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。
3. 是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。
4. 是否存在 bigkey？ 对于 bigkey 的删除操作，如果 Redis 是 4.0 及以上的版本， 直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，使用 SCAN 命令迭代删除， bigkey 的集合查询和聚合操作，使用 SCAN 命令在客户端完成。
5. Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果需要高性能，也允许数据丢失，将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。
6. Redis 实例的内存使用是否过大？发生 swap 了吗？是的话，增加机器内存或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。要避免出现 Redis 和其他内存需求大的应用共享机器的情况。
7. 在 Redis 实例的运行环境中，是否启用了透明大页机制？是的话，关闭内存大页机制。
8. 是否运行了 Redis 主从集群？是的话，把主库实例的数据量大小控制在 2~4GB， 以免主从复制时，从库因加载大的 RDB 文件而阻塞。
9. 是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，给 Redis 实例绑定物理核；使用 NUMA 架构时，把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。

影响系统性能的因素还有很多，遇到了特殊情况，Redis 所在的机器上有没有一些其他占内存、磁盘 IO 和网络 IO 的程序，比如说数据库程序或者数据采集程序。有的话，将这些程序迁移到其他机器上运行。



### 20 Redis 的内存空间存储效率问题

做了数据删除，数据量已经不大了，使用 top 命令查看时还会发现 Redis 占用了很多内存。这是**因为当数据删除后，Redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以操作系统仍然会记录着给 Redis 分配了大量内存**。

**潜在的风险点：Redis 释放的内存空间可能并不是连续的，这些不连续的内存空间很有可能处于一种闲置的状态。导致一个问题：虽然有空闲空间，Redis 却无法用来保存数据，不仅会减少 Redis 能够实际保存的数据量，还会降低 Redis 运行机器的成本回报率。**

#### 一、内存碎片

虽然操作系统的剩余内存空间总量足够，但是应用申请的是一块连续地址空间的 N 字节，但在剩余的内存空间中，没有大小为 N 字节的连续空间了，这些剩余空间就是内存碎片。

#### 二、内存碎片形成的原因

**内因是操作系统的内存分配机制，外因是 Redis 的负载特征。**

**内因：内存分配器的分配策略**

**内存分配器的分配策略决定了操作系统无法做到“按需分配”。**因为内存分配器一般是按**固定大小**来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。

**Redis 默认使用 jemalloc 内存分配器来分配内存**。jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字 节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。

是为了减少分配次数。例如，Redis 申请一个 20 字节的空间保存数据，jemalloc 就会分配 32 字节，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了，因为刚才分配的 32 字节已经够用了，这就避免了一次分配操作。

但是 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 Redis 的外因了。

**外因：键值对大小不一样和删改操作**

Redis 作为共用的缓存系统或键值数据库对外提供服务，所以不同业务应用的数据都可能保存在 Redis 中，带来不同大小的键值对。Redis 申请内存空间分配时，本身就会有大小不一的空间需求。这是第一个外因。

**内存分配器只能按固定大小分配内存，所以分配的内存空间一般都会比申请的空间大一些，不会完全一致，会造成一定的碎片，降低内存空间存储效率。**

第二个外因是，这些**键值对会被修改和删除，导致空间的扩容和释放**。

- 修改后的键值对变大或变小了，需要占用额外的空间或者释放不用的空间。
- 删除的键值对就不再需要内存空间了，会把空间释放出来，形成空闲空间。

<img src="https://img-blog.csdnimg.cn/b5dee3ecf305457d95d3f0989734cafc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

内存分配器策略是内因， Redis 的负载属于外因，包括了大小不一的键值对和键值对修改删除带来的内存空间变化。

#### 三、判断是否有内存碎片的方法

Redis 是内存数据库，内存利用率的高低直接关系到 Redis 运行效率的高低。Redis 的 INFO 命令，可以用来查询内存使用的详细信息，命令如下：

```
INFO memory 

Memory 

used_memory:1073741736 
used_memory_human:1024.00M 
used_memory_rss:1997159792 
used_memory_rss_human:1.86G 
… 
mem_fragmentation_ratio:1.86 
```

mem_fragmentation_ratio 表示的就是 Redis 当前的内存碎片率。碎片率计算规则是上面的命令中的两个指标 used_memory_rss 和 used_memory 相除的结果。

```
mem_fragmentation_ratio = used_memory_rss / used_memory
内存碎片率 = 操作系统实际分配给 Redis 的物理内存空间 / Redis 为了保存数据实际申请使用的空间
```

经验阈值：

- **mem_fragmentation_ratio 大于 1 但小于 1.5是合理的。**因为那些因素是难以避免的。内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；外因由 Redis 负载决定，也无法限制。所以存在内存碎片也是正常的。
- mem_fragmentation_ratio 大于 1.5 表明内存碎片率已经超过了 50%。需要采取一些措施来降低内存碎片率了。

#### 四、清理内存碎片的方法

**Redis 发生内存碎片，“简单粗暴”的方法是重启 Redis 实例**。这并不是一个“优雅”的方法，重启 Redis 会带来两个后果：

如果 Redis 中的数据没有持久化，数据就会丢失；
即使 Redis 数据持久化了，还需要通过 AOF 或 RDB 进行恢复，恢复时长取决于 AOF 或 RDB 的大小，如果只有一个 Redis 实例，恢复阶段无法提供服务。
**从 4.0-RC3 版本以后，Redis 自身提供了一种内存碎片自动清理的方法**。**内存碎片清理就是“搬家让位，合并空间”**。

<img src="https://img-blog.csdnimg.cn/252cf4760b2a4d139fa3246ea3791159.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:25%;" />

**碎片清理是有代价的，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。**Redis 是单线程，**在数据拷贝时，Redis 只能等着，这就导致 Redis 无法及时处理请求，性能就会降低**。数据拷贝还需要注意顺序，操作系统需要先拷贝 D，并释放 D 的空间后，才能拷贝 B。这种对顺序性的要求，会进一步增加 Redis 的等待时间，导致性能降低。

通过设置参数来控制碎片清理的开始和结束时机，以及占用的 CPU 比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。

Redis 启用自动内存碎片清理，把 activedefrag 配置项设置为 yes，命令如下：

```
config set activedefrag yes
```

同时满足这两个条件开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。

同时满足这两个条件开始清理。**在清理的过程中，只要有一个条件不满足了，就停止自动清理**。

* active-defrag-ignore-bytes 100mb：表示**内存碎片的字节数达到 100MB** 时，开始清理；
* active-defrag-threshold-lower 10：表示**内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10%** 时，开始清理。

为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间。

* active-defrag-cycle-min 25： 表示**自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展**；
* active-defrag-cycle-max 75：表示**自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过就停止清理**，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。

自动内存碎片清理机制在控制碎片清理启停的时机上，既考虑了碎片的空间占比、对 Redis 内存使用效率的影响，还考虑了清理机制本身的 CPU 时间占比、对 Redis 性能的影响。而且清理机制还提供了 4 个参数，可以根据实际应用中的数据量需求和性能要求灵活使用。

#### 总结

Redis 的内存空间效率问题，关键技术点是要识别和处理内存碎片：

1. info memory 命令是一个好工具，查看碎片率的情况；
2. 碎片率阈值是一个好经验，有效地判断是否要进行碎片清理了；
3. 内存碎片自动清理是一个好方法，避免因为碎片导致 Redis 的内存实际利用率降低，提升成本收益率。

Redis 的内存碎片自动清理涉及内存拷贝是个潜在的风险。如果在实践过程中遇到 Redis 性能变慢，通过日志看下是否正在进行碎片清理。如果 Redis 正在清理碎片，调小 active-defrag-cycle- max 的值，以减轻对正常请求处理的影响。



### 21 Redis 缓冲区的用法

缓冲区的功能是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。缓冲区占用的内存超出了设定的上限阈值时，会出现缓冲区溢出。如果发生了溢出，会丢数据了。随着累积的数据越来越多，缓冲区占用内存空间越来越大，一旦耗尽了 Redis 实 例所在机器的可用内存，就会导致 Redis 实例崩溃。

**缓冲区是用来避免请求或数据丢失**，只有用对了，才能真正起到“避免”的作用。

Redis 是典型的 client-server 架构，所有的操作命令都需要通过客户端发送给服务器端。

缓冲区在 Redis 中主要应用场景：

是在客户端和服务器端之间进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。
是在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据。

#### 一、客户端输入和输出缓冲区

为了避免客户端和服务器端的请求发送和处理速度不匹配，**服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，称之为客户端输入缓冲区和输出缓冲区。**

输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端，如下图：

<img src="https://img-blog.csdnimg.cn/b5fd0684f52d477d83b045f15446ce12.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom: 25%;" />



#### 二、输入缓冲区溢出的应对方法

输入缓冲区就是用来暂存客户端发送的请求命令，导致溢出的情况主要是下面两种：

**写入了 bigkey**，比如一下子写入了多个百万级别的集合类型数据；
**服务器端处理请求的速度过慢**，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。

要查看和服务器端相连的每个客户端对输入缓冲区的使用情况，使用 CLIENT LIST 命令：

```
CLIENT LIST 
id=3147836 addr=10.255.0.2:40168 fd=63 name= age=5013 idle=1009 flags=N db=13 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=hexists
```

CLIENT 命令返回的信息虽然很多，但只需要重点关注两类信息就可以：

1. 与服务器端连接的客户端的信息。不同客户端的 IP 和端口号。
2. 与输入缓冲区相关的三个参数：
   cmd，表示客户端最新执行的命令。
   qbuf，表示输入缓冲区已经使用的大小。
   qbuf-free，表示输入缓冲区尚未使用的大小。

CLIENT LIST 命令可以通过输出结果来判断客户端输入缓冲区的内存占用情况。如果 qbuf 很大，而同时 qbuf-free 很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。

**Redis 的客户端输入缓冲区大小的上限阈值，在代码中就设定为了 1GB。**Redis 服务器端允许**为每个客户端最多暂存 1GB 的命令**和数据。1GB 的大小，对于一般的生产环 境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了； 另一方面，如果再大的话 Redis 就有可能因为客户端占用了过多的内存资源而崩溃。

所以，Redis 并没有提供参数调节客户端输入缓冲区的大小。如果要避免输入缓冲区溢出，就只能从数据命令的发送和处理速度入手，也就是前面提到的避免客户端写入 bigkey，以及避免 Redis 主线程阻塞。

#### 三、输出缓冲区溢出的应对方法

Redis 的输出缓冲区暂存的是 Redis 主线程要返回给客户端的数据。主线程返回给客户端的数据，既有简单且大小固定的 OK 响应（例如，执行 SET 命令）或报错信息，也有大小不固定的、包含具体数据的执行结果（例如，执行 HGET 命令）。

Redis 为每个客户端设置的输出缓冲区也包括两部分：

* 一个大小为 16KB 的固定缓冲空间，用来暂存 OK 响应和出错信息；
* 一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果。

发生输出缓冲区溢出的三种情况：

* **服务器端返回 bigkey 的大量结果；**
* **执行了 MONITOR 命令；**
* **缓冲区大小设置得不合理**。

bigkey 原本就会占用大量的内存空间，所以服务器端返回的结果包含 bigkey，必然会影响输出缓冲区。

**MONITOR 命令是用来监测 Redis 执行的**。执行这个命令之后，会持续输出监测到的各个命令操作。MONITOR 的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出。建议 MONITOR 命令主要用在调试环境中，不要在线上生产环境中持续使用 MONITOR。如果在线上环境中偶尔使用 MONITOR 检查 Redis 的命令执行情况是没问题的。

输出缓冲区大小设置的问题和输入缓冲区不同，**通过 client- output-buffer-limit 配置项来设置缓冲区的大小**。设置的内容包括两方面：

1. **设置缓冲区大小的上限阈值；**
2. **设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。**

在具体使用 client-output-buffer-limit 来设置缓冲区大小的时候，需要先区分下客户端的类型。

两类客户端和 Redis 服务器端交互：

1. 常规和 Redis 服务器端进行读写命令交互的普通客户端；
2. 订阅了 Redis 频道的订阅客户端。
3. 在 Redis 主从集群中，主节点上也有一类客户端（从节点客户端）用来和从节点进行数据同步。

给普通客户端设置缓冲区大小时，在 Redis 配置文件中进行这样的设置：

```
client-output-buffer-limit normal 0 0 0
```

normal 表示当前设置的是普通客户端，第 1 个 0 设置的是缓冲区大小限制，第 2 个 0 和第 3 个 0 分别表示缓冲区持续写入量限制和持续写入时间限制。

普通客户端每发送完一个请求，会等到请求结果返回后，再发送下一个请求，这种发送方式称为阻塞式发送。如果不是读取体量特别大的 bigkey， 服务器端的输出缓冲区一般不会被阻塞的。 所以通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限 制都设置为 0，也就是不做限制。

订阅客户端一旦订阅的 Redis 频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。如果频道消息较多的话，也会占用较多的输出缓冲区空间。 因此给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制，在 Redis 配置文件中设置：

```
client-output-buffer-limit pubsub 8mb 2mb 60
```


pubsub 参数表示当前是对订阅客户端进行设置；8mb 表示输出缓冲区的大小上限为 8MB，一旦实际占用的缓冲区大小要超过 8MB，服务器端就会直接关闭客户端的连接；2mb 和 60 表示连续 60 秒内对输出缓冲区的写入量超过 2MB 的话，服务器端也会关闭客户端连接。

**总结下如何应对输出缓冲区溢出：**

1. **避免 bigkey 操作返回大量数据结果；**

2. **避免在线上环境中持续使用 MONITOR 命令。**

3. **使用 client-output-buffer-limit 设置合理的缓冲区大小上限，或是缓冲区连续写入时 间和写入量上限。**

   

#### 四、主从集群中的缓冲区

主从集群间的数据复制包括全量复制和增量复制两种。

**复制缓冲区的溢出问题**

全量复制过程主节点在向从节点传输 RDB 文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等 RDB 文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。

复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。避免复制缓冲区发生溢出：

1. 控制主节点保存的数据量大小。把主节点的数据量控制在 2~4GB，让全量同步执行得更快些，避免复制缓冲区累积过多命令。
2. 使用 client-output-buffer-limit 配置项，来设置合理的复制缓冲区大小。设置的依据是主节点的数据量大小、主节点的写负载压力和主节点本身的内存大小。

在主节点执行如下命令：

```
config set client-output-buffer-limit slave 512mb 128mb 60
```

复制缓冲区还会遇到一个问题：主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。

**总结：为了避免复制缓冲区累积过多命令造成溢出，引发全量复制失败，控制主节点保存的数据量大小，并设置合理的复制缓冲区大小。 同时需要控制从节点的数量，来避免主节点中复制缓冲区占用过多内存的问题**。

**复制积压缓冲区的溢出问题**

增量复制使用的缓冲区称为复制积压缓冲区。**复制积压缓冲区的英文名字 repl_backlog_buffer**。从缓冲区溢出的角度再来回顾下两个重点：复制积压缓冲区溢出的影响，以及如何应对复制积压缓冲区的溢出问题。

1. **复制积压缓冲区是一个大小有限的环形缓冲区。**当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制。
2. 为了应对复制积压缓冲区的溢出问题，**调整复制积压缓冲区的大小**，设置 repl_backlog_size 这个参数的值。

#### 总结

从缓冲区溢出对 Redis 的影响的角度，把这四个缓冲区分成两类做个总结：

**缓冲区溢出导致网络连接关闭**：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 Redis 客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。
**缓冲区溢出导致命令数据丢失**：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。
缓冲区溢出的三个原因：

* 命令数据发送过快过大；
* 命令数据处理较慢；
* 缓冲区空间过小。

缓冲区溢出的三个应对策略：

1. 针对命令数据发送过快过大的问题，对于普通客户端来说可以**避免 bigkey**，而对于复制缓冲区来说，就是**避免过大的 RDB 文件**。
2. 针对命令数据处理较慢的问题，解决方案就是**减少 Redis 主线程上的阻塞操作**，例如使用异步的删除操作。
3. 针对缓冲区空间过小的问题，解决方案就是**使用 client-output-buffer-limit 配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小**。输入缓冲区的大小默认是固定的，无法通过配置来修改它，除非直接去修改 Redis 源码。

