## Redis



优点：读写性能优异，支持持久化，支持事务（redisconntion、lua），数据结构丰富，支持主从/集群

缺点：容量受限，灾备恢复较差



项目用上： 存储字典、单号递增、@Cacheable存储数据、存储token、分布式锁

String:单号递增、token、分布式锁、@Cacheable

SET：判断这个人有没有出过团

HASH:存取字典key、value

Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求

| 数据类型 | 可以存储的值           | 操作                                                         |
| -------- | ---------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 |
| LIST     | 列表                   | 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 |
| SET      | 无序集合               | 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 |
| ZSET     | 有序集合               | 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 |



Redis 提供了RDB和AOF两种持久化方式。默认是只开启RDB，当Redis重启时，它会优先使用AOF文件来还原数据集。

**RDB持久化（快照持久化）**

RDB持久化：将某个节点的所有数据都保存在硬盘上。

创建快照的几种方式：

1.save命令:快照创建完毕之前不会再响应任何其他命令。

2.bgsave命令:开辟子进程去处理，主线程去处理命令请求

3.主从复制

4.shutdown：执行一个SAVE命令，阻塞所有客户端，不再执行客户端发送的任何命令，并在SAVE命令执行完毕之后关闭服务器

**如果系统真的发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于即使丢失一部分数据也不会造成一些大问题的应用程序。不能接受这个缺点的话，可以考虑AOF持久化。**

**AOF持久化**

AOF持久化：将写命令添加到AOF文件的末尾

与快照持久化相比，**AOF持久化的实时性更好**，因此已成为主流的持久化方案。

在Redis的配置文件中存在三种同步方式

|   选项   |                  同步频率                   |
| :------: | :-----------------------------------------: |
|  always  | 每个写命令都同步，这样会严重降低Redis的速度 |
| everysec |                每秒同步一次                 |
|    no    |          让操作系统来决定何时同步           |

重写/压缩AOF
AOF虽然在某个角度可以将数据丢失降低到最小而且对性能影响也很小，但是极端的情况下，体积不断增大的AOF文件很可能会用完硬盘空间。另外，如果AOF体积过大，那么还原操作执行时间就可能会非常长。

为了解决AOF体积过大的问题，**用户可以向Redis发送 BGREWRITEAOF命令 ，这个命令会通过移除AOF文件中的冗余命令来重写（rewrite）AOF文件来减小AOF文件的体积**。

Redis 4.0 对持久化机制的优化
Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性较差。



#### 缓存雪崩

缓存雪崩：指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。

**解决方案**

1. **过期时间打散。**缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. **加互斥锁**。一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
3. **热点数据不过期**。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。



关于互斥锁的选择，网上看到的大部分文章都是选择 Redis 分布式锁，因为这个可以保证只有一个请求会走到数据库，这是一种思路。

但是其实仔细想想的话，这边其实没有必要保证只有一个请求走到数据库，只要保证走到数据库的请求能大大降低即可，所以还有另一个思路是 JVM 锁。

JVM 锁保证了在单台服务器上只有一个请求走到数据库，通常来说已经足够保证数据库的压力大大降低，同时在性能上比分布式锁更好。

需要注意的是，无论是使用“分布式锁”，还是“JVM 锁”，加锁时要按 key 维度去加锁。

我看网上很多文章都是使用一个“固定的 key”加锁，这样会导致不同的 key 之间也会互相阻塞，造成性能严重损耗。






#### 缓存穿透

缓存穿透：指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

**解决方案**

1. **接口层增加校验**。如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. **缓存空值**。从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
3. **布隆过滤器**。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库。



**布隆过滤器的特点是判断不存在的，则一定不存在；判断存在的，大概率存在，但也有小概率不存在。**并且这个概率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。

布隆过滤器由一个 bitSet 和 一组 Hash 函数（算法）组成，是一种空间效率极高的概率型算法和数据结构，主要用来判断一个元素是否在集合中存在。



#### 缓存击穿

缓存击穿：指缓存中没有但数据库中有的数据（一般是缓存时间到期）。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

**解决方案**

1. 设置热点数据永远不过期。
2. 加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。



#### redis过期键淘汰策略

1.立即删除  

2.定时删除

3.惰性删除



**立即删除对cpu是最不友好的**。因为删除操作会占用cpu的时间，如果刚好碰上了cpu很忙的时候，比如正在做交集或排序等计算的时候，就会给cpu造成额外的压力。

惰性删除的缺点很明显:**浪费内存**。

定时删除是一个折中的办法，每隔一段时间执行一次删除操作。

redis使用的过期键值删除策略是：**惰性删除加上定期删除，两者配合使用**。



主从情况下：
从库发现过期直接返回空。当主库定期删除或惰性删除时，同步到从库，从库数据才真正删除。

原因： 避免主从同步出现混乱



#### redis数据淘汰策略

|     策略     |                         描述                         |                           应用场景                           |
| :----------: | :--------------------------------------------------: | :----------------------------------------------------------: |
| volatile-lru | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 | 如果设置了过期时间，且分热数据与冷数据，推荐使用 volatile-lru 策略。 |
| volatile-ttl |   从已设置过期时间的数据集中挑选将要过期的数据淘汰   | 如果让 Redis 根据 TTL 来筛选需要删除的key，请使用 volatile-ttl 策略。 |
| allkeys-lru  |       从所有数据集中挑选最近最少使用的数据淘汰       | 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 |

##### 淘汰策略的内部实现

- 客户端执行一个命令，导致 Redis 中的数据增加，占用更多内存
- Redis 检查内存使用量，如果超出 maxmemory 限制，根据策略清除部分 key
- 继续执行下一条命令，以此类推



#### 事务

**Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务(transaction)功能。**事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，可以减少客户端与服务器之间的网络通信次数从而提升性能。



#### 声明式缓存(注解)

##### Spring

https://www.cnblogs.com/coding-one/p/12402543.html)

spring 缓存抽象提供了以下一些注解来实现**声明式缓存**：

（通过拦截器Interceptor 和SpringAOP实现的）

| @Cacheable   | 触发缓存填充                       |
| ------------ | ---------------------------------- |
| @CacheEvict  | 触发缓存清除                       |
| @CachePut    | 在不影响方法执行的情况下更新缓存   |
| @Caching     | 重新组合应用于同一个方法的多个缓存 |
| @CacheConfig | 在类级别共享一些缓存相关的公共设置 |



**@Cacheable 缓存数据**

@Cacheable 提供两个参数来指定缓存名：value、cacheNames，二者选其一即可。

@Cacheable 支持同一个方法关联多个缓存。这种情况下，当执行方法之前，这些关联的每一个缓存都会被检查，而且只要至少其中一个缓存命中了，那么这个缓存中的值就会被返回。示例：

```java
@Cacheable({"menu", "menuById"})
```

当我们在声明 @Cacheable 时不指定 key 参数，则该缓存名下的所有 key 会使用 KeyGenerator 根据参数 自动生成。spring 有一个默认的 SimpleKeyGenerator ，在 spring boot 自动化配置中，这个会被默认注入。

相较于使用 KeyGenerator 生成，spring 官方更推荐显式指定 key 的方式，即指定 @Cacheable 的 key 参数。 

**key 和 keyGenerator 参数是互斥的，同时指定两个会导致异常**。

 **sync**是否同步，true/false。在一个多线程的环境中，某些操作可能被相同的参数并发地调用，这样同一个 value 值可能被多次计算（或多次访问 db），这样就达不到缓存的目的。

**condition**调用前判断，缓存的条件。

**unless**执行后判断，不缓存的条件。

示例：

```java
@Cacheable(cacheNames = {"testableCache"}, key = "'id-' + #id",  condition = "true", unless = "#result.data == null" )
```

redis存储的名称: testableCache::id-“id”

![image-20210308153206615](Redis.assets/image-20210308153206615.png)



**@CachePut** **更新缓存数据**

**@CacheEvict  删除缓存数据**



##### Jetcache

阿里巴巴开源的通用缓存访问框架JetCache，GitHub：https://github.com/alibaba/jetcache

JetCache是一个基于Java的缓存系统封装，提供统一的API和注解来简化缓存的使用。 JetCache提供了比SpringCache更加强大的注解，Spring Cache在对具体key缓存失效时间的设置不是很友好。 JetCache可以原生的支持TTL、两级缓存、分布式自动刷新，还提供了`Cache`接口用于手工缓存操作。





### 布隆过滤器

#### （不存在的一定不存在，存在的可能存在）



什么是布隆过滤器？

我们可以把它看作由**二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。**相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。



给你一个数据，如何判断给你的数据在不在其中。如果服务器的内存足够大，那么用HashMap是一个不错的解决方案，理论上的时间复杂度可以达到O(1)，但是现在数据的大小已经远远超出了服务器的内存，所以无法使用HashMap，这个时候就可以使用“布隆过滤器”来解决这个问题。但是还是同样的，会有一定的“误判率”。

仅从布隆过滤器本身而言，根本没有存放完整的数据，只是运用一系列随机映射函数计算出位置，然后填充二进制向量。

布隆过滤器的优缺点：

- 优点：**由于存放的不是完整的数据，所以占用的内存很少，而且新增，查询速度够快；**
- 缺点： **随着数据的增加，误判率随之增加；无法做到删除数据；只能判断数据是否一定不存在，而无法判断数据是否一定存在。**

使用guava实现布隆过滤器是把数据放在本地内存中，无法实现布隆过滤器的共享（共享方便集群进行判断），我们还可以把数据放在redis中，用 redis来实现布隆过滤器，我们要使用的数据结构是bitmap，你可能会有疑问，redis支持五种数据结构：String，List，Hash，Set，ZSet，没有bitmap呀。没错，实际上bitmap的本质还是String。





### 1、Redis 是单线程还是多线程？

redis 4.0 之前，redis 是***\*完全单线程的\****。

redis 4.0 时，redis 引入了多线程，但是**额外的线程只是用于后台处理**

redis 6.0 中，**多线程主要用于网络 I/O 阶段**，也就是接收命令和写回结果阶段，而在执行命令阶段，还是由单线程串行执行。由于执行时还是串行，因此无需考虑并发安全问题。



### 2、为什么 Redis 是单线程？

因为 redis 是完全基于内存操作的，通常情况下CPU不会是redis的瓶颈，**redis 的瓶颈最有可能是机器内存的大小或者网络带宽**。

既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为**如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗**。


### 3、Redis 为什么使用单进程、单线程也很快

主要有以下几点：

1、基于内存的操作

2、使用了 I/O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器

3、单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。

4、以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字符串、压缩列表等

### 4、Sorted Set 为什么使用跳跃表，而不是红黑树？

主要有以下几个原因：

1）跳表的性能和红黑树差不多。

2）跳表更容易实现和调试。



### 5、为什么是让缓存失效，而不是更新缓存

案例如下，有两个并发的写请求，流程如下：

![img](https://img-blog.csdnimg.cn/img_convert/93d63e4ac2c2a20e76d6a1a0b6d9b338.png)

分析：由于是删除缓存，所以不存在数据不一致的情况。



### 6、如何保证数据库和缓存的数据一致性

在上文的案例中，无论是先操作数据库，还是先操作缓存，都会存在脏数据的情况，有办法避免吗？

答案是有的，由于数据库和缓存是两个不同的数据源，要保证其数据一致性，其实就是**典型的分布式事务场景，可以引入分布式事务来解决，常见的有：2PC、TCC、MQ事务消息等。**

但是**引入分布式事务必然会带来性能上的影响，这与我们当初引入缓存来提升性能的目的是相违背的**。

所以**在实际使用中，通常不会去保证缓存和数据库的强一致性，而是做出一定的牺牲，保证两者数据的最终一致性。**

**如果是实在无法接受脏数据的场景，则比较合理的方式是放弃使用缓存，直接走数据库。**

保证数据库和缓存数据最终一致性的常用方案如下：

1）更新数据库，数据库产生 binlog。

2）监听和消费 binlog，执行失效缓存操作。

3）如果步骤2失效缓存失败，则引入重试机制，将失败的数据通过MQ方式进行重试，同时考虑是否需要引入幂等机制。

![img](https://img-blog.csdnimg.cn/img_convert/bb890384f07c5006146f0b369489c4f2.png)

兜底：当出现未知的问题时，及时告警通知，人为介入处理。









### 7、**redis延时双删**（数据库和缓存双写一致性方案）

https://www.it610.com/article/1306087917600411648.htm



（1）先淘汰缓存；

（2）再写数据库（这两步和原来一样）；

（3）休眠1秒，再次淘汰缓存；

这么做，可以将1秒内所造成的缓存脏数据，再次删除！



双删是为了**确保缓存和数据库的数据一致性**

延时是确保 **修改数据库 -> 清空缓存前，其他事务的更改缓存操作已经执行完。**



解决第一个问题：在线程 A 删除缓存、更新完数据库之后，先「休眠一会」，再「删除」一次缓存。 

解决第二个问题：线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。 

这两个方案的目的，都是为了把缓存清掉，这样一来，下次就可以从数据库读取到最新值，写入缓存。

但问题来了，这个「延迟删除」缓存，延迟时间到底设置要多久呢？

 问题1：**延迟时间要大于「主从复制」的延迟时间** 

 问题2：**延迟时间要大于线程 B 读取数据库 + 写入缓存的时间** 

但是，这个时间在分布式和高并发场景下，其实是很难评估的。 很多时候，我们都是凭借经验大致估算这个延迟时间，例如延迟 1-5s，**只能尽可能地降低不一致的概率。** 所以你看，采用这种方案，也只是尽可能保证一致性而已，极端情况下，还是有可能发生不一致。 **所以实际使用中，我还是建议你采用「先更新数据库，再删除缓存」的方案，同时，要尽可能地保证「主从复制」不要有太大延迟，降低出问题的概率。**



在这里我也分享 4 点心得给你： 

1、性能和一致性不能同时满足，为了性能考虑，通常会采用「最终一致性」的方案 

2、掌握缓存和数据库一致性问题，核心问题有 3 点：缓存利用率、并发、缓存 + 数据库一起成功问题 

3、失败场景下要保证一致性，常见手段就是「重试」，同步重试会影响吞吐量，所以通常会采用异步重试的方案 

4、订阅变更日志的思想，本质是把权威数据源（例如 MySQL）当做 leader 副本，让其它异质系统（例如 Redis / Elasticsearch）成为它的 follower 副 本，通过同步变更日志的方式，保证 leader 和 follower 之间保持一致



![redis缓存为什么要延时双删_第4张图片](https://img.it610.com/image/info8/41cae99b178248a1b6d1d8948d7b2d65.jpg)









#### 字符串 string

Redis 中的字符串是一种 **动态字符串**，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 ArrayList，有一个字符数组，从源码的 sds.h/sdshdr 文件 中可以看到 Redis 底层对于字符串的定义 SDS，即 Simple Dynamic String 结构。

#### 列表 list

Redis 的列表相当于 Java 语言中的 **LinkedList**，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。

#### 字典 hash

Redis 中的字典相当于 Java 中的 **HashMap**，内部实现也差不多类似，都是通过 **"数组 + 链表"** 的链地址法来解决部分 **哈希冲突**，同时这样的结构也吸收了两种不同数据结构的优点。

#### 集合 set

Redis 的集合相当于 Java 语言中的 **HashSet**，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

#### 有序列表 zset

这可能使 Redis 最具特色的一个数据结构了，它类似于 Java 中 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以为每个 value 赋予一个 score 值，用来代表排序的权重。

它的内部实现用的是一种叫做 「**跳跃表**」 的数据结构。





### redis模式

#### 一. 主从

通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了**避免单点故障**，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。

（优点）**读写分离：**

对于读占比较高的场景，可以通过把一部分流量分摊导出从节点(salve) 来减轻主节点（master）压力，同时需要主要只对主节点执行写操作，如下图：

（缺点）当使用从节点响应读请求时，业务端可能会遇到以下问题：

**复制数据延迟**
**读到过期数据**
**从节点故障**



```
主从数据库的配置
master  slave
主不用配置，从redis的conf文件加入 slaveof ip port 就可以了
或者从redis启动时  redis-server --port 6380 --slaveof 127.0.0.1 6379
    从数据库一般是只读，可以改为可写，但写入的数据很容易被主同步没，所以还是只读就可以。
也可以在运行是使用slaveof ip port命令，停止原来的主，切换成刚刚设置的主  slaveof no one会把自己变成主

复制原理
当从数据库启动时，会向主数据库发送sync命令，主数据库接收到sync后开始在后台报错快照rdb，在保存快照期间受到的命名缓存起来，当快照完成时，主数据库会将快照和缓存的命令一块发送给从。复制初始化结束。
之后，主每受到1个命令就同步发送给从。
当出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库。增量复制

主从复制是乐观复制，当客户端发送写执行给主，主执行完立即将结果返回客户端，并异步的把命令发送给从，从而不影响性能。也可以设置至少同步给多少个从主才可写。
无硬盘复制:如果硬盘效率低将会影响复制性能，2.8之后可以设置无硬盘复制，repl-diskless-sync yes
```



#### 二. 哨兵(sentinel)

当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然而整个过程相对麻烦且需要人工介入，难以实现自动化。 为此，Redis 2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。
**哨兵的作用就是监控redis主、从数据库是否正常运行，主出现故障自动将从数据库转换为主数据库。**

顾名思义，哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个。

    （1）监控主数据库和从数据库是否正常运行。
    （2）主数据库出现故障时自动将从数据库转换为主数据库。
![img](https://img-blog.csdn.net/20160909152623127)

可以用**info replication查看主从情况**

```

例子：
1主2从  1哨兵,可以用命令起也可以用配置文件里
可以使用双哨兵，更安全，
redis-server --port 6379
redis-server --port 6380 --slaveof 192.168.0.167 6379
redis-server --port 6381 --slaveof 192.168.0.167 6379


redis-sentinel sentinel.conf
哨兵配置文件
    sentinel.conf
        sentinel monitor mymaster 192.168.0.167 6379 1 

其中mymaster表示要监控的主数据库的名字，可以自己定义一个。这个名字必须仅由大小写字母、数字和“.-_”这 3 个字符组成。后两个参数表示主数据库的地址和端口号，这里我们要监控的是主数据库6379。
注意:

    1、使用时不能用127.0.0.1，需要用真实IP，不然java程序通过哨兵会连到java程序所在的机器(127.0.0.1 )
    
    2、配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自动发现所有复制该主数据库的从数据库

这样哨兵就能监控主6379和从6380、6381，一旦6379挂掉，哨兵就会在2个从中选择一个作为主，根据优先级选，如果一样就选个id小的，当6379再起来就作为从存在。
主从切换过程：

（1）      slave leader升级为master
（2）      其他slave修改为新master的slave
（3）      客户端修改连接
（4）      老的master如果重启成功，变为新master的slave


哨兵监控1主2从，停掉主，哨兵会选出1个从作为主，变成1主1从。然而当我把原来的主再起来，它不会作为从，只是个独立的节点。

如果在新的主刚被选出来时，我把原来的主起来，它就能成为新主的从节点。
如果在新的主选出来过一会再起原来的主，就不能成为新主的从节点
或者在老的主起来后，重启哨兵也能把它变成从，哨兵配置文件里有，哨兵会执行“+convert-to-slave”

```



#### 三. 集群(**redis cluster**)

即使使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用集群，就是分布式存储。即每台redis存储不同的内容，
共有16384个slot（2的14次方个）。每个redis分得一些slot，hash_slot = crc16(key) mod 16384 找到对应slot，键是可用键，如果有{}则取{}内的作为可用键，否则整个键是可用键
**集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选**。

修改每个实例的配置文件：

    cluster-enabled yes  --开启集群
    
    cluster-config-file nodes-6382.conf --集群配置文件名，每个实例配置的要不同，redis会根据文件名自动新建
**用集群工具创建集群**

```
集群过程：
首先redis-trib.rb会以客户端的形式尝试连接所有的节点，并发送PING命令以确定节点能够正常服务。如果有任何节点无法连接，则创建失败。同时发送 INFO 命令获取每个节点的运行ID以及是否开启了集群功能（即cluster_enabled为1）。 准备就绪后集群会向每个节点发送 CLUSTER MEET命令，格式为 CLUSTER MEET ip port，这个命令用来告诉当前节点指定ip和port上在运行的节点也是集群的一部分，从而使得6个节点最终可以归入一个集群。

然后redis-trib.rb会分配主从数据库节点，分配的原则是尽量保证每个主数据库运行在不同的IP地址上，同时每个从数据库和主数据库均不运行在同一IP地址上，以保证系统的容灾能力

3主3从，当1个主故障，大家会给对应的从投票，把从立为主，若没有从数据库可以恢复则redis集群就down了。

客户端连接：
使用redis-cli -c -p 任意一个端口
```

##### redis cluster 架构

　　**1)redis-cluster架构图**

![img](https://images2015.cnblogs.com/blog/17405/201607/17405-20160729120110388-883077606.jpg)

　　架构细节:

　　(1)所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.

　　(2)节点的fail是通过集群中超过半数的节点检测失效时才生效.

　　(3)客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可

　　(4)redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node<->slot<->value

 

  **2) redis-cluster选举:容错**

![img](https://images2015.cnblogs.com/blog/17405/201607/17405-20160729120154169-1347608301.jpg)

　　(1)领着选举过程是集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉.

　　(2):什么时候整个集群不可用(cluster_state:fail),当集群不可用时,所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误

  　　a:如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成进群的slot映射[0-16383]不完成时进入fail状态.

  　　b:如果进群超过半数以上master挂掉，无论是否有slave集群进入fail状态.





### Redisson

Redis分布式锁原理（二）——Redisson分布式锁源码浅析https://blog.csdn.net/h2503652646/article/details/119514951

在调用redisson的lock()方法时，我们可以传入自定义的超时时间，也可以不传，**如果不传那么将会使用Redisson默认的看门狗时间30s，需要注意的是，如果我们使用了自定义超时时间，那么Redisson不会自动为我们的锁续期，而不传时间Redisson会使用默认30s超时时间并且会自动为我们的锁进行续期。**而一般在开发中，**最佳实践其实推荐的是传入超时时间，因为这样省去了创建定时任务不断续时的过程，可能会有小伙伴会问那如果业务时间大于了超时时间怎么办，其实只需要把超时时间设的大一点就可以了，比如就30s，如果超过30s业务还没完成就该想想怎么优化业务逻辑了**。



#### 看门狗机制（watch dog）

 [redisson中的看门狗机制总结](https://www.cnblogs.com/jelly12345/p/14699492.html)

- watch dog 在当前节点存活时每10s给分布式锁的key续期 30s；
- watch dog 机制启动，且代码中没有释放锁操作时，watch dog 会不断的给锁续期；
- 如果程序释放锁操作时因为异常没有被执行，那么锁无法被释放，所以释放锁操作一定要放到 finally {} 中；
- 要使 watchLog机制生效 ，lock时 不要设置 过期时间
- watchlog的延时时间 可以由 lockWatchdogTimeout指定默认延时时间，但是不要设置太小。如100
- watchdog 会每 lockWatchdogTimeout/3时间，去延时。
- watchdog 通过 类似netty的 Future功能来实现异步延时
- watchdog 最终还是通过 lua脚本来进行延时







### 杂记

redis执行批量命令

1.RedisTemplate使用*PipeLine*管道命令

**减少请求次数，将多条请求命令合成一次请求通过管道发给redis server，再通过回调函数一次性接收多个命令的结果，减少网络IO次数**，在高并发情况下可带来明显性能提升。注意的是，redis server是单线程，**多个命令合成一次请求到达redis server依然还是顺序一个个执行的，仅仅只是减少了请求IO次数**。

```java
// 1.executePipelined 重写 入参 RedisCallback 的doInRedis方法
		List<Object> resultList = redis.executePipelined(new RedisCallback<Object>() {
 
			@Override
			public String doInRedis(RedisConnection connection) throws DataAccessException {
				// 2.connection 打开管道
				connection.openPipeline();
				// 3.connection 给本次管道内添加 要一次性执行的多条命令
            	for (int i = 0; i < 20; i++) {
                	connection.zIncrBy("im.test".getBytes(), 1.0, "prod_0_1410063315498532866".getBytes());
                	connection.zIncrBy("im.test".getBytes(), 1.0, "prod_0_1410063313262968834".getBytes());
                	connection.zIncrBy("im.test".getBytes(), 1.0, "prod_0_1440314158867456002".getBytes());
            	}
				// 4.关闭管道 不需要close 否则拿不到返回值
				// connection.closePipeline();
				// 这里一定要返回null，最终pipeline的执行结果，才会返回给最外层
             	 // 返回null即可，因为返回值会被管道的返回值覆盖，外层取不到这里的返回值
				return null;
			}
		});
```



选择数据库

select index  

select 8 



String

set key value
setnx key  value  key不存在才可用 相当于add操作
set key value xx  key存在 相当于update操作

批量操作
mget  k1 k2 k3
mset  k1 v1 k2 v2 k3 v3

getset key newvalue  设置新值返回旧值
append key value  追加值
strlen key 返回字符串的长度（注意中文）

incrbyfloat key 3.5 增加key对应的值3.5

getrange key start end 获取字符串指定下标所有的值

setrange key index value 设置指定下标的对应的值

Hash 
哈希命令都以h开头
hget key field  
hset key field value
hdel key field 
hgetall key 获取所有
 hexists key field   判断hash key 是否有field  复杂度o(1)
 hlen key 获取key的filed数量 复杂度o(1)
 批量  o(n)
 hmset key field value field value
 hmget key field field

 list(列表) 有序 可重复 左右两边弹入弹出
 增 
 lpush/rpush key value1 value2 value3..
 linsert key before|after value newvalue 在list指定的值前后插入newvalue
 删
 lpop/rpop key 
 lrem key count value 
 （count>0 从左到右 删除 count个 value  count<0 从右到左 count=0 全删）
 ltrim key start end 按索引范围修剪列表 
查 
 lrange key start end(包含end) 获取列表指定索引范围所有item
 lindex key index
 llen key 获取列表的长度
 改
 lset key index newvalue  设置列表指定索引值为 newvalue

 LRUSH + LPOP =Stack
 LRUSH + RPOP = Queue
 LPUSH + LTRIM = Capped Collection 控制列表大小
 LPUSH + BRPOP =Message Queue

 SET(集合，特点：无序，无重复，集合间操作)
 sadd  key element1 element2 增加 
 srem  key element1 删除
 scard key  计算几个大小
 sismember key value 判断it是否在集合中
 srandmember key count  从集合中随机挑count个元素（不会破坏集合数据）
 spop key  从集合中随机弹出一个元素
 smembers key 返回集合中的所有元素（无序，小心使用）

集合间
sdiff key1 key2 差集
sinter  key1 key2 交集
sunion key1 key2 并集
+ store destkey  将结果保存在 destkey 中
tips
SADD 标签
spop/srandmember 随机数应用
sadd + sinter 社交相关应用 共同关注的人

zset（有序集合）
key score value
user  1   an_zzz
zadd key score element (可以多对) 增加 o(n)
zrem key element(可以多个) 删除 o(1)
zscore key element 返回元素的分数 (可以多对)
zincrby key increScore element  增加或减少元素分数 o(1)
zcard key 返回元素个数
zrank 获取排名 从小到大，从0开始
zrange key start end [WITHSCORES] 返回指定索引范围内的升序元素[分值]o(long(n)+m)
zrangebyscore key minScore maxScore [WITHSCORES]  返回指定分数范围内的升序元素[分值]
zcount key minScore maxScore 返回指定分数范围内的元素个数
zremrangebyrank key start end 删除指定排名内的升序元素
zremrangebyscore key minScore maxScore 删除指定分数内的升序元素


慢查询参数
首先来关注下慢日志分析对应的两个参数：

1、slowlog-log-slower-than：预设阀值，即记录超过多少时间的记录，默认为10000微秒，即10毫秒。可设置为1000

2、slowlog-max-len：记录慢查询的条数，默认为128条，当超过设置的条数时最早进入队列的将被移除。线上建议增大数值，如：1000，这样可减少队列移除的频率。

config set 设置 

持久化方式
快照 ==》 MySQL dump ,redis RDB
写日志 ==》 MySQL binlog , redis AOF

RDB   
  save(同步)   文件策略：存在老的RDB文件，新替换老 复杂度：O(n)        阻塞？：是（阻塞客户端命令）
  bgsave(异步) 文件策略：与save相同                复杂度：与save相同  阻塞？：是（阻塞发生在fork,fork消耗内存）
  自动生成RDB （自动配置满足任一条件就会执行）
  触发机制：主从复制 shutdown
   RDB   缺点：耗时、耗性能  不可控、丢失数据

AOF
  always             不丢失数据    				IO开销大
  everysec（每秒）	 每秒一次fsync，保护磁盘	丢一秒数据
  no （OS决定fsync）  不用管					不可控

主从复制
指令        无需重启，但不便于管理
slaveof ip:端口
slaveof no one
配置文件   统一配置，需要重启
slaveof ip port
slaveof-read-only yes  只读

规避全量复制
1.第一次全量复制
2.节点运行ID不匹配
3.复制缓冲区不足 网络中断等。。

规避复制风暴

sentinel

三个定时任务
1.每10秒info 
 发现slave节点  确认主从关系
2.每2秒发布订阅 
 每2秒每个sentinel通过master节点的channel交换信息（pub/sub）
3.心态检测
 每1秒每个sentinel对其他sentinel和redis执行ping

 主观下线：每个sentinel节点对redis节点失败的“偏见”
 客观下线：所有sentinel节点对redis节点失败“达成共识”（超过quorum个统一）

 数据分布概念 
  1.节点取余分区
  2.一致性哈希分区
  3.虚拟槽哈希分布

  redis集群

  准备节点 --> meet操作 --> 分配槽 --> 配置主从

  集群伸缩 = 槽和数据在节点之间的移动

  加入集群的作用
  1.为他迁移槽和数据实现扩容
  2.作为从节点负责故障转移

  收缩集群
  1.下线迁移槽
  2.忘记节点
  3.关闭节点

  客户端路由
  moved 和 ask
  两者都是客户端重定向
  moved:槽已经确定迁移
  ask:槽还在迁移中

  数据倾斜
  1.节点和槽分配不均匀
  2.不同槽对应键值数差异较大
  3.包含bigkey
  4.内存相关配置不一致





### 01 redis基本架构：一个键值数据库包含什么？

#### 可以存哪些数据？

不同键值数据库支持的key类型一般差异不大，而value类型则有较大差别。我们在对键值数据库进行选型时，一个重要的考虑因素是它支持的value类型。例如**，Memcached支持的value类型仅为String类型，而Redis支持的value类型包括了String、哈希表、列表、集合等。**Redis能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的value。

大体来说，一个键值数据库包括了**访问框架、索引模块、操作模块和存储模块**四部分

<img src="https://img-blog.csdnimg.cn/1b8cb7478445410b8ea627adf4839c75.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5aO55bCP5L-K,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />



#### 采用什么访问模式？

访问模式通常有两种：一种是通过函数库调用的方式供外部应用使用，比如，上图中的libsimplekv.so，就是以动态链接库的形式链接到我们自己的程序中，提供键值存储功能；另一种是通过网络框架以Socket通信的形式对外提供键值对操作，这种形式可以提供广泛的键值存储服务。在上图中，我们可以看到，网络框架中包括Socket Server和协议解析。

不同的键值数据库服务器和客户端交互的协议并不相同，我们在对键值数据库进行二次开发、新增功能时，必须要了解和掌握键值数据库的通信协议，这样才能开发出兼容的客户端。

实际的键值数据库也基本采用上述两种方式，例如，**RocksDB以动态链接库的形式使用，而Memcached和Redis则是通过网络框架访问。**

#### 如何定位键值对的位置？

当SimpleKV解析了客户端发来的请求，知道了要进行的键值对操作，此时，SimpleKV需要查找所要操作的键值对是否存在，这依赖于键值数据库的索引模块。索引的作用是让键值数据库根据key找到相应value的存储位置，进而执行操作。

索引的类型有很多，常见的有哈希表、B+树、字典树等。不同的索引结构在性能、空间消耗、并发控制等方面具有不同的特征。如果你看过其他键值数据库，就会发现，不同键值数据库采用的索引并不相同，例如，**Memcached和Redis采用哈希表作为key-value索引，而RocksDB则采用跳表作为内存中key-value的索引。**

**一般而言，内存键值数据库（例如Redis）采用哈希表作为索引，很大一部分原因在于，其键值数据基本都是保存在内存中的，而内存的高性能随机访问特性可以很好地与哈希表O(1)的操作复杂度相匹配。**

SimpleKV的索引根据key找到value的存储位置即可。但是，和SimpleKV不同，**对于Redis而言，很有意思的一点是，它的value支持多种类型，当我们通过索引找到一个key所对应的value后，仍然需要从value的复杂结构（例如集合和列表）中进一步找到我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。**

#### 不同操作的具体逻辑是怎样的？

SimpleKV的**索引模块负责根据key找到相应的value的存储位置。**对于不同的操作来说，找到存储位置之后，需要进一步执行的操作的具体逻辑会有所差异。SimpleKV的操作模块就实现了不同操作的具体逻辑：

对于GET/SCAN操作而言，此时根据value的存储位置返回value值即可；
对于PUT一个新的键值对数据而言，SimpleKV需要为该键值对分配内存空间；
对于DELETE操作，SimpleKV需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。
不知道你注意到没有，对于PUT和DELETE两种操作来说，除了新写入和删除键值对，还需要分配和释放内存。这就不得不提SimpleKV的存储模块了。

#### 如何实现重启后快速提供服务？

SimpleKV采用了常用的内存分配器glibc的malloc和free，因此，SimpleKV并不需要特别考虑内存空间的管理问题。但是，键值数据库的键值对通常大小不一，glibc的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。

因此，**分配器是键值数据库中的一个关键因素。对于以内存存储为主的Redis而言，这点尤为重要。Redis的内存分配器提供了多种选择，分配效率也不一样，后面我会具体讲一讲这个问题。**SimpleKV虽然依赖于内存保存数据，提供快速访问，但是，我也希望SimpleKV**重启后能快速重新提供服务，所以，我在SimpleKV的存储模块中增加了持久化功能。**



#### 小结

<img src="https://img-blog.csdnimg.cn/f281a7821c4c4ae2b47a42a61a6de53f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5aO55bCP5L-K,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />

从这张对比图中，我们可以看到，从SimpleKV演进到Redis，有以下几个重要变化：

* Redis主要**通过网络框架进行访问**，而不再是动态库了，这也使得Redis可以作为一个基础性的网络服务进行访问，扩大了Redis的应用范围。
* Redis数据模型中的**value类型很丰富**，因此也带来了更多的操作接口，例如面向列表的LPUSH/LPOP，面向集合的SADD/SREM等。在下节课，我将和你聊聊这些value模型背后的数据结构和操作效率，以及它们对Redis性能的影响。
* Redis的**持久化模块能支持两种方式：日志（AOF）和快照（RDB）**，这两种持久化方式具有不同的优劣势，影响到Redis的访问性能和可靠性。
* SimpleKV是个简单的单机键值数据库，但是，**Redis支持高可靠集群和高可扩展集群**，因此，Redis中包含了相应的集群功能支撑模块。



### 02 Redis的慢操作

#### 一、Redis数据类型的底层实现

**底层数据结构**一共有 **6** 种，分别是**简单动态字符串、双向链表、压缩列表、哈希表、跳表、整数数组**。它们和**数据类型**的对应关系如下图所示：

<img src="https://img-blog.csdnimg.cn/b68e70c00312416582949f0aa4e36de2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis数据类型和底层数据结构的对应关系" style="zoom:67%;" />

String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。这四种类型称为集合类型，它们的特点是**一个键对应了一个集合的数据**。



#### 二、键和值的结构组织

为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。哈希表就是一个数组，数组的每个元素称为一个哈希桶。一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。

其实，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。

如图，哈希桶中的 entry 元素中保存了key和value指针，分别指向了实际的键和值，即使值是一个集合，也可以通过value指针被查找到。

<img src="https://img-blog.csdnimg.cn/a444e1eaeb7e48008947a5dec9686a12.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="全局哈希表" style="zoom:67%;" />

因为这个哈希表保存了所有的键值对，所以把它称为全局哈希表。哈希表的最大好处是可以用 O(1) 的时间复杂度来快速查找到键值对。只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素。

这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。不管哈希表里有 10 万个键还是 100 万个键，只需要一次计算就能找到相应的键。

#### 三、哈希表操作变慢的原因

往哈希表中写入更多数据时，哈希冲突是不可避免的问题。即两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。哈希桶的个数通常要少于 key 的数量，难免会有一些 key 的哈希值对应到了同一个哈希桶中。

##### 3.1、链式哈希

Redis 解决哈希冲突的方式是链式哈希。指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。

如图，entry1、entry2 和 entry3 都需要保存在哈希桶 3 中，导致了哈希冲突。此时，entry1 元素会通过一个next指针指向 entry2，同样，entry2 也会通过next指针 指向 entry3。即使哈希桶 3 中的元素有 100 个，也可以通过 entry 元素中的指针把它们连起来。这就形成了一个链表，也叫作哈希冲突链。

##### 3.2、rehash

哈希冲突链上的元素只能通过指针逐一查找再操作。**如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低**。

**为了避免这个问题，Redis 会对哈希表做 rehash 操作。增加哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突**。

Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：

给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
释放哈希表 1 的空间。

用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。

##### 3.3、渐进式rehash

**第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求，无法快速访问数据了。**

为了避免这个问题，Redis 采用了**渐进式 rehash**。**在第二步拷贝数据时，Redis每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。**如图：

<img src="https://img-blog.csdnimg.cn/675241ea329a4c7fa513e6575d6a476b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="渐进式rehash" style="zoom:67%;" />

把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。

#### 四、集合类型数据操作效率

**String 类型**找到哈希桶就能直接增删改查了，**哈希表**的 **O(1)** 操作复杂度也就是它的复杂度了。

集合类型即使找到哈希桶了，还要在集合中再进一步操作。集合类型的值，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。

集合的操作效率的影响因素

1. **集合的底层数据结构有关**。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。
2. **操作本身的执行特点有关**，比如读写一个元素的操作要比读写所有元素的效率高。

#### 五、集合类型的底层数据结构

集合类型的底层数据结构主要有 5 种：**整数数组、双向链表、哈希表、压缩列表和跳表。**

哈希表上文已述，**整数数组和双向链表操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度是 O(N)，操作效率比较低**。

压缩列表像一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，**压缩列表在表头有三个字段 zlbytes（列表长度）、zltail（列表尾的偏移量） 和 zllen（entry 个数）；压缩列表在表尾还有一个 zlend，表示列表结束**。

<img src="https://img-blog.csdnimg.cn/be50c0b995c24238be6833755d52c99e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="压缩列表" style="zoom:67%;" />

**压缩列表查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。查找其他元素是逐个查找，复杂度就是 O(N) 了。**

**跳表在链表的基础上，增加了多级索引**，通过索引位置的几个跳转，**实现数据的快速定位**，当数据量很大时，**跳表的查找复杂度就是 O(logN)**， 如图：

<img src="https://img-blog.csdnimg.cn/b95bf6a165574b319936e07ed21712ac.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="跳表" style="zoom:67%;" />



按照查找的时间复杂度给这些数据结构分下类了：<img src="https://img-blog.csdnimg.cn/fdb75520d5e64b96a413aafda40712bf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="数据结构的时间复杂度" style="zoom:67%;" />



#### 六、不同操作的复杂度

集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。**复杂度的高低是我们选择集合类型的重要依据**。

提前规避高复杂度操作的四句口诀：

**单元素操作是基础；**
**范围操作非常耗时；**
**统计操作通常高效；**
**例外情况只有几个。**

第一，**单元素操作是指每一种集合类型对单个数据实现的增删改查操作**。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、 SREM、SRANDMEMBER 复杂度也是 O(1)。

注意：集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元 素时，复杂度就从 O(1) 变成 O(M) 了。

第二，**范围操作是指集合类型中的遍历操作**，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时尽量避免。

不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），实现了渐进式遍历，每次只返回有限数量的数据。相比于 HGETALL、SMEMBERS 避免了一次性返回所有元素而导致的 Redis 阻塞。

第三，**统计操作是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)**，这是因为当**集合类型采用压缩列表、双向链表、整数数组这些数据结构时，专门记录了元素的个数统计**，因此可以高效地完成相关操作。

第四，例外情况是指**某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量**。 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作是在列表的头尾增删元素，**可以通过偏移量直接定位，所以复杂度也只有 O(1)**，可以实现快速操作。

#### 总结

Redis 的底层数据结构包括了用来保存每个键和值的全局哈希表结构，**支持集合类型实现的双向链表、压缩列表、整数数组、哈希表、跳表这五大底层结构**。

Redis 能快速操作键值的原因：

* O(1) 复杂度的哈希表被广泛使用，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定；
* Sorted Set 用了 O(logN) 复杂度的跳表。

不过，集合类型的范围操作要遍历底层数据结构，复杂度通常是 O(N)。建议用其他命令来替代，例如**可以用 SCAN 来代替， 避免在 Redis 内部产生费时的全集合遍历操作**。

**List 类型两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。建议因地制宜地使用 List 类型。例如，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO 队列场景，而不是作为一个可以随机读写的集合。**



Q：整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么Redis还会把他们作为底层数据结构呢？

A：

1、**内存利用率**，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。

2、**数组对CPU高速缓存支持更友好**，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。

Q：如果在数组上是随机访问，对CPU高速缓存还友好不？

A：Redis底层的使用数组和压缩链表对数据大小限制在64个字节以下，当大于64个字节会改变存储数据的数据结构，所以随机访问对于CPU高速缓存没啥影响



### 03 Redis的高性能IO模型

[Redis](https://so.csdn.net/so/search?q=Redis&spm=1001.2101.3001.7020) 是单线程是指 **Redis 的网络 IO**和**键值对读写**是由一个线程来完成的。但 Redis 的**持久化、异步删除、集群数据同步等**，其实是由**额外的线程执行**的。所以严格来说Redis 并不是单线程的。

#### 一、Redis 用单线程的原因

Redis 为什么用单线程，就要先了解多线程的开销。

##### 1.1 多线程的开销

**使用多线程，可以增加系统吞吐率、增加系统扩展性。在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。**下面的左图是采用多线程时的理想结果。

**但是通常情况下采用多线程后，如果没有良好的系统设计，实际得到的结果是右图。刚开始增加线程数时，系统吞吐率会增加，但是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况。**

<img src="https://img-blog.csdnimg.cn/7dc8b0d7138b46e29535fa79e5d7727f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="线程数与系统吞吐率" style="zoom:67%;" />

下降原因是：

系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，**为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销**。这就是多线程编程模式面临的共享资源的并发访问控制问题。

1. 如果没有精细的设计，比如说只是简单地采用一个**粗粒度互斥锁**，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，**并行变串行**，系统吞吐率并没有随着线程的增加而增加。
2. 多线程一般会引入**同步原语**来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。

为了避免这些问题，**Redis 直接采用了单线程模式**。

#### 二、 Redis 的单线程快的原因

通常来说，单线程的处理能力要比多线程差很多，但是 Redis 却能使用单线程模型达到每秒数十万级别的处理能力，这是因为Redis 多方面设计选择的一个综合结果。

Redis 的大部分操作在**内存上完成**，再加上它采用了**高效的数据结构**，例如哈希表和跳表；
Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

##### 2.1 Redis的多路复用机制

###### 2.1.1 基本 IO 模型与阻塞点

网络操作的基本 IO 模型和潜在的**阻塞点**。以 Get 请求为例，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。

如下图，其中bind/listen、accept、recv、parse 和 send 属于网络 IO 处理，而 get 属于键值数据操作。既然 Redis 是单线程，那么最基本的一种实现是在一个线程中依次执行上面说的这些操作。

<img src="https://img-blog.csdnimg.cn/b9b8a7a25db04ee6b5b03a604f10cd22.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis基本IO模型 " style="zoom:67%;" />

这里的**网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()：**

当 Redis **监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里**，导致其他客户端无法和 Redis 建立连接。
当 Redis **通过 recv() 从一个客户端 读取数据**时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。
这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过 socket 网络模型本身支持非阻塞模式。

###### 2.1.2 非阻塞模式

**Socket 网络模型的非阻塞模式设置，主要体现在socket()、listen()、 accept() 三个关键的函数调用上。**

在 socket 模型中，不同操作调用后会返回不同的套接字类型。socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。

<img src="https://img-blog.csdnimg.cn/b6a9d676b5ac4a70b46ff00f1e56940c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="Redis套接字类型与非阻塞设置 " style="zoom:67%;" />

**针对监听套接字，可以设置非阻塞模式**：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。

**虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。**

**针对已连接套接字，也可以设置非阻塞模式**：Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。

这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。

###### 2.1.3 基于多路复用的高性能 I/O 模型

**Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，即 select/epoll 机制。**

（redis如何使用IO多路复用）

**在 Redis 只运行单线程的情况下， 多路复用机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。**

图中的多个 FD（文件描述符） 就是刚才所说的多个套接字。 **Redis 网络框架调用 epoll 机制，让Linux内核监听这些套接字**。此时Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，不会阻塞在某一个特定的客户端请求处理上。所以Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

<img src="https://img-blog.csdnimg.cn/c5e41be4e63a464ca70c92c5557145e7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5rW36ZmG5LqR,size_20,color_FFFFFF,t_70,g_se,x_16" alt="基于多路复用的Redis高性能IO模型 " style="zoom:67%;" />

###### 2.1.4 select/epoll的事件的回调机制

**select/epoll 提供了基于事件的回调机制，针对不同事件的发生，调用相应的处理函数**。select/epoll 监测到 FD 上有请求到达时，就会触发相应的事件。

**这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理**。好处：

* **Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。**
* **Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。**

因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。

**例如现在有两个请求，这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件 和 Read 事件，此时内核就会回调 Redis 相应的 accept 和 get 函数进行处理。**

这就像病人去医院瞧病。在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以医院都设置了分诊台，分诊台会一直处理这些诊断前的工作（类似于 Linux 内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于 Redis 单线程），效率也能提升。

事件的回调机制的实现有很多种：

基于 Linux 系统下的 select 和 epoll 实现；
基于 FreeBSD 的 kqueue 实现；
基于 Solaris 的 evport 实现；
可以根据 Redis 实际运行的操作系统，选择相应的多路复用实现。

#### 总结

Redis 单线程是指网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。

单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的网络 IO 操作阻塞点。

Redis 6.0 中提出了多线程模型。