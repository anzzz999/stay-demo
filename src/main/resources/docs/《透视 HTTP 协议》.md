# 《透视 HTTP 协议》

## 破冰篇（7讲）

### 01 | 时势与英雄：HTTP的前世今生

在 **70 年代**，基于对 ARPA 网的实践和思考，研究人员发明出了**著名的 TCP/IP 协议。由于具有良好的分层结构和稳定的性能，TCP/IP 协议迅速战胜其他竞争对手流行起来，并在 80 年代中期进入了 UNIX 系统内核**，促使更多的计算机接入了互联网。

1989 年，任职于欧洲核子研究中心（CERN）的蒂姆·伯纳斯 - 李（Tim Berners-Lee）发表了一篇论文，提出了在互联网上构建超链接文档系统的构想。这篇论文中他确立了三项关键技术。

1. **URI：即统一资源标识符，作为互联网上资源的唯一身份；**

2. **HTML：即超文本标记语言，描述超文本文档；**
3. **HTTP：即超文本传输协议，用来传输超文本。**





#### HTTP/0.9

时间：20 世纪 90 年代初期

背景：互联网世界非常简陋，计算机处理能力低，存储容量小，网速很慢，还是一片“信息荒漠”。

HTTP情况：

1、这一时期的 HTTP 被定义为 0.9 版，结构比较简单，为了便于服务器和客户端处理，它也采用了纯文本格式。

2、**蒂姆·伯纳斯 - 李最初设想的系统里的文档都是只读的，所以只允许用“GET”动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接**，功能非常有限。

#### HTTP/1.0

背景：

1、1992 年发明了 JPEG 图像格式

2、1993 年，NCSA（美国国家超级计算应用中心）开发出了 Mosaic，是第一个可以图文混排的浏览器

3、1995 年开发出了服务器软件 Apache （源于NCSAhttpd服务器），简化了 HTTP 服务器的搭建工作。

4、1995 年发明了 MP3 音乐格式

HTTP情况：

在已有实践的基础上，HTTP/1.0 版本在 1996 年正式发布。

**HTTP/1.0 版本在多方面增强了 0.9 版：**

**增加了 HEAD、POST 等新方法**
**增加了响应状态码，标记可能的错误原因**
**引入了协议版本号概念**
**引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活**
**传输的数据不再仅限于文本**

#### HTTP/1.1

背景：

时间：1995 年

事件：“浏览器大战”

参与者：网景的 Netscape Navigator VS 微软的 Internet Explorer

结局：微软的 Internet Explorer 取得胜利。

HTTP情况：

1、在“浏览器大战”结束之后的 1999 年，**HTTP/1.1 发布了 RFC 文档，编号为 2616**，正式确立了延续十余年的传奇。（“**正式的标准**”）

HTTP/1.1 主要的变更点有：

**增加了 PUT、DELETE 等新的方法**
**增加了缓存管理和控制**
**明确了连接管理，允许持久连接**
**允许响应数据分块（chunked），利于传输大文件**
**强制要求 Host 头，让互联网主机托管成为可能**
2、2014 年又做了一次修订，把原来一个大文档拆分成6个较小的文档，编号为 7230-7235，优化了一些细节，没有实质性的改动。

#### HTTP/2

背景：

1、一方面：HTTP、1.1发布之后，随着互联网爆发式的增长，出现了一些对HTTP不满的意见，主要就是**连接慢**，跟不上迅猛的发展。

2、另一方面：Google 首先开发了自己的浏览器 Chrome，然后推出了新的 SPDY 协议，并在 Chrome 里应用于自家的服务器，如同十多年前的网景与微软一样，从实际的用户方来“倒逼”HTTP 协议的变革，这也开启了第二次的“浏览器大战”。

结局：

胜利者是 Google，Chrome 目前的全球的占有率超过了 60%。Google 借此顺势把 SPDY 推上了标准的宝座，**互联网标准化组织以 SPDY 为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2，RFC 编号 7540**。

特点：

**二进制协议，不再是纯文本**
**可发起多个请求，废弃了 1.1 里的管道**
**使用专用算法压缩头部，减少数据传输量**
**允许服务器主动向客户端推送数据**
**增强了安全性，“事实上”要求加密通信**
目前它的普及率还比较低，HTTP/1.1太过于经典和强势了，哈哈哈。。。



#### HTTP/3

在 HTTP/2 还处于草案之时，Google 又发明了一个新的协议，叫做 `QUIC`。

2018 年，互联网标准化组织 IETF 提议将“HTTP over QUIC”更名为“HTTP/3”并获得批准，HTTP/3 正式进入了标准化制订阶段。



#### HTTP的前世

HTTP 协议始于三十年前蒂姆·伯纳斯 - 李的一篇论文；

HTTP/0.9 是个简单的文本协议，只能获取文本资源；

HTTP/1.0 确立了大部分现在使用的技术，但它不是正式标准；

HTTP/1.1 是目前互联网上使用最广泛的协议，功能也非常完善；

HTTP/2 基于 Google 的 SPDY 协议，注重性能改善，但还未普及；

HTTP/3 基于 Google 的 QUIC 协议，是将来的发展方向。



![img](https://pic2.zhimg.com/80/v2-9659d122f0993ba815e3c637661687ed_720w.jpg)

随着网络技术的发展，1999 年设计的 HTTP/1.1 已经不能满足需求，所以 Google 在 2009 年设计了基于 TCP 的 SPDY，后来 SPDY 的开发组推动 SPDY 成为正式标准，不过最终没能通过。不过 SPDY 的开发组全程参与了 HTTP/2 的制定过程，参考了 SPDY 的很多设计，所以我们**一般认为 SPDY 就是 HTTP/2 的前身。无论 SPDY 还是 HTTP/2，都是基于 TCP 的**，TCP 与 UDP 相比效率上存在天然的劣势，所以 2013 年 Google 开发了**基于 UDP 的名为 QUIC 的传输层协议**，**QUIC 全称 Quick UDP Internet Connections**，希望它能替代 TCP，使得网页传输更加高效。后经**[提议](https://mailarchive.ietf.org/arch/msg/quic/RLRs4nB1lwFCZ_7k0iuz0ZBa35s)**，互联网工程任务组正式将基于 QUIC 协议的 HTTP （HTTP over QUIC）重命名为 HTTP/3。







### 02 |HTTP是什么？HTTP又不是什么？

#### HTTP 是什么

> **HTTP 就是超文本传输协议，也就是 `HyperText Transfer Protocol`。**

#### 协议

首先，HTTP 是一个协议。

> **HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。**

#### 传输

> **HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。**

**HTTP 是一个传输协议**，所谓的传输（Transfer）其实很好理解，就是把一堆东西从 A 点搬到 B 点，或者从 B 点搬到 A 点，即“A<===>B”。

第一点：**HTTP 协议是一个双向协议。**

也就是说，数据在A和B之间是双向流动，（一个叫请求方，另一个叫响应方）。

第二点：**没有限制只有 A 和 B 这两个角色，允许中间有“中转”或者“接力”。**

类似：A<=>X<=>Y<=>Z<=>B，例如：安全认证、数据压缩、编码转换等等功能。

#### 超文本

**超文本**：**文字、图片、音频和视频等的混合体，最关键的是含有“超链接”**，能够从一个“超文本”跳跃到另一个“超文本”，**形成复杂的非线性、网状的结构关系**。





#### HTTP 不是什么

**HTTP 是一个协议，是一种计算机间通信的规范，所以它不存在“单独的实体”**。它不是浏览器、手机 APP 那样的应用程序，也不是 Windows、Linux 那样的操作系统，更不是 Apache、Nginx、Tomcat 那样的 Web 服务器。

HTTP 不是互联网。

HTTP 不是编程语言。

HTTP 不是 HTML。

HTTP 不是一个孤立的协议。



**HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。**

#### 总结

1、HTTP 是一个用在计算机世界里的协议，它确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。

2、HTTP 专门用来在两点之间传输数据，不能用于广播、寻址或路由。

3、HTTP 传输的是文字、图片、音频、视频等超文本数据。

4、HTTP 是构建互联网的重要基础技术，它没有实体，依赖许多其他的技术来实现，但同时许多技术也都依赖于它。



**HTTP 是什么：HTTP 意思是超文本传输协议，HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。**



思维导图：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zdGF0aWMwMDEuZ2Vla2Jhbmcub3JnL3Jlc291cmNlL2ltYWdlLzI3L2NjLzI3ODE5MTllNzNmNWQyNThmZjFkYzM3MWFmNjMyYWNjLnBuZw?x-oss-process=image/format,png" alt="http思维导图" style="zoom: 50%;" />





### 03 |20HTTP世界全览（上）：与HTTP相关的各种概念

#### 网络世界

1、通常所说的“上网”实际上访问的只是互联网的一个子集“万维网”（World Wide Web）

**World Wide Web 它基于 HTTP 协议，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。**

2、互联网上还有许多万维网之外的资源

**例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。**

不过由于 **HTTP 协议非常灵活、易于扩展，而且“超文本”的表述能力很强，所以很多其他原本不属于 HTTP 的资源也可以“包装”成 HTTP 来访问**，这就是我们为什么能够总看到各种“网页应用”——例如“微信网页版”“邮箱网页版”——的原因。



#### 浏览器

> 浏览器的正式名字叫“`Web Browser`”，顾名思义，就是检索、查看互联网上网页资源的应用程序

**浏览器本质上是一个 HTTP 协议中的请求方，使用 HTTP 协议获取网络上的各种资源。集成了很多额外的功能**

比如：HTML 排版引擎用来展示页面，JavaScript 引擎用来实现动态化效果，甚至还有开发者工具用来调试网页，等等插件和扩展。

**在 HTTP 协议里，浏览器的角色被称为“User Agent”即“用户代理”，作为访问者的“代理”来发起 HTTP 请求。**



#### Web 服务器

**浏览器是 HTTP 里的请求方，另一端的应答方（响应方）就是服务器，Web Server**。

Web 服务器两个层面的含义：

**硬件**含义：物理形式或“云”形式的机器

**软件**含义：提供 Web 服务的应用程序

Apache、Nginx、Windows 上的 IIS、Java 的 Jetty/Tomcat 等



#### CDN

**CDN，全称Content Delivery Network（内容分发网络）。应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。**

好处：它可以**缓存源站的数据**。如果 CDN 的调度算法很优秀，更可以找到离用户最近的节点，**大幅度缩短响应时间**。

其他：CDN 除了基本的网络加速外，还提供负载均衡、安全防护、边缘计算、跨运营商网络等功能



#### 爬虫

“爬虫”（Crawler），实际上是一种可以**自动访问 Web 资源的应用程序**。

1、来源：绝大多数爬虫是由各大搜索引擎“放”出来的，抓取网页存入庞大的数据库，再建立关键字索引，这样我们才能够在搜索引擎中快速地搜索到互联网角落里的页面。

2、爬虫坏处：它会过度消耗网络资源，占用服务器和带宽，影响网站对真实数据的分析，甚至导致敏感信息泄漏。

3、“君子协定”：robots.txt约定哪些该爬，哪些不该爬。

4、基本技术：无论是“爬虫”还是“反爬虫”，用到的基本技术都是两个，一个是 HTTP，另一个就是 HTML。



#### HTML/WebService/WAF

1、**HTML 是 HTTP 协议传输的主要内容之一**，它描述了超文本页面，用各种“标签”定义文字、图片等资源和排版布局，最终由浏览器“渲染”出可视化页面。

2、Web Service：是一种由 W3C 定义的应用服务开发规范，使用 client-server 主从架构，通常使用 WSDL 定义服务接口，使用 HTTP 协议传输 XML 或 SOAP 消息，也就是说，它是一个基于 Web（HTTP）的服务架构技术，既可以运行在内网，也可以在适当保护后运行在外网。

3、**WAF：是“网络应用防火墙”**。与硬件“防火墙”类似，它是应用层面的“防火墙”，专门检测 HTTP 流量，是防护 Web 应用的安全技术。

WAF 通常位于 Web 服务器之前，可以阻止如 SQL 注入、跨站脚本等攻击，目前应用较多的一个开源项目是 ModSecurity，它能够完全集成进 Apache 或 Nginx。



### 04 HTTP世界全览（下）：与HTTP相关的各种协议.pdf

#### TCP/IP

> `TCP/IP` 协议是一系列网络[通信协议](https://so.csdn.net/so/search?q=通信协议&spm=1001.2101.3001.7020)的统称，**核心: TCP 和 IP，其他: UDP、ICMP、ARP 等等**。

#### IP

> IP 协议是`Internet Protocol`的缩写，**主要目的是解决寻址和路由问题**，以及如何在两点间传送数据包。

#### TCP

> TCP 协议是`Transmission Control Protocol`的缩写，即`传输控制协议`，**它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信。**



#### DNS

**域名系统（Domain Name System），用有意义的名字来作为 IP 地址的等价替代。**

1、在 DNS 中，域名（Domain Name）又称为主机名（Host）
2、域名用.分隔成多个单词，级别从左到右逐级升高，最右边的被称为顶级域名
3、表示商业公司的com，表示教育机构的edu，表示国家的cn,uk
4、把域名做一个转换，映射到它的真实 IP，这就是所谓的域名解析。





#### URI/URL

DNS 和 IP 地址只是标记了互联网上的主机，要访问网络上的资源就需要用到 URI。

**URI（Uniform Resource Identifier），即统一资源标识符，使用它就能够唯一地标记互联网上资源。**
**URL（Uniform Resource Locator）， 即统一资源定位符**，也就是俗称的网址，它实际上是 URI 的一个子集，两者几乎是相同的，差异不大，通常不会做严格的区分。



#### HTTPS

> `HTTP over SSL/TLS`，也就是运行在 `SSL/TLS` 协议上的 HTTP。

SSL：全称是Secure Socket Layer，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即Transport Layer Security，但由于历史的原因还是有很多人称之为 SSL/TLS，或者直接简称为 SSL。

SSL使用了许多密码学最先进的研究成果

对称加密
非对称加密
摘要算法
数字签名
数字证书…



#### 代理

> 代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为`中转站`，既可以转发客户端的请求，也可以转发服务器的应答。

**CDN，实际上就是一种代理，它代替源站服务器响应客户端的请求，通常扮演着透明代理和反向代理的角色。**

代理是 HTTP 传输过程中的中转站，可以实现：

负载均衡：把访问请求均匀分散到多台机器，实现访问集群化
内容缓存：暂存上下行的数据，减轻后端的压力
安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器
数据处理：提供压缩、加密等额外的功能





### 05 常说的“四层”和“七层”到底是什么？“五层”“六层”哪去了？

#### TCP/IP 网络分层模型

层次图如下：

![层次图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8xOC8xNmU3ZGYxY2IyOGZmYzhm?x-oss-process=image/format,png)

**第一层：链接层（link layer）**
负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，**使用 MAC 地址来标记网络上的设备**，所以有时候也叫 MAC 层。

**第二层：网际层或者网络互连层（internet layer）**
IP 协议就处在这一层。因为 IP 协议定义了IP 地址的概念，所以就可以在链接层的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。

**第三层：传输层（transport layer）**
保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次。

**TCP：是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复**
**UDP：则无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。**
**TCP 的数据是连续的字节流，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。**
第四层：应用层（application layer）
**有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP、HTTP。**

MAC 层的传输单位是帧（frame）。

IP 层的传输单位是包（packet）。

TCP 层的传输单位是段（segment）。

HTTP 的传输单位则是消息或报文（message）。

可以统称为数据包。



#### OSI 网络分层模型

> OSI，全称是`开放式系统互联通信参考模型`（`Open System Interconnection Reference Model`）。

OSI 模型分成了七层，如下图：

![OSI 模型](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8xOC8xNmU3ZGYxY2I1Y2Y1MTQ0?x-oss-process=image/format,png)



**第一层(物理层)**：网络的物理形式，例如电缆、光纤、网卡、集线器等等
**第二层(数据链路层)**：它基本相当于 TCP/IP 的链接层
**第三层(网络层)**：相当于 TCP/IP 里的网际层
**第四层(传输层)**：相当于 TCP/IP 里的传输层
**第五层(会话层)**：维护网络中的连接状态，即保持会话和同步
**第六层(表示层)**：把数据转换为合适、可理解的语法和语义
**第七层(应用层)**：面向具体的应用传输数据。



#### 两个分层模型的映射关系

大概的一个对应关系：

第一层：物理层，TCP/IP 里无对应
第二层：数据链路层，对应 TCP/IP 的链接层
第三层：网络层，对应 TCP/IP 的网际层
第四层：传输层，对应 TCP/IP 的传输层
第五、六、七层：统一对应到 TCP/IP 的应用层
**TCP/IP 实际应用时的会话管理、编码转换、压缩等和具体应用经常联系的很紧密，很难分开。例如：HTTP 协议就同时包含了连接管理和数据格式定义。**



![映射关系](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8xOC8xNmU3ZGYxY2IzY2FjOGRm?x-oss-process=image/format,png)





**四层负载均衡：就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。**

**七层负载均衡：就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。**

**小窍门（不是绝对的）：**

**“两个凡是”：凡是由操作系统负责处理的就是四层或四层以下，否则，凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层。**



#### TCP/IP 协议栈的工作方式

1、HTTP 协议的传输过程就是这样通过协议栈逐层向下，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去。

2、接收数据则是相反的操作，从下往上穿过协议栈，逐层拆包，每层去掉本层的专有头，上层就会拿到自己的数据。

![协议栈的工作方式](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8xOC8xNmU3ZGYxY2I2MzA2MzUx?x-oss-process=image/format,png)







### 06 域名里有哪些门道？

#### 域名的形式

1、域名是一个有层次的结构，是一串用.分隔的多个单词，最右边的被称为顶级域名，然后是二级域名，层级关系向左依次降低。

2、域名本质上还是个名字空间系统，使用多级域名就可以划分出不同的国家、地区、组织、公司、部门，每个域名都是独一无二的，可以作为一种身份的标识。

比如：极客时间的域名time.geekbang.org，org就是顶级域名，geekbang是二级域名，time则是主机名。

3、域名的总长度限制在253个字符以内，而每一级域名长度不能超过63个字符。

4、域名是大小写无关的，但是通常都使用小写的形式。



#### 域名的解析

就像 IP 地址必须转换成 MAC 地址才能访问主机一样，**域名也必须要转换成 IP 地址，这个过程就是域名解析**。



#### DNS 的核心系统

DNS 的核心系统：是一个三层的树状、分布式服务，基本对应域名的结构如下：

1、**根域名服务器（Root DNS Server）**：

管理顶级域名服务器，返回com、net、cn等顶级域名服务器的 IP 地址。

2、**顶级域名服务器（Top-level DNS Server）**：

管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址。

3、**权威域名服务器（Authoritative DNS Server）**：

管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址。



#### 两种方法减压

1、**缓存**：

1）、**许多大公司、网络运行商都会建立自己的 DNS 服务器**，作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。

2）、这些“野生”服务器被称为**非权威域名服务器**。可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址。

比较知名的DNS有：

Google：8.8.8.8
Microsoft：4.2.2.1
CloudFlare：1.1.1.1
2、**hosts文件**：

**操作系统里也会对 DNS 解析结果做缓存，它里面有一个特殊的主机映射文件，通常是一个可编辑的文本**：

在 Linux 里是/etc/hosts
在 Windows 里是C:\WINDOWS\system32\drivers\etc\hosts
如果操作系统在缓存里找不到 DNS 记录，就会找这个文件。



#### DNS解析的过程

浏览器DNS缓存–>操作系统缓存–>Hosts文件–>非权威域名服务器（缓存DNS服务器，比如我们每家每户上网设置的DNS服务器）–>根域名服务器–>顶级域名服务器–>权威域名服务器（域名注册商的DNS服务器）。



#### 域名的“新玩法”

1、**重定向**：

常用于服务器临时维护，DNS 修改内部的 IP 地址映射关系，保证业务服务正常运行。

2、**名字空间**：

使用开源软件搭建一个内部使用的DNS，作为名字服务器。这样我们开发的各种内部服务就都用域名来标记，发起网络通信时就不必在使用写死的 IP 地址。

3、**负载均衡**：

方式1：因为域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机，客户端收到多个 IP 地址后，就可以自己使用轮询算法依次向服务器发起请求，实现负载均衡。

方式2：域名解析可以配置内部的策略，返回离客户端最近的主机，或者返回当前服务质量最好的主机，这样在 DNS 端把请求分发到不同的服务器，实现负载均衡。

4、**恶意玩法**：

**域名屏蔽**：对域名直接不解析，返回错误，让你无法拿到 IP 地址，也就无法访问网站
**域名劫持**：也叫域名污染，你要访问 A 网站，但 DNS 给了你 B 网站。



1.在浏览器地址栏里随便输入一个不存在的域名，比如就叫“www.不存在com”，试着解释下它的DNS解析过程。

第一个问题：浏览器缓存->操作系统dnscache ->hosts文件->非权威域名服务器->根域名服务器->顶级域名服务器->二级域名服务器->权威域名服务器。
其中非权威域名服务器还包括LDNS（企业内网DNS服务器），三大营运商DNS，谷歌公开的DNS，微软公开的DNS等。



2.如果因为某些原因，DNS失效或者出错了，会出现什么后果?

第二个问题：如果dns失效或出错，那就访问不了了，客户端直接报“Failed host lookup”的错误





### 07 自己动手，搭建HTTP实验环境



### 08 键入网址再按下回车，后面究竟发生了什么？

**这一整个流程。**

（1）我们知道，HTTP协议是建立在TCP/IP基础上的，所以在利用HTTP传输数据之前，会先进行TCP/IP搭建，这里就对应到前三个包，通过SYN、SYN，ACK，ACK顺利搭建好了TCP/IP；

（2）紧接着，这时候浏览器按照 HTTP 协议规定的格式，通过 TCP 发送了一个“GET / HTTP/1.1”请求报文，也就是 Wireshark 里的第四个包。

（3）接着，服务器返给浏览器一个报文，说：'好的好的，我收到你的请求啦"，对应第五个包

（4）然后，服务器对浏览器发过来的报文进行处理，并将结果和处理结果返给浏览器，对应第6个包，这里304指的是该请求和之前的请求一样，因此从缓存中获取到了内容，直接返回给了浏览器。

（5）最后，浏览器收到查询结果后给服务器进行了回应，“好啦好啦我收到来自你的回复啦！”，对应最后一个包，整个三次握手过程结束。

**再简要叙述一下这次最简单的浏览器 HTTP 请求过程：**

浏览器从地址栏的输入中获得服务器的 IP 地址和端口号；
浏览器用 TCP 的三次握手与服务器建立连接；
浏览器向服务器发送拼好的报文；
服务器收到报文后处理请求，同样拼好报文再发给浏览器；
浏览器解析报文，渲染输出页面。





### 09 HTTP报文是什么样子的？

HTTP 协议基本工作流程，也就是“请求 - 应答”“一发一收”的模式。

可以看到，HTTP 的工作模式是非常简单的，由于 **TCP/IP 协议负责底层的具体传输工作**，HTTP 协议基本上不用在这方面操心太多。单从这一点上来看，所谓的“超文本传输协议”其实并不怎么管“传输”的事情，有点“名不副实”。

那么 HTTP 协议的**核心**部分是什么呢？

答案就是它**传输的报文内容**。

**HTTP 协议在规范文档里详细定义了报文的格式，规定了组成部分，解析规则，还有处理策略，所以可以在 TCP/IP 层之上实现更灵活丰富的功能，例如连接控制，缓存管理、数据编码、内容协商等等。**



#### 报文结构

你也许对 TCP/UDP 的报文格式有所了解，**拿 TCP 报文来举例，它在实际要传输的数据之前附加了一个 20 字节的头部数据，存储 TCP 协议必须的额外信息，例如发送方的端口号、接收方的端口号、包序号、标志位等等**。

有了这个附加的 TCP 头，数据包才能够正确传输，到了目的地后把头部去掉，就可以拿到真正的数据。

![image-20220209214008228](C:\Users\99512\AppData\Roaming\Typora\typora-user-images\image-20220209214008228.png)

HTTP 协议也是与 TCP/UDP 类似，同样也需要在实际传输的数据前附加一些头数据，不过与 TCP/UDP 不同的是，它是一个“**纯文本**”的协议，所以头数据都是 ASCII 码的文本，可以很容易地用肉眼阅读，不用借助程序解析也能够看懂。

HTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成：

**起始行（start line）**：描述请求或响应的基本信息；

**头部字段集合（header）**：使用 key-value 形式更详细地说明报文；

**消息正文（entity）**：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。

这其中前两部分起始行和头部字段经常又合称为“**请求头**”或“**响应头**”，消息正文又称为“**实体**”，但与“**header**”对应，很多时候就直接称为“**body**”。

**HTTP 协议规定报文必须有 header，但可以没有 body，而且在 header 之后必须要有一个“空行”，也就是“CRLF”，十六进制的“0D0A”。**

所以，一个完整的 HTTP 报文就像是下图的这个样子，注意在 header 和 body 之间有一个“空行”。

![image-20220209214152224](C:\Users\99512\AppData\Roaming\Typora\typora-user-images\image-20220209214152224.png)

##### 请求行

了解了 HTTP 报文的基本结构后，我们来看看请求报文里的起始行也就是**请求行**（request line），它简要地描述了**客户端想要如何操作服务器端的资源**。

请求行由三部分构成：

请求方法：是一个动词，如 GET/POST，表示对资源的操作；

请求目标：通常是一个 URI，标记了请求方法要操作的资源；

版本号：表示报文使用的 HTTP 协议版本。

这三个部分通常使用空格（space）来分隔，最后要用 CRLF 换行表示结束。

```
GET / HTTP/1.1
```

![image-20220209214327382](C:\Users\99512\AppData\Roaming\Typora\typora-user-images\image-20220209214327382.png)





##### 状态行

看完了请求行，我们再看响应报文里的起始行，在这里它不叫“响应行”，而是叫“**状态行**”（status line），意思是**服务器响应的状态**。

比起请求行来说，状态行要简单一些，同样也是由三部分构成：

**版本号**：表示报文使用的 HTTP 协议版本；

**状态码**：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误；

**原因**：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。



![image-20220209214433496](C:\Users\99512\AppData\Roaming\Typora\typora-user-images\image-20220209214433496.png)

```
HTTP/1.1 200 OK

HTTP/1.1 404 Not Found
```



##### 头部字段

请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头

![image-20220209214551434](C:\Users\99512\AppData\Roaming\Typora\typora-user-images\image-20220209214551434.png)

请求头和响应头的结构是基本一样的，唯一的区别是起始行，所以我把请求头和响应头里的字段放在一起介绍。

**头部字段是 key-value 的形式，key 和 value 之间用“:”分隔，最后用 CRLF 换行表示字段结束**。比如在“Host: 127.0.0.1”这一行里 key 就是“Host”，value 就是“127.0.0.1”。

HTTP 头字段非常灵活，不仅可以使用标准里的 Host、Connection 等已有头，也可以任意添加自定义头，这就给 HTTP 协议带来了无限的扩展可能。

不过使用头字段需要注意下面几点：

**字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好；**

**字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名；**

**字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格；**

**字段的顺序是没有意义的，可以任意排列不影响语义；**

**字段原则上不能重复，除非这个字段本身的语义允许，例如 Set-Cookie。**





#### 常用头字段

HTTP 协议规定了非常多的头部字段，实现各种各样的功能，但基本上可以分为四大类：

**通用字段**：在请求头和响应头里都可以出现；

**请求字段**：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；

**响应字段**：仅能出现在响应头里，补充说明响应报文的信息；

**实体字段**：它实际上属于通用字段，但专门描述 body 的额外信息。

**Host**字段，它属于请求字段，只能出现在请求头里，它同时也是唯一一个 HTTP/1.1 规范里要求**必须出现**的字段，也就是说，如果请求头里没有 Host，那这就是一个错误的报文。Host 字段告诉服务器这个请求应该由哪个主机来处理。

**User-Agent**是请求字段，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面。但由于历史的原因，User-Agent 非常混乱，每个浏览器都自称是“Mozilla”“Chrome”“Safari”，企图使用这个字段来互相“伪装”，导致 User-Agent 变得越来越长，最终变得毫无意义。

**Date**字段是一个通用字段，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。

**Server**字段是响应字段，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号。Server 字段也不是必须要出现的，因为这会把服务器的一部分信息暴露给外界。

实体字段里要说的一个是**Content-Length**，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输。

#### 小结

今天我们学习了 HTTP 的报文结构，下面做一个简单小结。

HTTP 报文结构就像是“大头儿子”，由“起始行 + 头部 + 空行 + 实体”组成，简单地说就是“header+body”；

HTTP 报文可以没有 body，但必须要有 header，而且 header 后也必须要有空行，形象地说就是“大头”必须要带着“脖子”；

请求头由“请求行 + 头部字段”构成，响应头由“状态行 + 头部字段”构成；

请求行有三部分：请求方法，请求目标和版本号；

状态行也有三部分：版本号，状态码和原因字符串；

头部字段是 key-value 的形式，用“:”分隔，不区分大小写，顺序任意，除了规定的标准头，也可以任意添加自定义字段，实现功能扩展；

HTTP/1.1 里唯一要求必须提供的头字段是 Host，它必须出现在请求头里，标记虚拟主机名。



1. 如果拼 HTTP 报文的时候，在头字段后多加了一个 CRLF，导致出现了一个空行，会发生什么？

答：空行后面的内容被当成了报文主体

2. 讲头字段时说“:”后的空格可以有多个，那为什么绝大多数情况下都只使用一个空格呢？

答：这时约定俗成的默认用法，按照rfc标准，空格可以是零个或多个，但一个空格已经成了约定俗成的习惯。头部多一个空格就会多一个传输的字节，去掉无用的信息，保证传输的头部字节数尽量小。







### 10丨应该如何理解请求方法？

上一讲我介绍了 HTTP 的报文结构，它是由 header+body 构成，请求头里有请求方法和请求目标，响应头里有状态码和原因短语，今天要说的就是**请求头里的请求方法。**

目前 HTTP/1.1 规定了八种方法，单词**都必须是大写的形式**，我先简单地把它们列出来，后面再详细讲解。

GET：获取资源，可以理解为读取或者下载数据；

HEAD：获取资源的元信息；

POST：向资源提交数据，相当于写入或上传数据；

PUT：类似 POST；

DELETE：删除资源；

CONNECT：建立特殊的连接隧道；

OPTIONS：列出可对资源实行的方法；

TRACE：追踪请求 - 响应的传输路径。

![img](https://img2020.cnblogs.com/blog/473210/202003/473210-20200325215246538-506034041.jpg)

#### **GET/HEAD**

GET它的含义是请求**从服务器获取资源**

   **HEAD**方法与 GET 方法类似，也是请求从服务器获取资源，服务器的处理机制也是一样的，但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的“元信息”。

​    HEAD 方法可以看做是 GET 方法的一个“简化版”或者“轻量版”。因为它的响应头与 GET 完全相同，所以可以用在很多并不真正需要资源的场合，避免传输 body 数据的浪费。

​    比如，想要检查一个文件是否存在，只要发个 HEAD 请求就可以了，没有必要用 GET 把整个文件都取下来。再比如，要检查文件是否有最新版本，同样也应该用 HEAD，服务器会在响应头里把文件的修改时间传回来。



#### **POST/PUT**

​    接下来要说的是**POST**和**PUT**方法，这两个方法也很像。

​    GET 和 HEAD 方法是从服务器获取数据，而 POST 和 PUT 方法则是相反操作，向 URI 指定的资源提交数据，数据就放在报文的 body 里。

​    POST 也是一个经常用到的请求方法，使用频率应该是仅次于 GET，应用的场景也非常多，只要向服务器发送数据，用的大多数都是 POST。

PUT 的作用与 POST 类似，也可以向服务器提交数据，但与 POST 存在微妙的不同，通常 POST 表示的是“新建”“create”的含义，而 PUT 则是“修改”“update”的含义。



#### **其他方法**

​    讲完了 GET/HEAD/POST/PUT，还剩下四个标准请求方法，它们属于比较“冷僻”的方法，应用的不是很多。

​    **DELETE**方法指示服务器删除资源，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 DELETE 请求。

​    **CONNECT**是一个比较特殊的方法，要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。

​    **OPTIONS**方法要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持。

​    **TRACE**方法多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用。

#### **扩展方法**

​    虽然 HTTP/1.1 里规定了八种请求方法，但它并没有限制我们只能用这八种方法，这也体现了 HTTP 协议良好的扩展性，我们可以任意添加请求动作，只要请求方和响应方都能理解就行。



#### **安全与幂等**

​    关于请求方法还有两个面试时有可能会问到、比较重要的概念：**安全**与**幂等**。

​    在 HTTP 协议里，所谓的“**安全**”是指请求方法不会“破坏”服务器上的资源，即不会对服务器上的资源造成实质的修改。

​    按照这个定义，只有 GET 和 HEAD 方法是“安全”的，因为它们是“只读”操作，只要服务器不故意曲解请求方法的处理方式，无论 GET 和 HEAD 操作多少次，服务器上的数据都是“安全的”。

​    而 POST/PUT/DELETE 操作会修改服务器上的资源，增加或删除数据，所以是“不安全”的。

​    所谓的“**幂等**”实际上是一个数学用语，被借用到了 HTTP 协议里，意思是多次执行相同的操作，结果也都是相同的，即多次“幂”后结果“相等”。

​    很显然，GET 和 HEAD 既是安全的也是幂等的，DELETE 可以多次删除同一个资源，效果都是“资源不存在”，所以也是幂等的。

​    POST 和 PUT 的幂等性质就略费解一点。

​    按照 RFC 里的语义，POST 是“新增或提交数据”，多次提交数据会创建多个资源，所以不是幂等的；而 PUT 是“替换或更新数据”，多次更新一个资源，资源还是会第一次更新的状态，所以是幂等的。



#### **小结**

今天我们学习了 HTTP 报文里请求方法相关的知识，简单小结一下。

请求方法是客户端发出的、要求服务器执行的、对资源的一种操作；

请求方法是对服务器的“指示”，真正应如何处理由服务器来决定；

最常用的请求方法是 GET 和 POST，分别是获取数据和发送数据；

HEAD 方法是轻量级的 GET，用来获取资源的元信息；

PUT 基本上是 POST 的同义词，多用于更新数据；

“安全”与“幂等”是描述请求方法的两个重要属性，具有理论指导意义





### 11丨你能写出正确的网址吗？

URI，也就是**统一资源标识符**（**U**niform **R**esource **I**dentifier）

URL——**统一资源定位符**（**U**niform **R**esource **L**ocator）

 URI 本质上是一个字符串，这个字符串的作用是**唯一地标记资源的位置或者名字**。

这里我要提醒你注意，它不仅能够标记万维网的资源，也可以标记其他的，如邮件系统、本地文件系统等任意资源。而“资源”既可以是存在磁盘上的静态文本、页面数据，也可以是由 Java、PHP 提供的动态服务。

​    下面的这张图显示了 URI 最常用的形式，由 scheme、host:port、path 和 query 四个部分组成，但有的部分可以视情况省略。



![img](https://img2020.cnblogs.com/blog/473210/202003/473210-20200326212840284-825205063.png)

#### URI 的基本组成

​    URI 第一个组成部分叫**scheme**，翻译成中文叫“**方案名**”或者“**协议名**”，表示**资源应该使用哪种协议**来访问。

​    最常见的当然就是“http”了，表示使用 HTTP 协议。另外还有“https”，表示使用经过加密、安全的 HTTPS 协议。此外还有其他不是很常见的 scheme，例如 ftp、ldap、file、news 等。

​    浏览器或者你的应用程序看到 URI 里的 scheme，就知道下一步该怎么走了，会调用相应的 HTTP 或者 HTTPS 下层 API。显然，如果一个 URI 没有提供 scheme，即使后面的地址再完善，也是无法处理的。

​    在 scheme 之后，必须是**三个特定的字符**“**://**”，它把 scheme 和后面的部分分离开。

在“://”之后，是被称为“**authority**”的部分，表示**资源所在的主机名**，通常的形式是“host:port”，即主机名加端口号。

​    主机名可以是 IP 地址或者域名的形式，必须要有，否则浏览器就会找不到服务器。但端口号有时可以省略，浏览器等客户端会依据 scheme 使用默认的端口号，例如 HTTP 的默认端口号是 80，HTTPS 的默认端口号是 443。

   有了协议名和主机地址、端口号，再加上后面**标记资源所在位置**的**path**，浏览器就可以连接服务器访问资源了。

​    URI 里 path 采用了类似文件系统“目录”“路径”的表示方式，因为早期互联网上的计算机多是 UNIX 系统，所以**采用了 UNIX 的“/”风格**。其实也比较好理解，它与 scheme 后面的“://”是一致的。

​    这里我也要再次提醒你注意，URI 的 path 部分必须以“/”开始，也就是必须包含“/”，不要把“/”误认为属于前面 authority。



例子：

```
https://tools.ietf.org/html/rfc7230
 	
file:///D:/http_study/www/
```

第一个是 HTTP 协议标准文档 RFC7230 的 URI，主机名是“tools.ietf.org”，路径是“/html/rfc7230”。

最后一个 URI 要注意了，它的协议名不是“http”，而是“**file**”，表示这是本地文件，而后面居然有三个斜杠，这是怎么回事？

如果你刚才仔细听了 scheme 的介绍就能明白，**这三个斜杠里的前两个属于 URI 特殊分隔符“://”，然后后面的“/D:/http_study/www/”是路径，而中间的主机名被“省略”了。这实际上是 file 类型 URI 的“特例”，它允许省略主机名，默认是本机 localhost。**

**但对于 HTTP 或 HTTPS 这样的网络通信协议，主机名是绝对不能省略的。原因之前也说了，会导致浏览器无法找到服务器。**



#### URI 的查询参数

​    使用“协议名 + 主机名 + 路径”的方式，已经可以精确定位网络上的任何资源了。但这还不够，很多时候我们还想在操作资源的时候附加一些额外的修饰参数。

仅用“协议名 + 主机名 + 路径”的方式是无法适应这些场景的，所以 URI 后面还有一个“**query**”部分，它在 path 之后，用一个“?”开始，但不包含“?”，表示对资源附加的额外要求。这是个很形象的符号，比“://”要好的多，很明显地表示了“查询”的含义。

​    查询参数 query 有一套自己的格式，是多个“**key=value**”的字符串，这些 KV 值用字符“**&**”连接，浏览器和客户端都可以按照这个格式把长串的查询参数解析成可理解的字典或关联数组形式。

还有，某些特殊的 URI，会在 path、query 里出现“@&?"等起界定符作用的字符，会导致 URI 解析错误，这时又该怎么办呢？

​    所以，URI 引入了编码机制，对于 ASCII 码以外的字符集和特殊字符做一个特殊的操作，把它们转换成与 URI 语义不冲突的形式。这在 RFC 规范里称为“escape”和“unescape”，俗称“转义”。

​    URI 转义的规则有点“简单粗暴”，**直接把非 ASCII 码或特殊字符转换成十六进制字节值，然后前面再加上一个“%”**。

​    例如，空格被转义成“%20”，“?”被转义成“%3F”。**而中文、日文等则通常使用 UTF-8 编码后再转义**



#### 小结

今天我们学习了网址也就是 URI 的知识，在这里小结一下今天的内容。

URI 是用来唯一标记服务器上资源的一个字符串，通常也称为 URL；

URI 通常由 scheme、host:port、path 和 query 四个部分组成，有的可以省略；

scheme 叫“方案名”或者“协议名”，表示资源应该使用哪种协议来访问；

“host:port”表示资源所在的主机名和端口号；

path 标记资源所在的位置；

query 表示对资源附加的额外要求；

在 URI 里对“@&/”等特殊字符和汉字必须要做编码，否则服务器收到 HTTP 报文后会无法正确处理。





### 12丨响应状态码该怎么用？

#### 状态码

​    目前 RFC 标准里规定的状态码是三位数，所以取值范围就是从 000 到 999。但如果把代码简单地从 000 开始顺序编下去就显得有点太“low”，不灵活、不利于扩展，所以状态码也被设计成有一定的格式。

​    RFC 标准把状态码分成了五类，用数字的第一位表示分类，而 0~99 不用，这样状态码的实际可用范围就大大缩小了，由 000~999 变成了 100~599。

这五类的具体含义是：

**1××：提示信息**，表示目前是协议处理的中间状态，还需要后续的操作；

**2××：成功**，报文已经收到并被正确处理；

**3××：重定向**，资源位置发生变动，需要客户端重新发送请求；

**4××：客户端错误**，请求报文有误，服务器无法处理；

**5××：服务器错误**，服务器在处理请求时内部发生了错误。

 在 HTTP 协议中，正确地理解并应用这些状态码不是客户端或服务器单方的责任，而是双方共同的责任。



接下来我就挑一些实际开发中比较有价值的状态码逐个详细介绍。

1××

​    1××类状态码属于提示信息，是协议处理的中间状态，实际能够用到的时候很少。

我们偶尔能够见到的是“**101 Switching Protocols**”。它的意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。

2××

​    2××类状态码表示服务器收到并成功处理了客户端的请求，这也是客户端最愿意看到的状态码。

​    “**200 OK**”是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果，如果是非 HEAD 请求，通常在响应头后都会有 body 数据。

​    “**204 No Content**”是另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但**响应头后没有 body 数据**。所以对于 Web 服务器来说，正确地区分 200 和 204 是很必要的。

​    “**206 Partial Content**”是 **HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现**，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。

​    状态码 206 通常还会伴随着头字段“**Content-Range**”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。

3××

​    3××类状态码表示客户端请求的资源发生了变动，客户端必须用新的 URI 重新发送请求获取资源，也就是通常所说的“重定向”，包括著名的 301、302 跳转。

​    “**301 Moved Permanently**”俗称“永久重定向”，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问。

​    与它类似的是“**302 Found**”，曾经的描述短语是“**Moved Temporarily**”，俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。

​    301 和 302 都会在响应头里使用字段**Location**指明后续要跳转的 URI，最终的效果很相似，浏览器都会重定向到新的 URI。两者的根本区别在于语义，一个是“永久”，一个是“临时”，所以在场景、用法上差距很大。

​    比如，你的网站升级到了 HTTPS，原来的 HTTP 不打算用了，这就是“永久”的，所以要配置 301 跳转，把所有的 HTTP 流量都切换到 HTTPS。

​    再比如，今天夜里网站后台要系统维护，服务暂时不可用，这就属于“临时”的，可以配置成 302 跳转，把流量临时切换到一个静态通知页面，浏览器看到这个 302 就知道这只是暂时的情况，不会做缓存优化，第二天还会访问原来的地址。

“**304 Not Modified**” 是一个比较有意思的状态码，它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“**缓存重定向**”）。

301、302 和 304 分别涉及了 HTTP 协议里重要的“重定向跳转”和“缓存控制”，在之后的课程中我还会细讲。

4××

​    4××类状态码表示客户端发送的请求报文有误，服务器无法处理，它就是真正的“错误码”含义了。

​    “**400 Bad Request**”是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误，客户端看到 400 只会是“一头雾水”“不知所措”。所以，在开发 Web 应用时应当尽量避免给客户端返回 400，而是要用其他更有明确含义的状态码。

​    “**403 Forbidden**”实际上不是客户端的请求出错，而是表示服务器禁止访问资源。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以在 body 里详细说明拒绝请求的原因，不过现实中通常都是直接给一个“闭门羹”。

​    “**404 Not Found**”可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端。但现在已经被“用滥了”，只要服务器“不高兴”就可以给出个 404，而我们也无从得知后面到底是真的未找到，还是有什么别的原因，某种程度上它比 403 还要令人讨厌。

​    4××里剩下的一些代码较明确地说明了错误的原因，都很好理解，开发中常用的有：

405 Method Not Allowed：不允许使用某些方法操作资源，例如不允许 POST 只能 GET；

406 Not Acceptable：资源无法满足客户端请求的条件，例如请求中文但只有英文；

408 Request Timeout：请求超时，服务器等待了过长的时间；

409 Conflict：多个请求发生了冲突，可以理解为多线程并发时的竞态；

**413 Request Entity Too Large：请求报文里的 body 太大；**

414 Request-URI Too Long：请求行里的 URI 太大；

429 Too Many Requests：客户端发送了太多的请求，通常是由于服务器的限连策略；

431 Request Header Fields Too Large：请求头某个字段或总体太大；

5××

​    5××类状态码表示客户端请求报文正确，但服务器在处理时内部发生了错误，无法返回应有的响应数据，是服务器端的“错误码”。

​    “**500 Internal Server Error**”与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析。

​    “**501 Not Implemented**”表示客户端请求的功能还不支持，这个错误码比 500 要“温和”一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了。

​    “**502 Bad Gateway**”通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的。

​    “**503 Service Unavailable**”表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503。

​    503 是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个“**Retry-After**”字段，指示客户端可以在多久以后再次尝试发送请求。





### 13 |HTTP有哪些特点？

#### 灵活可扩展

首先， HTTP 协议是一个“灵活可扩展”的传输协议。

#### 可靠传输

第二个特点， HTTP 协议是一个“可靠”的传输协议。

#### 应用层协议

第三个特点，HTTP 协议是一个应用层的协议。

#### 请求 - 应答

第四个特点，HTTP 协议使用的是请求 - 应答通信模式。



### 14丨 HTTP有哪些优点？又有哪些缺点？

#### 小结

HTTP 最大的优点是**简单、灵活和易于扩展**；

HTTP 拥有成熟的软硬件环境，**应用的非常广泛**，是互联网的基础设施；

HTTP 是**无状态**的，可以轻松实现集群化，扩展性能，但有时也需要用 Cookie 技术来实现“有状态”；

HTTP 是**明文传输**，数据完全肉眼可见，能够方便地研究分析，但也容易被窃听；

HTTP 是**不安全的**，无法验证通信双方的身份，也不能判断报文是否被窜改；

HTTP 的**性能不算差**，但不完全适应现在的互联网，还**有很大的提升空间**。

虽然 HTTP 免不了这样那样的缺点，但你也不要怕，别忘了它有一个最重要的“灵活可扩展”的优点，所有的缺点都可以在这个基础上想办法解决，接下来的“进阶篇”和“安全篇”就会讲到。





## 进阶篇 (8讲)

### 15丨海纳百川：HTTP的实体数据

#### 小结

今天我们学习了 HTTP 里的数据类型和语言类型，在这里为今天的内容做个小结。

![img](https://img2020.cnblogs.com/blog/473210/202004/473210-20200401224923183-1916295279.png)

**数据类型表示实体数据的内容**是什么，**使用的是 MIME type，相关的头字段是 Accept 和 Content-Type**；

**数据编码表示实体数据的压缩方式**，**相关的头字段是 Accept-Encoding 和 Content-Encoding；**

**语言类型**表示实体数据的自然语言，**相关的头字段是 Accept-Language 和 Content-Language；**

**字符集表示实体数据的编码方式**，相关的**头字段是 Accept-Charset 和 Content-Type；**

客户端需要在**请求头里使用 Accept 等头字段与服务器进行“内容协商”**，要求服务器返回最合适的数据；

**Accept 等头字段可以用“,”顺序列出多个可能的选项，还可以用“;q=”参数来精确指定权重**。







### 16丨把大象装进冰箱：HTTP传输大文件的方法

#### 数据压缩

如果你还有印象的话，肯定能够想到一个最基本的解决方案，那就是“**数据压缩**”，把大象变成小猪佩奇，再放进冰箱。

​    通常浏览器在发送请求时都会带着“**Accept-Encoding**”头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进“**Content-Encoding**”响应头里，再把原数据压缩后发给浏览器。

​    如果压缩率能有 50%，那么就相当于在带宽不变的情况下网速提升了一倍，加速的效果是非常明显的。

​    不过这个解决方法也有个缺点，**gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了**。

​    **不过数据压缩在处理文本的时候效果还是很好的**，所以各大网站的服务器都会使用这个手段作为“保底”。例如，在 Nginx 里就会使用“gzip on”指令，启用对“text/html”的压缩。

#### 分块传输

如果大文件整体不能变小，那就把它“拆开”，分解成多个小块，把这些小块分批发给浏览器，浏览器收到后再组装复原。

这样浏览器和服务器都不用在内存里保存文件的全部，每次只收发一小部分，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。

​    这种“**化整为零**”的思路在 HTTP 协议里就是“**chunked**”分块传输编码，在响应报文里用头字段“**Transfer-Encoding: chunked**”来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。

这就好比是用魔法把大象变成“乐高积木”，拆散了逐个装进冰箱，到达目的地后再施法拼起来“满血复活”。

​    分块传输也可以用于“流式数据”，例如由数据库动态生成的表单页面，这种情况下 body 数据的长度是未知的，无法在头字段“**Content-Length**”里给出确切的长度，所以也只能用 chunked 方式分块发送。

“Transfer-Encoding: chunked”和“Content-Length”这两个字段是**互斥的**，也就是说响应报文里这两个字段不能同时出现，**一个响应报文的传输要么是长度已知，要么是长度未知（chunked）**，这一点你一定要记住。

下面我们来看下分块传输的编码规则，其实也很简单，同样采用了明文的方式，很类似响应头。

1. 每个分块包含两个部分，长度头和数据块；
2. 长度头是以CRLF（回车换行，即\r\n）结尾的一行明文，用16进制数字表示长度；
3. 数据块紧跟在长度头后，最后也用CRLF结尾，但数据不包含CRLF；
4. 最后用一个长度为0的块表示结束，即“0\r\n\r\n”。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ccc350b47b7d4d0a9fb7740905a8cbd2~tplv-k3u1fbpfcp-watermark.awebp)



#### 范围请求

有的时候，不需要全部的数据只需求其中的部分请求时，可使用范围请求。允许客户端在请求头里使用专用字段来表示只获取文件的一部分。

**范围请求不是Web服务器必备的功能，所以服务器必须在响应头里使用字段“Accept-Range：bytes”明确告知客户端：我是支持范围请求的。不支持的话就发送“Accept-Range：none”或者不发送Accept-Range字段。**

**请求头Range是HTTP范围请求的专用字段**，**格式是“bytes=x-y”**，其中x，y是以字节为单位的数据范围。x，y表示的是“偏移量”，范围必须从0计数。例：前10个字节是0-9

Range的格式很灵活，起点x和终点y可以省略：

- “0-”表示从文档起点到文档终点，即整个文件；
- “10-”从第10个字节开始到文档末尾
- “-1”是文档的最后一个字节
- “-10”是从文档末尾倒数10个字节

服务器收到Range字段后，需要做四件事：

1. **它必须检查范围是否合法**，比如文件只有100个字节，但请求“200-300”，这就是范围越界了。服务器就会返回状态码416，意思是“你请求的范围有误，我无法处理，请再检查一下”。
2. 如果范围正确，**服务器就可以根据Range头计算偏移量**，读取文件的片段了，**返回状态码“206 Partical Content”**，跟200的意思差不多，但表示body只是原数据的一部分。
3. **服务器要添加一个响应头字段Content-Range，**告诉片段的实际偏移量和资源的总大小，**格式是“bytes x-y/length”**，与Range头区别在没有“=”，范围后多了总长度。例如，对于“0-10”的范围请求，值就是“bytes 0-10/100”。
4. 最后就是**发送数据**了，直接把片段用TCP发给客户端，一个范围请求就算是处理完了。

#### 多段数据

在Range头里使用多个“x-y”，一次性获取获取多个片段数据。

这种情况需要使用一种特殊的MIME类型：“multipart/byteranges”，表示报文的boby是由多段字节序列组成的，并且还要用一个参数“boundary=xxx”给出段之间的分隔标记。

多段数据的格式与分块传输也比较类似，但它需要用分隔标记boundary来区分不同的分段，可以通过图来对比下：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/efbd50cad4da4d53878fa2713a855981~tplv-k3u1fbpfcp-watermark.awebp)

每一个分段必须以“- -boundary”开始（前面加两个“-”），之后要用“Content-Type”和“Content-Range”标记这段数据的类型和所在范围，然后就像普通的响应头一样以回车换行结束，再加上分段数据，最后用一个“- -boundary- -”（前后各有两个“-”）表示所有的分段结束。



#### 小结

今天我们学习了 HTTP 传输大文件相关的知识，在这里做一下简单小结：

**压缩** HTML 等文本文件是传输大文件最基本的方法；

**分块传输**可以流式收发数据，节约内存和带宽，使用响应头字段“Transfer-Encoding: chunked”来表示，分块的格式是 16 进制长度头 + 数据块；

**范围请求可以只获取部分数据**，即“分块请求”，实现视频拖拽或者断点续传，使用请求头字段“Range”和响应头字段“Content-Range”，**响应状态码必须是 206；**

**也可以一次请求多个范围**，这时候响应报文的数据类型是“multipart/byteranges”，body 里的多个部分会用 boundary 字符串分隔。

要注意这四种方法不是互斥的，而是可以混合起来使用，例如压缩后再分块传输，或者分段后再分块。



Q：分块传输数据的时候，如果数据里含有回车换行（\r\n）是否会影响分块的处理呢？

A：不会影响，因为分块前有数据长度说明

Q：如果对一个被 gzip 的文件执行范围请求，比如“Range: bytes=10-19”，那么这个范围是应用于原文件还是压缩后的文件呢？

A：看原文件是什么形式。如果原来的文件是gzip的，那就正确。如果原文件是文本，而是在传输过程中被压缩，那么就应用于压缩前的数据。总之，range是针对原文件的。





### 17丨排队也要讲效率

#### 短连接 

HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程也采用了简单的“请求 - 应答”方式。

​    它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。

​    因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“**短连接**”（short-lived connections）。早期的 HTTP 协议也被称为是“**无连接**”的协议。

​    **短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。TCP 建立连接要有“三次握手”，发送 3 个数据包，需要 1 个 RTT；关闭连接是“四次挥手”，4 个数据包需要 2 个 RTT**。

​    而 HTTP 的一次简单“请求 - 响应”通常只需要 4 个包，如果不算服务器内部的处理时间，最多是 2 个 RTT。这么算下来，浪费的时间就是“3÷5=60%”，有三分之二的时间被浪费掉了，**传输效率低**得惊人。

#### 长连接

针对短连接暴露出的缺点，HTTP 协议就提出了“**长连接**”的通信方式，也叫“持久连接”（persistent connections）、“连接保活”（keep alive）、“**连接复用**”（connection reuse）。

​    其实解决办法也很简单，用的就是“**成本均摊**”的思路，既然 TCP 的连接和关闭非常耗时间，那么就**把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上**。

#### 连接相关的头字段

**HTTP/1.1中的连接都会默认启用长连接。也可以在请求头里明确地要求使用长连接机制，使用的字段是Connection，值是“keep-alive”**。不过不管客户端是否显示要求长连接，如果服务器支持长连接，它总会在**响应报文里放一个“Connection：keep-alive”**字段，告诉客户端：“我是支持长连接的，接下来就用这个TCP一直收发数据吧”。

**长连接的缺点是，如果TCP连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源**。所以长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到。

在客户端，**可以在请求头里加上“Connection：close”字段，告诉服务器：“这次通信后就关闭连接”**。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用Socket API关闭TCP连接。

服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式：

1. **使用“keepalive_timeout”指令**，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。
2. **使用“keepalive_requests”指令**，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。

另外，客户端和服务器都可以在报文里附加通用头字段“Keep-Alive: timeout=value”，限定长连接的超时时间。但这个字段的约束力并不强，通信的双方可能并不会遵守，所以不太常见。

#### 队头阻塞

“队头阻塞”（Head-of-line  blocking）与短连接和长连接无关，而是因为**HTTP规定报文必须是“一发一收”**，这就形成了一个先进先出的“串行”队列。**如果队首的请求因为处理的太慢耽误了时间，那么后面的请求也不得不跟着一起等待**。

#### 性能优化

因为“请求-应答”模型不能变，所以“队头阻塞”问题在HTTP/1.1里无法解决，只能缓解。缓解的方法就是“**并发连接**”，也就是同时**对一个域名发起多个长连接，用数据来解决质量的问题。**但是，HTTP协议建议客户端使用并发，但不能“滥用”并发，所以对并发数有限制（6~8）。

**域名分片**（domain  sharing）：由于HTTP协议和浏览器限制并发连接数量，那我就**多开几个域名，都指向同一台服务器**，这样实际连接的数量就又上去了。



### 18丨四通八达：HTTP的重定向和跳转

跳转动作是由浏览器的使用者主动发起的，可以称为“**主动跳转**”，但还有一类跳转是由服务器来发起的，浏览器使用者无法控制，相对地就可以称为“**被动跳转**”，这在 HTTP 协议里有个专门的名词，叫做“**重定向**”（Redirection）。

#### 重定向的过程

 “**Location**”字段属于响应字段，必须出现在响应报文里。但只有配合 301/302 状态码才有意义，它**标记了服务器要求重定向的 URI**，这里就是要求浏览器跳转到“index.html”。

**浏览器收到 301/302 报文，会检查响应头里有没有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接。**

在“Location”里的 URI 既可以使用绝对 URI，也可以使用相对 URI。所谓“绝对 URI”，就是完整形式的 URI，包括 scheme、host:port、path 等。所谓“相对 URI”，就是省略了 scheme 和 host:port，只有 path 和 query 部分，是不完整的，但可以从请求上下文里计算得到。

#### 重定向状态码

**301**俗称“**永久重定向**”（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，今后的所有请求都必须改用新的 URI。

​    **浏览器看到 301，就知道原来的 URI“过时”了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。**

**302**俗称“**临时重定向**”（“Moved Temporarily”），意思是原 URI 处于“临时维护”状态，新的 URI 是起“顶包”作用的“临时工”。

​    **浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以只会执行简单的跳转页面**，不记录新的 URI，也不会有其他的多余动作，下次访问还是用原 URI。

301/302 是最常用的重定向状态码，在 3××里剩下的几个还有：

303 See Other：类似 302，但要求重定向后的请求改为 GET 方法，访问一个结果页面，避免 POST/PUT 重复操作；

307 Temporary Redirect：类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确；

308 Permanent Redirect：类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义。

​    不过这三个状态码的接受程度较低，有的浏览器和服务器可能不支持，开发时应当慎重。

301 的含义是“**永久**”的。

​    如果域名、服务器、网站架构发生了大幅度的改变，比如启用了新域名、服务器切换到了新机房、网站目录层次重构，这些都算是“永久性”的改变。原来的 URI 已经不能用了，必须用 301“永久重定向”，通知浏览器和搜索引擎更新到新地址，这也是搜索引擎优化（SEO）要考虑的因素之一。

302 的含义是“**临时**”的。

​    原来的 URI 在将来的某个时间点还会恢复正常，常见的应用场景就是系统维护，把网站重定向到一个通知页面，告诉用户过一会儿再来访问。另一种用法就是“服务降级”，比如在双十一促销的时候，把订单查询、领积分等不重要的功能入口暂时关闭，保证核心服务能够正常运行。

#### 重定向的相关问题

第一个问题是“**性能损耗**”。很明显，重定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次。

第二个问题是“**循环跳转**”。所以 HTTP 协议特别规定，浏览器必须具有检测“循环跳转”的能力。

#### 小结

今天我们学习了 HTTP 里的重定向和跳转，简单小结一下这次的内容：

**重定向是服务器发起的跳转，要求客户端改用新的 URI 重新发送请求，通常会自动进行，用户是无感知的；**

**301/302 是最常用的重定向状态码**，分别是“永久重定向”和“临时重定向”；

**响应头字段 Location 指示了要跳转的 URI**，可以用绝对或相对的形式；

重定向可以把一个 URI 指向另一个 URI，也可以把多个 URI 指向同一个 URI，用途很多；

使用重定向时需要当心性能损耗，还要避免出现循环跳转。



Q：301 和 302 非常相似，试着用自己的理解再描述一下两者的异同点。

A：**301用于废弃原地址跳转新地址，302用于暂时无法访问原地址跳转新地址**，两者都需要浏览器重新发起一次请求

Q：你能结合自己的实际情况，再列出几个应当使用重定向的场景吗？

A：**未登录跳转登录**；web升级，在升级过程中要展示升级进度，可以重定向到另一个服务来展示升级的进度



### 19丨让我知道你是谁：HTTP的Cookie机制

HTTP 协议是可扩展的，后来发明的 Cookie 技术，给 HTTP 增加了“记忆能力”。

#### 什么是 Cookie？

HTTP的Cookie机制，相当于是服务器给每个客户端都贴上一张小纸条，上面写了一些只有服务器才能理解的数据，需要的时候客户端把这些信息发给服务器，服务器看到 Cookie，就能够认出对方是谁了。

### Cookie 的工作过程

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b0e17ef89bea448db25b66c4bc28b581~tplv-k3u1fbpfcp-watermark.awebp)

1. 当用户通过**浏览器**第一次访问服务器的时候，服务器肯定是不知道他的身份的。所以，就要**创建一个独特的身份标识数据，格式是”key=value“，然后放进Set-Cookie字段里，随着响应报文一同发给浏览器**。（服务器有时会在响应头里添加多个Set-Cookie，存储多个”key=value“。但浏览器这边发送时不需要用多个Cookie字段，只要在一行里用”；“隔开就行）
2. 浏览器**收到响应报文，看到里面有Set-Cookie，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进Cookie字段里发给服务器**。
3. 因为第二次请求里面有了Cookie字段，**服务器**就知道这个用户不是新人，之前来过，就可以**拿出Cookie里的值，识别出用户的身份，然后提供个性化的服**务。

**Cookie是”浏览器绑定“的，只能在本浏览器内生效。**

#### Cookie 的属性

​    说到这里，你应该知道了，**Cookie 就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息**。所以，就**需要在“key=value”外再用一些手段来保护，防止外泄或窃取，这些手段就是 Cookie 的属性**。

首先，我们应该**设置Cookie的生存周期**，也就是它的有效期，可以使用Expires和Max-Age两个属性来设置。

- **”Expires“俗称”过期时间“，用的是绝对时间**，可以理解为deadline
- **”Max-Age“用的是相对时间**，单位是秒，浏览器用收到报文的时间点再加上Max-Age，就可以得到失效的绝对时间。

Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，但浏览器会优先采用 Max-Age 计算失效期。

####  Cookie 的作用域

其次，我们需要**设置 Cookie 的作用域**，让浏览器仅发送给特定的服务器和 URI，避免被其他网站盗用。

​    作用域的设置比较简单，“**Domain**”和“**Path**”指定了 Cookie 所属的域名和路径，浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie。

#### **Cookie** **的安全性**

**”HttpOnly“**：此Cookie**只能通过浏览器HTTP协议传输，禁止其他方式访问**，浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API，脚本攻击也就无从谈起了。

**”SameSite“**：**可以防范“跨站请求伪造”（XSRF）攻击**，设置成“SameSite=Strict”可以严格限定 Cookie 不能随着跳转链接跨站发送，而“SameSite=Lax”则略宽松一点，允许 GET/HEAD 等安全方法，但禁止 POST 跨站发送。

**”Secure”**：**表示这个Cookie仅能用HTTPS协议加密传输**，明文的HTTP协议会禁止发送。但Cookie本身不是加密的，浏览器里还是以明文的形式存在。

Chrome 开发者工具是查看 Cookie 的有力工具，在“Network-Cookies”里可以看到单个页面 Cookie 的各种属性，另一个“Application”面板里则能够方便地看到全站的所有 Cookie。

#### Cookie的应用

1. 最基本的一个用途就是**身份识别**，保存用户的登录信息，实现会话事务。
2. 另一个常见用途是**广告跟踪**。你上网的时候肯定看过很多的广告图片，这些图片背后都是广告商网站（例如 Google），它会“偷偷地”给你贴上 Cookie 小纸条，这样你上其他的网站，别的广告就能用 Cookie 读出你的身份，然后做行为分析，再推给你广告。

Q：如果 Cookie 的 Max-Age 属性设置为 0，会有什么效果呢？

A：max-age=0是指不能缓存，但在**会话期间是可用的**，浏览器会话关闭之前可以用cookie记录用户的信息。**会话结束cookie即失效**。

Q：Cookie 的好处已经很清楚了，你觉得它有什么缺点呢？

A：1、**不安全**。如果被中间人获取到 Cookie，完全将它作为用户凭证冒充用户。解决方案是使用 https 进行加密。 2、**有数量和大小限制**。另外 Cookie 太大也不好，传输的数据会变大。3、**客户端可能不会保存 Cookie**。比如用 telnet 收发数据，用户禁用浏览器 Cookie 保存功能的情况。



### 20丨生鲜速递：HTTP的缓存控制

 缓存（Cache）是计算机领域里的一个重要概念，是优化系统性能的利器。

基于“请求 - 应答”模式的特点，可以大致分为客户端缓存和服务器端缓存，因为服务器端缓存经常与代理服务“混搭”在一起，所以今天我先讲客户端——也就是浏览器的缓存。

#### 服务器的缓存控制

HTTP 整个流程：

1. 浏览器发现缓存无数据，于是发送请求，向服务器获取资源；
2. 服务器响应请求，返回资源，同时标记资源的有效期；
3. 浏览器缓存资源，等待下次重用。

服务器标记资源有效期使用的头字段是“Cache-Control”，里面的值“max-age=30”就是资源的有效期，相当于告诉浏览器：“这个页面只能缓存30s，之后就算过期不能用”。

注意，这里的**max-age是“生存时间”**，**时间的计算起点是响应报文的创建时刻**，而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有节点所停留的时间。

除了“max-age”，在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存：

- **no-store：不允许缓存；**
- **no-cache：可以缓存，但在使用之前必须要去服务器验证是否过期**，是否有最新的版本；
- **must-revalidate：如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证**

服务器的缓存控制策略流程图如下：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0bdaab3ae3374811ac41322bc19acb6b~tplv-k3u1fbpfcp-watermark.awebp)



#### 客户端的缓存控制

其实**不止服务器可以发“Cache-Control”头，浏览器也可以发“Cache-Control”，也就是说请求-应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略**。

当你**点“刷新”按钮的时候，浏览器会在请求头里加一个“Cache-Control：max-age=0”**，max-age=0的意思就是我需要一个最新的数据，而本地缓存里的数据至少保存了几秒钟，所以浏览器不会使用缓存，而是向服务器发请求。服务器看到max-age=0，也就会用一个最新生成的报文回应浏览器。

**Ctrl+F5的“强制刷新”其实就是发了一个“Cache-Control：no-cache”，含义跟“max-age=0”基本一样**。



#### 条件请求

HTTP协议定义了一系列“If ”开头的“条件请求”字段，专门用来检查验证资源是否过期，把两个请求才能完成的工作合并在一个请求里做。而且，验证的责任也交给服务器，浏览器只需“坐享其成”。

条件请求一共有5个头字段，**我们最常用的是“If-Modified-Since”和“If-None-Match”这两个**。**需要第一次的响应报文预先提供“Last-modified”（文件的最后修改时间）和“ETag”（Entity Tag的缩写，是资源的一个唯一标识**，主要是用来解决修改时间无法准确区分文件变化的问题），然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的。

**如果资源没有变，服务器就回应一个“304 Not Modified”，表示缓存依然有效**，浏览器就可以更新一下有效期，然后放心大胆地使用缓存了。

条件请求里其他的三个头字段是“If-Unmodified-Since”“If-Match”“If-Range”。



Q：Cache 和 Cookie 都是服务器发给客户端并存储的数据，你能比较一下两者的异同吗？

A：Cache 和 Cookie 的相同点是：都会保存到浏览器中，并可以设置过期时间。

不同点：

1. Cookie 会随请求报文发送到服务器，而 Cache 不会，但可能会携带 if-Modified-Since（保存资源的最后修改时间）和 If-None-Match（保存资源唯一标识） 字段来验证资源是否过期。
2. Cookie 在浏览器可以通过脚本获取（如果 cookie 没有设置 HttpOnly），Cache 则无法在浏览器中获取（出于安全原因）。
3. Cookie 通过响应报文的 Set-Cookie 字段获得，Cache 是缓存完整的报文。
4. 用途不同。Cookie 常用于身份识别，Cache 则是由浏览器管理，用于节省带宽和加快响应速度。
5. Cookie 的 max-age 是从浏览器拿到响应报文时开始计算的，而 Cache 的 max-age 是从响应报文的生成时间（Date 头字段）开始计算。

Q：即使有“Last-modified”和“ETag”，强制刷新（Ctrl+F5）也能够从服务器获取最新数据（返回 200 而不是 304），请你在实验环境里试一下，观察请求头和响应头，解释原因。

A：强制刷新是因为请求头里的 If-Modified-Since 和 If-None-Match 会被清空所以会返回最新数据。





### 21丨良心中间商：HTTP的代理服务

#### 代理的作用

​    为什么要有代理呢？换句话说，代理能干什么、带来什么好处呢？

由于代理处在 HTTP 通信过程的中间位置，相应地就对上屏蔽了真实客户端，对下屏蔽了真实服务器，简单的说就是“**欺上瞒下**”。在这个中间层的“小天地”里就可以做很多的事情，为 HTTP 协议增加更多的灵活性，实现客户端和服务器的“双赢”。

​    代理最基本的一个功能是**负载均衡**。因为在面向客户端时屏蔽了源服务器，客户端看到的只是代理服务器，源服务器究竟有多少台、是哪些 IP 地址都不知道。于是代理服务器就可以掌握请求分发的“大权”，决定由后面的哪台服务器来响应请求。

 代理中常用的负载均衡算法你应该也有所耳闻吧，比如轮询、一致性哈希等等，这些算法的目标都是尽量把外部的流量合理地分散到多台源服务器，提高系统的整体资源利用率和性能。

​    在负载均衡的同时，代理服务还可以执行更多的功能，比如：

**健康检查**：**使用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用**；

**安全防护**：**保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载**；

**加密卸载**：**对外网使用 SSL/TLS 加密通信认证，而在安全的内网不加密，消除加解密成本**；

**数据过滤**：**拦截上下行的数据，任意指定策略修改请求或者响应**；

**内容缓存**：**暂存、复用服务器响应**，这个与[第 20 讲](https://time.geekbang.org/column/article/106804)密切相关，我们稍后再说。

#### 代理相关头字段

​    代理的好处很多，但因为它“欺上瞒下”的特点，隐藏了真实客户端和服务器，如果双方想要获得这些“丢失”的原始信息，该怎么办呢？

​    首先，代理服务器需要用字段“**Via**”标明代理的身份。

​    **Via 是一个通用字段，请求头或响应头里都可以出现。每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾，就像是经手人盖了一个章。**

如果通信链路中有很多中间代理，就会在 Via 里形成一个链表，这样就可以知道报文究竟走过了多少个环节才到达了目的地。

但服务器的 IP 地址应该是保密的，关系到企业的内网安全，所以一般不会让客户端知道。不过反过来，**通常服务器需要知道客户端的真实 IP 地址，方便做访问控制、用户画像、统计分析。**

最常用的两个头字段是“**X-Forwarded-For**”和“**X-Real-IP**”。

​    “**X-Forwarded-For**”的字面意思是“**为谁而转发**”，形式上和“Via”差不多，也是每经过一个代理节点就会在字段里追加一个信息。但“Via”追加的是代理主机名（或者域名），而**“X-Forwarded-For”追加的是请求方的 IP 地址**。所以，在**字段里最左边的 IP 地址就客户端的地址。**

​    “**X-Real-IP**”是另一种获取客户端真实 IP 的手段，它的作用很简单，就是**记录客户端 IP 地址，没有中间的代理信息**，相当于是“X-Forwarded-For”的简化版。如果客户端和源服务器之间只有一个代理，那么这两个字段的值就是相同的。



#### 代理协议

​    有了“X-Forwarded-For”等头字段，源服务器就可以拿到准确的客户端信息了。但**对于代理服务器来说它并不是一个最佳的解决方案**。

​    **因为通过“X-Forwarded-For”操作代理信息必须要解析 HTTP 报文头，这对于代理来说成本比较高，原本只需要简单地转发消息就好，而现在却必须要费力解析数据再修改数据，会降低代理的转发性能**。

​    **另一个问题是“X-Forwarded-For”等头必须要修改原始报文，而有些情况下是不允许甚至不可能的（比如使用 HTTPS 通信被加密）**。

​    **所以就出现了一个专门的“代理协议”（The PROXY protocol）**，它由知名的代理软件 HAProxy 所定义，也是一个“事实标准”，被广泛采用（注意并不是 RFC）。

​    “代理协议”有 v1 和 v2 两个版本，v1 和 HTTP 差不多，也是明文，而 v2 是二进制格式。今天只介绍比较好理解的 v1，**它在 HTTP 报文前增加了一行 ASCII 码文本，相当于又多了一个头**。

​    **这一行文本其实非常简单，开头必须是“PROXY”五个大写字母，然后是“TCP4”或者“TCP6”，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\r\n）结束**。

```http
PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\n
GET / HTTP/1.1\r\n
Host: www.xxx.com\r\n
\r\n
```

服务器看到这样的报文，**只要解析第一行就可以拿到客户端地址，不需要再去理会后面的 HTTP 数据，省了很多事情**。

不过代理协议并不支持“X-Forwarded-For”的链式地址形式，所以拿到客户端地址后再如何处理就需要代理服务器与后端自行约定。

#### 小结

**HTTP 代理就是客户端和服务器通信链路中的一个中间环节，为两端提供“代理服务”**；

**代理处于中间层，为 HTTP 处理增加了更多的灵活性，可以实现负载均衡、安全防护、数据过滤等功能**；

**代理服务器需要使用字段“Via”标记自己的身份**，多个代理会形成一个列表；

如果想要知道客户端的真实 IP 地址，可以使用字段“X-Forwarded-For”和“X-Real-IP”；

**专门的“代理协议”可以在不改动原始报文的情况下传递客户端的真实 IP**。

课下作业

Q：你觉得代理有什么缺点？实际应用时如何避免？

A：a 代理服务器与上下游的通信机制也是http协议，因此增加了传输中的**数据泄漏和篡改风险**，可以使用https解决。b 如果**代理服务器发生故障，会影响客户端的正常访问**，可以增加代理服务器的数量，并配置代理服务器负载均衡算法。c 由于**多了代理服务器的请求响应过程，增加了从源客户端和源服务器之间的来回时间**。

Q：你知道多少反向代理中使用的负载均衡算法？它们有什么优缺点？

A：**轮询，加权轮询，随机法，加权随机法，源地址哈希法，最小连接数法**



### 22丨冷链周转：HTTP的缓存代理

  但 HTTP 传输链路上，不只是客户端有缓存，服务器上的缓存也是非常有价值的，可以让请求不必走完整个后续处理流程，“就近”获得响应结果。

​    特别是对于那些“读多写少”的数据，例如突发热点新闻、爆款商品的详情页，一秒钟内可能有成千上万次的请求。即使仅仅缓存数秒钟，也能够把巨大的访问流量挡在外面，    让 RPS（request per second）降低好几个数量级，减轻应用服务器的并发压力，对性能的改善是非常显著的。

​    **HTTP 的服务器缓存功能主要由代理服务器来实现（即缓存代理）**，而源服务器系统内部虽然也经常有各种缓存（如 Memcache、Redis、Varnish 等），但与 HTTP 没有太多关系，所以这里暂且不说。

#### 缓存代理服务

在没有缓存的时候，代理服务器每次都是直接转发客户端和服务器的报文，中间不会存储任何数据，只有最简单的中转功能。

加入了缓存后就不一样了。

​    代理服务收到源服务器发来的响应数据后需要做两件事。第一个当然是把报文转发给客户端，而第二个就是把报文存入自己的 Cache 里。

​    下一次再有相同的请求，代理服务器就可以直接发送 304 或者缓存数据，不必再从源服务器那里获取。这样就降低了客户端的等待时间，同时节约了源服务器的网络带宽。

在 HTTP 的缓存体系中，**缓存代理的身份十分特殊，它“既是客户端，又是服务器”，同时也“既不是客户端，又不是服务器”**。

​    说它“即是客户端又是服务器”，是因为它面向源服务器时是客户端，在面向客户端时又是服务器，所以它即可以用客户端的缓存控制策略也可以用服务器端的缓存控制策略，也就是说它可以同时使用第 20 讲的各种“Cache-Control”属性。

​    但缓存代理也“即不是客户端又不是服务器”，因为它只是一个数据的“中转站”，并不是真正的数据消费者和生产者，所以还需要有一些新的“Cache-Control”属性来对它做特别的约束。

#### 源服务器的缓存控制

  [第 20 讲](https://time.geekbang.org/column/article/106804)介绍了 4 种服务器端的“Cache-Control”属性：max-age、no_store、no_cache 和 must-revalidate，你应该还有印象吧？

​    **这 4 种缓存属性可以约束客户端，也可以约束代理。**

​    但客户端和代理是不一样的，客户端的缓存只是用户自己使用，而代理的缓存可能会为非常多的客户端提供服务。所以，需要对它的缓存再多一些限制条件。

​    首先，我们要区分客户端上的缓存和代理上的缓存，可以使用两个新属性“**private**”和“**public**”。

​    **“private”表示缓存只能在客户端保存，是用户“私有”的，不能放在代理上与别人共享。而“public”的意思就是缓存完全开放，谁都可以存，谁都可以用。**

其次，缓存失效后的重新验证也要区分开（即使用条件请求“Last-modified”和“ETag”），“**must-revalidate**”是只要过期就必须回源服务器验证，而新的“**proxy-revalidate**”只要求代理的缓存过期后必须验证，客户端不必回源，只验证到代理这个环节就行了

再次，缓存的生存时间可以使用新的“**s-maxage**”（s 是 share 的意思，注意 maxage 中间没有“-”），**只限定在代理上能够存多久**，而客户端仍然使用“max_age”。

 还有一个代理专用的属性“**no-transform**”。代理有时候会对缓存下来的数据做一些优化，比如把图片生成 png、webp 等几种格式，方便今后的请求处理，而“no-transform”就会禁止这样做，**不许“偷偷摸摸搞小动作”。**

  我还要提醒你一点，**源服务器在设置完“Cache-Control”后必须要为报文加上“Last-modified”或“ETag”字段。否则，客户端和代理后面就无法使用条件请求来验证缓存是否有效，也就不会有 304 缓存重定向。**

  说完了服务器端的缓存控制策略，稍微歇一口气，我们再来看看客户端。

客户端在 HTTP 缓存体系里要面对的是代理和源服务器，也必须区别对待，这里我就直接上图了，来个“看图说话”。

关于缓存的生存时间，多了两个新属性“**max-stale**”和“**min-fresh**”。

​    **“max-stale”的意思是如果代理上的缓存过期了也可以接受，但不能过期太多，超过 x 秒也会不要**。**“min-fresh”的意思是缓存必须有效，而且必须在 x 秒后依然有效**。

有的时候客户端还会发出一个特别的“**only-if-cached**”属性，**表示只接受代理缓存的数据，不接受源服务器的响应**。如果代理上没有缓存或者缓存过期，就应该给客户端返回一个 504（Gateway Timeout）。

代理在响应报文里还额外加了**“X-Cache”“X-Hit”**等自定义头字段，**表示缓存是否命中和命中率，方便你观察缓存代理的工作情况。**

#### 其他问题

缓存代理的知识就快讲完了，下面再简单说两个相关的问题。

 第一个是“**Vary**”字段，在[第 15 讲](https://time.geekbang.org/column/article/104024)曾经说过，它是**内容协商的结果**，相当于报文的一个版本标记。

​    同一个请求，经过内容协商后可能会有不同的字符集、编码、浏览器等版本。比如，“Vary: Accept-Encoding”“Vary: User-Agent”，缓存代理必须要存储这些不同的版本。

**当再收到相同的请求时，代理就读取缓存里的“Vary”，对比请求头里相应的“ Accept-Encoding”“User-Agent”等字段，如果和上一个请求的完全匹配，比如都是“gzip”“Chrome”，就表示版本一致，可以返回缓存的数据**。

另一个问题是“**Purge**”，也就是“**缓存清理**”，它对于代理也是非常重要的功能，例如：

过期的数据应该及时淘汰，避免占用空间；

源站的资源有更新，需要删除旧版本，主动换成最新版（即刷新）；

有时候会缓存了一些本不该存储的信息，例如网络谣言或者危险链接，必须尽快把它们删除。

清理缓存的方法有很多，比较常用的一种做法是使用自定义请求方法“PURGE”，发给代理服务器，要求删除 URI 对应的缓存数据。

#### 小结

计算机领域里最常用的性能优化手段是“时空转换”，也就是“时间换空间”或者“空间换时间”，HTTP 缓存属于后者；

缓存代理是增加了缓存功能的代理服务，缓存源服务器的数据，分发给下游的客户端；

“Cache-Control”字段也可以控制缓存代理，常用的有“private”“s-maxage”“no-transform”等，同样必须配合“Last-modified”“ETag”等字段才能使用；

缓存代理有时候也会带来负面影响，缓存不良数据，需要及时刷新或删除。



## 五安全篇

### 23 | TLS又是什么？

#### 为什么要有 HTTPS？

​    简单的回答是“**因为 HTTP 不安全**”。

​    由于 **HTTP 天生“明文”的特点，整个传输过程完全透明，任何人都能够在链路中截获、修改或者伪造请求 / 响应报文，数据不具有可信性。**

既然 HTTP“不安全”，那什么样的通信过程才是安全的呢？

通常认为，如果通信过程具备了四个特性，就可以认为是“安全”的，这四个特性是：**机密性、完整性，身份认证和不可否认。**

​    **机密性**（Secrecy/Confidentiality）是指**对数据的“保密”**，只能由可信的人访问，对其他人是不可见的“秘密”，简单来说就是不能让不相关的人看到不该看的东西。

​    **完整性**（Integrity，也叫**一致性**）是**指数据在传输过程中没有被窜改**，不多也不少，“完完整整”地保持着原状。

​    机密性虽然可以让数据成为“秘密”，但不能防止黑客对数据的修改，黑客可以替换数据，调整数据的顺序，或者增加、删除部分数据，破坏通信过程。

​    **身份认证**（Authentication）是**指确认对方的真实身份**，也就是“证明你真的是你”，保证消息只能发送给可信的人。

​    如果通信时另一方是假冒的网站，那么数据再保密也没有用，黑客完全可以使用冒充的身份“套”出各种信息，加密和没加密一样。

​    第四个特性是**不可否认**（Non-repudiation/Undeniable），也叫不可抵赖，意思是不能否认已经发生过的行为，不能“说话不算数”“耍赖皮”。

#### 什么是 HTTPS？

​    说到这里，终于轮到今天的主角 HTTPS 出场了，它为 HTTP 增加了刚才所说的四大安全特性。

​    HTTPS 其实是一个“非常简单”的协议，RFC 文档很小，只有短短的 7 页，里面规定了**新的协议名“https”，默认端口号 443**，至于其他的什么请求 - 应答模式、报文结构、请求方法、URI、头字段、连接管理等等都完全沿用 HTTP，没有任何新的东西。

HTTPS 能够鉴别危险的网站，并且尽最大可能保证你的上网安全，防御黑客对信息的窃听、窜改或者“钓鱼”、伪造。

由“**HTTP over TCP/IP**”变成了“**HTTP over SSL/TLS**”，让 HTTP 运行在了安全的 SSL/TLS 协议上（可参考第 4 讲和第 5 讲），收发报文不再使用 Socket API，而是调用专门的安全接口。

<img src="https://img2020.cnblogs.com/blog/473210/202004/473210-20200416102157866-1845537712.png" alt="img" style="zoom:67%;" />



#### SSL/TLS

**SSL 即安全套接层（Secure Sockets Layer），在 OSI 模型中处于第 5 层（会话层）**，由网景公司于 1994 年发明。

​    **TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术**。

​    浏览器和服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为“密码套件”（cipher suite，也叫加密套件）。

**TLS 的密码套件命名非常规范，格式很固定。基本的形式是“密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法”**，比如刚才的密码套件的意思就是：

“ECDHE-RSA-AES256-GCM-SHA384”。

​    “握手时使用 ECDHE 算法进行密钥交换，用 RSA 签名和身份认证，握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM，摘要算法 SHA384 用于消息认证和产生随机数。”

#### OpenSSL

​    说到 TLS，就不能不谈到 OpenSSL，**它是一个著名的开源密码学程序库和工具包，几乎支持所有公开的加密算法和协议**，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，包括常用的 Web 服务器 Apache、Nginx 等。

#### 小结

因为 HTTP 是明文传输，所以不安全，容易被黑客窃听或窜改；

通信安全必须同时具备**机密性、完整性，身份认证和不可否认**这四个特性；

HTTPS 的语法、语义仍然是 HTTP，但把下层的协议由 TCP/IP 换成了 SSL/TLS；

SSL/TLS 是信息安全领域中的权威标准，采用多种先进的加密技术保证通信安全；

OpenSSL 是著名的开源密码学工具包，是 SSL/TLS 的具体实现。



### 24丨固若金汤的根本（上）：对称加密与非对称加密

实现机密性最常用的手段是“**加密**”（encrypt），就是把消息用某种方式转换成谁也看不懂的乱码，只有掌握特殊“钥匙”的人才能再转换出原始文本。

​    这里的“钥匙”就叫做“**密钥**”（key），加密前的消息叫“**明文**”（plain text/clear text），加密后的乱码叫“**密文**”（cipher text），使用密钥还原明文的过程叫“**解密**”（decrypt），是加密的反操作，加密解密的操作过程就是“**加密算法**”。

 按照密钥的使用方式，加密可以分为两大类：**对称加密和非对称加密**。

#### 对称加密

​    **“对称加密”很好理解，就是指加密和解密时使用的密钥都是同一个，是“对称”的**。只要保证了密钥的安全，那整个通信过程就可以说具有了机密性。

TLS 里有非常多的对称加密算法可供选择，比如 RC4、DES、3DES、AES、ChaCha20 等，但前三种算法都被认为是不安全的，通常都禁止使用，**目前常用的只有 AES 和 ChaCha20**。

​    **AES 的意思是“高级加密标准”（Advanced Encryption Standard），密钥长度可以是 128、192 或 256。它是 DES 算法的替代者，安全强度很高，性能也很好，而且有的硬件还会做特殊优化，所以非常流行，是应用最广泛的对称加密算法。**

​    ChaCha20 是 Google 设计的另一种加密算法，密钥长度固定为 256 位，纯软件运行性能要超过 AES，曾经在移动客户端上比较流行，但 ARMv8 之后也加入了 AES 硬件优化，所以现在不再具有明显的优势，但仍然算得上是一个不错算法。

#### 加密分组模式

​    对称算法还有一个“**分组模式**”的概念，它可以**让算法用固定长度的密钥加密任意长度的明文，把小秘密（即密钥）转化为大秘密（即密文）。**

​    最早有 ECB、CBC、CFB、OFB 等几种分组模式，但都陆续被发现有安全漏洞，所以现在基本都不怎么用了。**最新的分组模式被称为 AEAD（Authenticated Encryption with Associated Data），在加密的同时增加了认证的功能，常用的是 GCM、CCM 和 Poly1305**。

​    把上面这些组合起来，就可以得到 TLS 密码套件中定义的对称加密算法。

比如，AES128-GCM，意思是密钥长度为 128 位的 AES 算法，使用的分组模式是 GCM；ChaCha20-Poly1305 的意思是 ChaCha20 算法，使用的分组模式是 Poly1305。

#### 非对称加密

​    对称加密看上去好像完美地实现了机密性，但其中有一个很大的问题：如何把密钥安全地传递给对方，术语叫“**密钥交换**”。

  所以，就出现了非对称加密（也叫公钥加密算法）。

​    它有两个密钥，一个叫“**公钥**”（public key），一个叫“**私钥**”（private key）。两个密钥是不同的，“不对称”，公钥可以公开给任何人使用，而私钥必须严格保密。

​    公钥和私钥有个特别的“**单向**”性，虽然都可以用来加密解密，但公钥加密后只能用私钥解密，反过来，私钥加密后也只能用公钥解密。

​    **非对称加密可以解决“密钥交换”的问题**。网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。

**非对称加密算法的设计要比对称算法难得多**，在 TLS 里只有很少的几种，比如 DH、DSA、RSA、ECC 等。

​    **RSA** 可能是其中最著名的一个，**几乎可以说是非对称加密的代名词**，它的安全性基于“**整数分解**”的数学难题，**使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私钥是非常困难的。**

​    10 年前 RSA 密钥的推荐长度是 1024，但随着计算机运算能力的提高，现在 1024 已经不安全，普遍认为至少要 2048 位。

​    **ECC**（Elliptic Curve Cryptography）是非对称加密里的“后起之秀”，它基于“**椭圆曲线离散对数**”的数学难题，使用特定的曲线方程和基点生成公钥和私钥，子算法 ECDHE 用于密钥交换，ECDSA 用于数字签名。

比起 RSA，ECC 在安全强度和性能上都有明显的优势。160 位的 ECC 相当于 1024 位的 RSA，而 224 位的 ECC 则相当于 2048 位的 RSA。因为密钥短，所以相应的计算量、消耗的内存和带宽也就少，加密解密的性能就上去了，对于现在的移动互联网非常有吸引力。

#### 混合加密

虽然非对称加密没有“密钥交换”的问题，但因为它们都是基于复杂的数学难题，运算速度很慢，即使是 ECC 也要比 AES 差上好几个数量级。如果仅用非对称加密，虽然保证了安全，但通信速度有如乌龟、蜗牛，实用性就变成了零。

那么，是不是能够把对称加密和非对称加密结合起来呢，两者互相取长补短，即能高效地加密解密，又能安全地密钥交换。

​    这就是现在 TLS 里使用的**混合加密**方式，其实说穿了也很简单：

​    **在通信刚开始的时候使用非对称算法，比如 RSA、ECDHE，首先解决密钥交换的问题。**

​    **然后用随机数产生对称算法使用的“会话密钥”（session key），再用公钥加密。因为会话密钥很短，通常只有 16 字节或 32 字节，所以慢一点也无所谓。**

​    **对方拿到密文后用私钥解密，取出会话密钥。这样，双方就实现了对称密钥的安全交换，后续就不再使用非对称加密，全都使用对称加密。**

这样混合加密就解决了对称加密算法的密钥交换问题，而且安全和性能兼顾，完美地实现了机密性。

​    不过这只是“万里长征的第一步”，后面还有完整性、身份认证、不可否认等特性没有实现，所以现在的通信还不是绝对安全，我们下次再说。

#### 小结

加密算法的核心思想是“把一个小秘密（密钥）转化为一个大秘密（密文消息）”，守住了小秘密，也就守住了大秘密；

**对称加密只使用一个密钥，运算速度快**，密钥必须保密，无法做到安全的密钥交换，常用的有 **AES** 和 ChaCha20；

**非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢，常用的有 RSA 和 ECC；**

把对称加密和非对称加密结合起来就得到了“又好又快”的混合加密，也就是 TLS 里使用的加密方式。



Q：在混合加密中用到了公钥加密，因为只能由私钥解密。那么反过来，私钥加密后任何人都可以用公钥解密，这有什么用呢？

A：公钥加密私钥解密，私钥签名公钥验签。



### 25丨固若金汤的根本（下）：数字签名与证书

上一讲中我们学习了**对称加密和非对称加密，以及两者结合起来的混合加密，实现了机密性**。

​    但仅有机密性，离安全还差的很远。

​    黑客虽然拿不到会话密钥，无法破解密文，但可以通过窃听收集到足够多的密文，再尝试着修改、重组后发给网站。因为没有完整性保证，服务器只能“照单全收”，然后他就可以通过服务器的响应获取进一步的线索，最终就会破解出明文。

​    另外，**黑客也可以伪造身份发布公钥。如果你拿到了假的公钥，混合加密就完全失效了**。你以为自己是在和“某宝”通信，实际上网线的另一端却是黑客，银行卡号、密码等敏感信息就在“安全”的通信过程中被窃取了。

​    **所以，在机密性的基础上还必须加上完整性、身份认证等特性，才能实现真正的安全。**

#### 摘要算法

​    **实现完整性的手段**主要是**摘要算法**（Digest Algorithm），也就是常说的散列函数、哈希函数（Hash Function）。

​    你可以把**摘要算法近似地理解成一种特殊的压缩算法，它能够把任意长度的数据“压缩”成固定长度、而且独一无二的“摘要”字符串，就好像是给这段数据生成了一个数字“指纹”**。

​    换一个角度，**也可以把摘要算法理解成特殊的“单向”加密算法，它只有算法，没有密钥，加密后的数据无法解密，不能从摘要逆推出原文。**

 **因为摘要算法对输入具有“单向性”和“雪崩效应”，输入的微小不同会导致输出的剧烈变化，所以也被 TLS 用来生成伪随机数（PRF，pseudo random function）。**

​    你一定在日常工作中听过、或者用过 **MD5（Message-Digest 5）、SHA-1（Secure Hash Algorithm 1），它们就是最常用的两个摘要算法，能够生成 16 字节和 20 字节长度的数字摘要。但这两个算法的安全强度比较低，不够安全**，在 TLS 里已经被禁止使用了。

​    **目前 TLS 推荐使用的是 SHA-1 的后继者：SHA-2。**

​    **SHA-2 实际上是一系列摘要算法的统称，总共有 6 种，常用的有 SHA224、SHA256、SHA384，分别能够生成 28 字节、32 字节、48 字节的摘要**。

（SHA256都会产生一个256位的哈希值，称作消息摘要。这个摘要相当于是个长度为32个字节的数组，通常有一个长度为64的十六进制字符串来表示，其中1个字节=8位，一个十六进制的字符的长度为4位）

#### 完整性

​    摘要算法保证了“数字摘要”和原文是完全等价的。所以，我们只要在原文后附上它的摘要，就能够保证数据的完整性。

 不过摘要算法不具有机密性，如果明文传输，那么黑客可以修改消息后把摘要也一起改了，网站还是鉴别不出完整性。

​    所以，**真正的完整性必须要建立在机密性之上，在混合加密系统里用会话密钥加密消息和摘要，这样黑客无法得知明文，也就没有办法动手脚了。**

​    这有个术语，叫**哈希消息认证码（HMAC）**。

#### 数字签名

​    加密算法结合摘要算法，我们的通信过程可以说是比较安全了。但这里还有漏洞，就是通信的两个端点（endpoint）。

​    就像一开始所说的，黑客可以伪装成网站来窃取信息。而反过来，他也可以伪装成你，向网站发送支付、转账等消息，网站没有办法确认你的身份，钱可能就这么被偷走了。

没错，这个东西就是非对称加密里的“**私钥**”，使用私钥再加上摘要算法，就能够实现“**数字签名**”，同时实现“身份认证”和“不可否认”。

​    数字签名的原理其实很简单，就是把公钥私钥的用法反过来，之前是公钥加密、私钥解密，**现在是私钥加密、公钥解密**。

​    但又因为**非对称加密效率太低，所以私钥只加密原文的摘要，这样运算量就小的多，而且得到的数字签名也很小，方便保管和传输**。

​    签名和公钥一样完全公开，任何人都可以获取。但这个签名只有用私钥对应的公钥才能解开，**拿到摘要后，再比对原文验证完整性，就可以像签署文件一样证明消息确实是你发的。**

 刚才的这两个行为也有专用术语，叫做“**签名**”和“**验签**”。

​    只要你和网站互相交换公钥，就可以用“签名”和“验签”来确认消息的真实性，因为私钥保密，黑客不能伪造签名，就能够保证通信双方的身份。

#### 数字证书和 CA

​    到现在，综合使用对称加密、非对称加密和摘要算法，我们已经实现了安全的四大特性，是不是已经完美了呢？

​    不是的，这里还有一个“**公钥的信任**”问题。因为谁都可以发布公钥，我们还缺少防止黑客伪造公钥的手段，也就是说，**怎么来判断这个公钥就是你或者某宝的公钥呢？**

找一个公认的可信第三方，让它作为“信任的起点，递归的终点”，构建起公钥的信任链。这个“第三方”就是我们常说的**CA**（Certificate Authority，**证书认证机构**）。

**CA 对公钥的签名认证也是有格式的**，不是简单地把公钥绑定在持有者身份上就完事了，还**要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名，完整地证明公钥关联的各种信息**，形成“**数字证书**”（Certificate）。

​    知名的 CA 全世界就那么几家，比如 DigiCert、VeriSign、Entrust、Let’s Encrypt 等，它们签发的证书分 DV、OV、EV 三种，区别在于可信程度。DV 是最低的，只是域名级别的可信，背后是谁不知道。EV 是最高的，经过了法律和审计的严格核查，可以证明网站拥有者的身份。

小一点的 CA 可以让大 CA 签名认证，但链条的最后，也就是**Root CA**，就只能自己证明自己了，这个就叫“**自签名证书**”（Self-Signed Certificate）或者“**根证书**”（Root Certificate）。

**有了这个证书体系，操作系统和浏览器都内置了各大 CA 的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链（Certificate Chain）一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的**。

#### 证书体系的弱点

​	如果 CA 失误或者被欺骗，签发了错误的证书，虽然证书是真的，可它代表的网站却是假的。

​    还有一种更危险的情况，CA 被黑客攻陷，或者 CA 有恶意，因为它（即根证书）是信任的源头，整个信任链里的所有证书也就都不可信了。

针对第一种，开发出了 **CRL（证书吊销列表**，Certificate revocation list）和 **OCSP（在线证书状态协议**，Online Certificate Status Protocol），及时废止有问题的证书。

​    对于第二种，因为涉及的证书太多，就只能操作系统或者浏览器从根上“下狠手”了，撤销对 CA 的信任，列入“黑名单”，这样它颁发的所有证书就都会被认为是不安全的。

小结

今天我们学习了数字签名和证书、CA，是不是有种“盗梦空间”一层套一层的感觉？你可以在课后再去各大网站，结合它们“小锁头”里的信息来加深理解。

今天的内容可以简单概括为四点：

**摘要算法用来实现完整性，能够为数据生成独一无二的“指纹”，常用的算法是 SHA-2；**

**数字签名是私钥对摘要的加密，可以由公钥解密后验证，实现身份认证和不可否认；**

**公钥的分发需要使用数字证书，必须由 CA 的信任链来验证，否则就是不可信的；**

作为信任链的源头 CA 有时也会不可信，解决办法有 CRL、OCSP，还有终止信任。



### 26丨信任始于握手：TLS1.2连接过程解析

#### HTTPS 建立连接

​    当你在浏览器地址栏里键入“**https**”开头的 URI，再按下回车，会发生什么呢？

​    回忆一下[第 8 讲](https://time.geekbang.org/column/article/100502)的内容，你应该知道，浏览器首先要从 URI 里提取出协议名和域名。因为协议名是“https”，所以浏览器就知道了端口号是默认的 443，它再用 DNS 解析域名，得到目标的 IP 地址，然后就可以使用三次握手与网站建立 TCP 连接了。

​    **在 HTTP 协议里，建立连接后，浏览器会立即发送请求报文。但现在是 HTTPS 协议，它需要再用另外一个“握手”过程，在 TCP 上建立安全连接，之后才是收发 HTTP 报文。**

​    **这个“握手”过程与 TCP 有些类似，是 HTTPS 和 TLS 协议里最重要、最核心的部分，懂了它，你就可以自豪地说自己“掌握了 HTTPS”。**

#### TLS 协议的组成

​    在讲 TLS 握手之前，我先简单介绍一下 TLS 协议的组成。

​    **TLS 包含几个子协议，你也可以理解为它是由几个不同职责的模块组成，比较常用的有记录协议、警报协议、握手协议、变更密码规范协议等。**

​       **记录协议**（Record Protocol）**规定了 TLS 收发数据的基本单位：记录**（record）。它有点像是 TCP 里的 segment，**所有的其他子协议都需要通过记录协议发出**。但**多个记录数据可以在一个 TCP 包里一次性发出，也并不需要像 TCP 那样返回 ACK**。

​    **警报协议**（Alert Protocol）的职责是**向对方发出警报信息**，有点像是 HTTP 协议里的状态码。比如，protocol_version 就是不支持旧版本，bad_certificate 就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接。

​    **握手协议**（Handshake Protocol）**是 TLS 里最复杂的子协议**，要比 TCP 的 SYN/ACK 复杂的多，**浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统**。

​    最后一个是**变更密码规范协议**（Change Cipher Spec Protocol），它非常简单，就是一个“**通知**”，告诉对方，后续的数据都将使用加密保护。那么反过来，在它之前，数据都是明文的。

​    下面的这张图简要地描述了 TLS 的握手过程，其中每一个“框”都是一个记录，多个记录组合成一个 TCP 包发送。所以，**最多经过两次消息往返（4 个消息）就可以完成握手，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议**。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e47ed3151cea4a27ad89dc4862692ffd~tplv-k3u1fbpfcp-watermark.awebp)

#### ECDHE握手过程

握手的详细图如下：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c095033173664618b2b9732d76799ccc~tplv-k3u1fbpfcp-watermark.awebp)

在TCP建立连接之后，**浏览器会首先发一个”Client Hello“消息，也就是跟服务器”打招呼“。里面有客户端的版本号、支持的密码套件，还有一个随机数（Client Random），用于后续生成会话密钥。**

这个的意思就是：“我这边有这些这些信息，你看看哪些是能用的，关键的随机数可得留着”

作为“礼尚往来”，**服务器收到“Client Hello”后，会返回一个“Server Hello”消息。把版本号对一下，也给出一个随机数（Server Random），然后从客户端的列表里选一个作为本次通信使用的密码套件**，在这里它选择了“TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384”。

这个的意思就是：“版本号对上了，可以加密，你的密码套件挺多，我选一个最合适的吧，用椭圆曲线加RSA、AES、SHA384。我也给你一个随机数，你也得留着。”

然后，**服务器为了证明自己的身份，就把证书也发给了客户端（Server Certificate）**。

接下来是一个关键的操作，**因为服务器选择了ECDHE算法，所以它会在证书后发送“Server Key Exchange”消息，里面是椭圆曲线的公钥（Server Params），用来实现密钥交换算法，再加上自己的私钥签名认证**。


这相当于说：“刚才我选的密码套件有点复杂，所以再给你个算法的参数，和刚才的随机数一样有用，别丢了。为了防止别人冒充，我又盖了个章。”

**之后是“Server Hello Done”消息，服务器说：“我的信息就是这些，打招呼完毕。”**

这样**第一个消息往返就结束了（两个TCP包），结果是客户端和服务器通过明文共享了三个信息：Client Random、Server Random和Server Params**。

**客户端这时也拿到了服务器的证书，开始走证书链逐级验证，确认证书的真实性，再用证书公钥验证签名，就确认了服务器的身份**：“刚才跟我打招呼的不是骗子，可以接着往下走。”

**然后，客户端按照密码套件的要求，也生成一个椭圆曲线的公钥（Client Params），用“Client Key Exchange”消息发给服务器。**

```
Handshake Protocol: Client Key Exchange
    EC Diffie-Hellman Client Params
        Pubkey: 8c674d0e08dc27b5eaa…
```

**现在客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params、Server Params），就用ECDHE算法一阵算，算出了一个新的东西，叫“Pre-Master”，其实也是一个随机数**。

至于具体的计算原理和过程，因为太复杂就不细说了，但**算法可以保证即使黑客截获了之前的参数，也是绝对算不出这个随机数的**。

**现在客户端和服务器手里有了三个随机数：Client Random、Server Random和Pre-Master。用这三个作为原始材料，就可以生成用于加密会话的主密钥，叫“Master Secret”。**而黑客因为拿不到“Pre-Master”，所以也就得不到主密钥。

为什么非得这么麻烦，非要三个随机数呢？

​    这就必须说 TLS 的设计者考虑得非常周到了，他们不信任客户端或服务器伪随机数的可靠性，为了保证真正的“完全随机”“不可预测”，把三个不可靠的随机数混合起来，那么“随机”的程度就非常高了，足够让黑客难以猜测。

 你一定很想知道“Master Secret”究竟是怎么算出来的吧，贴一下 RFC 里的公式：

```
master_secret = PRF(pre_master_secret, "master secret",ClientHello.random + ServerHello.random)
```

 这里的“PRF”就是伪随机数函数，它基于密码套件里的最后一个参数，比如这次的 SHA384，通过摘要算法来再一次强化“Master Secret”的随机性。

**主密钥有48字节，但它也不是最终用于通信的会话密钥，还会再用PRF扩展出更多的密钥，比如客户端发送用的会话密钥（client_write_key）、服务器发送用的会话密钥（server_write_key）等等，避免只用一个密钥带来的安全隐患。**

**有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个”Change Cipher Spec“，然后再发一个”Finished“消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证。**

意思就是告诉服务器：“后面都改用对称算法加密通信了啊，用的就是打招呼时说的 AES，加密对不对还得你测一下。”

**服务器也是同样的操作，发“Change Cipher Spec”和“Finished”消息，双方都验证加密解密 OK，握手正式结束，后面就收发被加密的 HTTP 请求和响应了。**

#### RSA握手过程

刚才说的其实是如今主流的 TLS 握手过程，这与传统的握手有两点不同。

第一个，使用 ECDHE 实现密钥交换，而不是 RSA，所以会在服务器端发出“Server Key Exchange”消息。

第二个，因为使用了 ECDHE，客户端可以不用等到服务器发回“Finished”确认握手完毕，立即就发出 HTTP 报文，省去了一个消息往返的时间浪费。这个叫“TLS False Start”，意思就是“抢跑”，和“TCP Fast Open”有点像，都是不等连接完全建立就提前发应用数据，提高传输的效率。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c42724af3b164d42b94717a8151b8728~tplv-k3u1fbpfcp-watermark.awebp" alt="img" style="zoom:67%;" />

流程如上图所示，大体没有变，只是”Pre-Master“不再需要用算法生成，而是客户端直接生成随机数，然后用服务器的公钥加密，通过”Client Key Exchange“消息发给服务器。服务器再用私钥解密，这样双方也实现了共享三个随机数，就可以生成主密钥。

#### 双向认证

不过上面说的是“单向认证”握手过程，只认证了服务器的身份，而没有认证客户端的身份。这是因为通常单向认证通过后已经建立了安全通信，用账号、密码等简单的手段就能够确认用户的真实身份。

但为了防止账号、密码被盗，有的时候（比如网上银行）还会使用 U 盾给用户颁发**客户端证书**，实现“双向认证”，这样会更加安全。

**双向认证的流程也没有太多变化，只是在“Server Hello Done”之后，“Client Key Exchange”之前，客户端要发送“Client Certificate”消息，服务器收到后也把证书链走一遍，验证客户端的身份。**

Q：密码套件里的那些算法分别在握手过程中起了什么作用？

A：比如TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256：使用ECDHE进行密钥交换（文中已经讲了，用它算出Pre_Master，成会话密钥Master Secret。密钥交换过程中应该会使用到非对称加密中的公钥加密），RSA进行身份验证（私钥加密公钥解密），使用128位GCM分组工作模式的AES进行消息和会话密钥的对称加密（加密真正的消息），使用SHA256摘要算法（如HMAC、PRM）对数据签名，保证数据完整性

Q：你能完整地描述一下 RSA 的握手过程吗？

A：客户端使用tcp链接明文将自己的随机数、密码套件、tls版本号发送给服务端，服务端根据自己支持的密码套件从客户端的密码套件中选取一个最合适的密码套件，协商出tls版本，将协商好的密码套件、tls版本以及自己的随机数明文告诉客户端，并将自己的证书发送给客户端，并结束 客户端收到证书之后去ca一级一级验证证书的有效性，验证通过后，客户端使用随机数生成pre-master并 用服务器的公钥进行加密传给服务端，服务端使用自己的私钥进行解密，使用解密后的值与客户端随机数，自己的随机数进行计算，得出master secret；这时候，客户端使用三个值也能计算出master secret，客户端告诉服务器我之后都使用加密进行通信了，结束；服务端也告诉客户端，我也要开始使用加密通信了，over 接下来两个人使用计算出来的master secret进行消息加密，并使用master secret进行解密




### 27丨更好更快的握手：TLS1.3特性解析

TLS1.3 终于在去年（2018 年）“粉墨登场”，再次确立了信息安全领域的新标准。 TLS1.3 的三个主要改进目标：**兼容**、**安全与性能**。

#### 最大化兼容性

为了保证这些被广泛部署的“老设备”能够继续使用，避免新协议带来的“冲击”，TLS1.3 不得不做出妥协，保持现有的记录格式不变，通过“伪装”来实现兼容，使得 TLS1.3 看上去“像是”TLS1.2。

​    那么，该怎么区分 1.2 和 1.3 呢？

​    这要用到一个新的**扩展协议**（Extension Protocol），它有点“补充条款”的意思，通过在记录末尾添加一系列的“扩展字段”来增加新的功能，老版本的 TLS 不认识它可以直接忽略，这就实现了“后向兼容”。

​    在记录头的 Version 字段被兼容性“固定”的情况下，只要是 TLS1.3 协议，握手的“Hello”消息后面就必须有“**supported_versions**”扩展，它**标记了 TLS 的版本号**，使用它就能区分新旧协议。

#### 强化安全

TLS1.3在协议里修补了TLS1.2的一些不安全因素：

- 伪随机数函数由PRF升级为HKDF（HMAC-based Extract-and-Expand Key Derivation Function）;
- 明确禁止在记录协议里使用压缩；
- 废除了RC4、DES对称加密算法；
- 废除了ECB、CBC等传统分组模式；
- 废除了MD5、SHA1、SHA-224摘要算法；
- 废除了RSA、DH密钥交换算法和许多命名曲线。

经过这一番“减肥瘦身”之后，**TLS1.3 里只保留了 AES、ChaCha20 对称加密算法，分组模式只能用 AEAD 的 GCM、CCM 和 Poly1305，摘要算法只能用 SHA256、SHA384，密钥交换算法只有 ECDHE 和 DHE，椭圆曲线也被“砍”到只剩 P-256 和 x25519 等 5 种**。导致**现在的TLS1.3里只有5个套件，无论是客户端还是服务器都不会再犯”选择困难症“了。**

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/582838470cb54df8945ba33f73a7ab9e~tplv-k3u1fbpfcp-watermark.awebp" alt="img" style="zoom:67%;" />



**废除RSA和DH密钥交换算法的原因**。

浏览器默认会使用ECDHS而不是RSA做密钥交换，是因为它不具有”**前向安全**“（Forward Secrecy）。一旦私钥泄露或被解出来，那么黑客就能够使用私钥解密出之前所有报文的”Pre-Master“，再算出会话密钥，解出所有密文。这就是所谓的“**今日截获，明日解密**”。

**而ECDHE算法在每次握手时都会生成一对临时的公钥和私钥，每次通信的密钥对都是不同的，也就是“一次一密”**，即使黑客花大力气解出了这一次的会话密钥，也只是这次通信被攻击，之前的历史消息不会受到影响，仍然是安全的。

**所以现在主流的服务器和浏览器在握手阶段都已经不再使用RSA，改用ECDHE，而TLS1.3在协议里明确废除RSA和DH则在标准层面保证了“前向安全”。**

#### 提升性能

HTTPS建立连接时除了要做TCP握手，还要做TLS握手，在1.2中会多花两个消息往返（2-RTT），可能导致几十毫秒甚至上百毫秒的延迟，在移动网络中延迟还会更严重。

**现在因为密码套件大幅度简化，也就没有必要再像以前那样走复杂的协商流程了。TLS1.3压缩了以前的“Hello”协商过程，删除了“Key Exchange”消息，把握手时间减少到了“1-RTT”，效率提高了一倍。**

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/acfd925cc40f4639bcd7f240b01ed8a2~tplv-k3u1fbpfcp-watermark.awebp" alt="img" style="zoom:67%;" />

其实具体的做法还是利用了扩展。**客户端在“Client Hello”消息里直接用“supported_groups”带上支持的曲线，比如P-256、x25519，用“key_share”带上曲线对应的客户端公钥参数，用“signature_algorithms”带上签名算法。**

**服务器收到后在这些扩展里选定一个曲线和参数，再用“key_share”扩展返回服务器这边的公钥参数，就实现了双方的密钥交换。**

#### 握手分析

TLS1.3握手的过程如下图：

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c783ccab9a644dea9498a2d77ffa3e79~tplv-k3u1fbpfcp-watermark.awebp" alt="img" style="zoom:67%;" />

在TCP建立连接之后，浏览器首先还是发一个“Client Hello”。

因为1.3的消息兼容1.2，所以开头的版本号、支持的密码套件和随机数（Client Random）结构都是一样的（不过这时的随机数是32个字节）。

```

Handshake Protocol: Client Hello
    Version: TLS 1.2 (0x0303)
    Random: cebeb6c05403654d66c2329…
    Cipher Suites (18 suites)
        Cipher Suite: TLS_AES_128_GCM_SHA256 (0x1301)
        Cipher Suite: TLS_CHACHA20_POLY1305_SHA256 (0x1303)
        Cipher Suite: TLS_AES_256_GCM_SHA384 (0x1302)
    Extension: supported_versions (len=9)
        Supported Version: TLS 1.3 (0x0304)
        Supported Version: TLS 1.2 (0x0303)
    Extension: supported_groups (len=14)
        Supported Groups (6 groups)
            Supported Group: x25519 (0x001d)
            Supported Group: secp256r1 (0x0017)
    Extension: key_share (len=107)
        Key Share extension
            Client Key Share Length: 105
            Key Share Entry: Group: x25519
            Key Share Entry: Group: secp256r1

```



注意“Client Hello”里的扩展，“supported_versions”表示这是TLS1.3，“supported_groups”是支持的曲线，“key_share”是曲线对应的参数。

服务器收到“Client Hello”同样返回“Server Hello”消息，还是要给出一个随机数（Server Random）和选定密码套件。

```

Handshake Protocol: Server Hello
    Version: TLS 1.2 (0x0303)
    Random: 12d2bce6568b063d3dee2…
    Cipher Suite: TLS_AES_128_GCM_SHA256 (0x1301)
    Extension: supported_versions (len=2)
        Supported Version: TLS 1.3 (0x0304)
    Extension: key_share (len=36)
        Key Share extension
            Key Share Entry: Group: x25519, Key Exchange length: 32

```



表面上看跟TLS1.2是一样的，**重点是后面的扩展**。“supported_versions”里确认使用的是TLS1.3，然后在“key_share”扩展带上曲线和对应的公钥参数。

**这时只交换了两条消息，客户端和服务器就拿到了四个共享信息：Client Random和Server Random、Client Params和Server Params，两边就可以各自用ECDHE算出“Pre-Master”，再用HKDF生成主密钥“Master Secret”，效率比TLS1.2提高了一大截。**

**在算出主密钥后，服务器立刻发出“Change Cipher Spec”消息，比TLS1.2提早进入加密通信，后面的证书等就都是加密的了，减少了握手时的明文信息泄露。**

这里**TLS1.3还有一个安全强化措施，多了个“Certificate Verify”消息，用服务器的私钥把前面的曲线、套件、参数等握手数据加了签名，作用和“Finished”消息差不多。但由于是私钥签名，所以强化了身份认证和防篡改**。

**这两个“Hello”消息之后，客户端验证服务器证书，再发“Finished”消息，就正式完成了握手，开始收发HTTP报文。**

#### 小结

今天我们一起学习了 TLS1.3 的新特性，用抓包研究了它的握手过程，不过 TLS1.3 里的内容很多，还有一些特性没有谈到，后面会继续讲。

为了兼容 1.1、1.2 等“老”协议，TLS1.3 会“伪装”成 TLS1.2，新特性在“扩展”里实现；

1.1、1.2 在实践中发现了很多安全隐患，所以 TLS1.3 大幅度删减了加密算法，只保留了 ECDHE、AES、ChaCha20、SHA-2 等极少数算法，强化了安全；

TLS1.3 也简化了握手过程，完全握手只需要一个消息往返，提升了性能。

Q：TLS1.3 里的密码套件没有指定密钥交换算法和签名算法，那么在握手的时候会不会有问题呢？

A：TLS1.3精简了加密算法，通过support_groups、key_share、signature_algorithms这些参数就能判断出密钥交换算法和签名算法，不用在cipher suite中协商了

Q：结合 RSA 握手过程，解释一下为什么 RSA 密钥交换不具有“前向安全”。

A：RSA握手时，client key exchage会使用RSA公钥加密pre master后传给服务端，一旦私钥被破解，那么之前的信息都会被破译，根本原因还是在于RSA的这一对公钥私钥并不是临时的。

Q：TLS1.3 的握手过程与 TLS1.2 的“False Start”有什么异同？

A：相同点：都在未收到Finished确认消息时就已经向对方发送加密信息了，不同点：TLS1.3将change cipher spec合并到了hello中





### 28 丨 连接太慢该怎么办：HTTPS的优化

HTTPS 连接大致上可以划分为两个部分，第一个是建立连接时的**非对称加密握手**，第二个是握手后的**对称加密报文传输**。

由于目前流行的 **AES、ChaCha20 性能都很好，还有硬件优化，报文传输的性能损耗可以说是非常地小，小到几乎可以忽略不计了**。所以，**通常所说的“HTTPS 连接慢”指的就是刚开始建立连接的那段时间**。

​    **在 TCP 建连之后，正式数据传输之前，HTTPS 比 HTTP 增加了一个 TLS 握手的步骤，这个步骤最长可以花费两个消息往返**，也就是 2-RTT。而且**在握手消息的网络耗时**之外，还会有其他的一些“隐形”消耗，比如：

产生用于**密钥交换的临时公私钥对**（ECDHE）；

**验证证书时访问 CA 获取 CRL 或者 OCSP；**

**非对称加密解密处理“Pre-Master”**。

在最差的情况下，也就是不做任何的优化措施，HTTPS 建立连接可能会比 HTTP 慢上几百毫秒甚至几秒，这其中既有网络耗时，也有计算耗时，就会让人产生“打开一个 HTTPS 网站好慢啊”的感觉。

​    不过刚才说的情况早就是“过去时”了，现在已经有了很多行之有效的 HTTPS 优化手段，运用得好可以把连接的额外耗时降低到几十毫秒甚至是“零”。

我画了一张图，把 TLS 握手过程中影响性能的部分都标记了出来，对照着它就可以“有的放矢”地来优化 HTTPS。

![img](https://img2020.cnblogs.com/blog/473210/202005/473210-20200506222815219-485612434.png)



#### 硬件优化

​    在计算机世界里的“优化”可以分成“硬件优化”和“软件优化”两种方式，先来看看有哪些硬件的手段。

​    硬件优化，说白了就是“花钱”。但花钱也是有门道的，要“有钱用在刀刃上”，不能大把的银子撒出去“只听见响”。

​    **HTTPS 连接是计算密集型，而不是 I/O 密集型**。所以，如果你花大价钱去买网卡、带宽、SSD 存储就是“南辕北辙”了，起不到优化的效果。

​    首先，你可以选择**更快的 CPU**，最好还内建 AES 优化，这样即可以加速握手，也可以加速传输。

​    其次，你可以选择“**SSL** **加速卡**”，加解密时调用它的 API，让专门的硬件来做非对称加解密，分担 CPU 的计算压力。

​    不过“SSL 加速卡”也有一些缺点，比如升级慢、支持算法有限，不能灵活定制解决方案等。

​    所以，就出现了第三种硬件加速方式：“**SSL** **加速服务器**”，用专门的服务器集群来彻底“卸载”TLS 握手时的加密解密计算，性能自然要比单纯的“加速卡”要强大的多。

#### 软件优化

​    不过硬件优化方式中除了 CPU，其他的通常可不是靠简单花钱就能买到的，还要有一些开发适配工作，有一定的实施难度。比如，“加速服务器”中关键的一点是通信必须是“异步”的，不能阻塞应用服务器，否则加速就没有意义了。

​    所以，软件优化的方式相对来说更可行一些，性价比高，能够“少花钱，多办事”。

软件方面的优化还可以再分成两部分：一个是**软件升级**，一个是**协议优化**。

​    软件升级实施起来比较简单，就是把现在正在使用的软件尽量升级到最新版本，比如把 Linux 内核由 2.x 升级到 4.x，把 Nginx 由 1.6 升级到 1.16，把 OpenSSL 由 1.0.1 升级到 1.1.0/1.1.1。

​    由于这些软件在更新版本的时候都会做性能优化、修复错误，只要运维能够主动配合，这种软件优化是最容易做的，也是最容易达成优化效果的。

​    但对于很多大中型公司来说，硬件升级或软件升级都是个棘手的问题，有成千上万台各种型号的机器遍布各个机房，逐一升级不仅需要大量人手，而且有较高的风险，可能会影响正常的线上服务。

​    所以，在软硬件升级都不可行的情况下，我们最常用的优化方式就是在现有的环境下挖掘协议自身的潜力。

#### 协议优化

​    从刚才的 TLS 握手图中你可以看到影响性能的一些环节，协议优化就要从这些方面着手，先来看看核心的密钥交换过程。

​    **如果有可能，应当尽量采用 TLS1.3，它大幅度简化了握手的过程，完全握手只要 1-RTT，而且更加安全。**

​    如果暂时不能升级到 1.3，只能用 1.2，那么握手时使用的密钥交换协议**应当尽量选用椭圆曲线的 ECDHE 算法**。它**不仅运算速度快，安全性高，还支持“False Start”**，能够把握手的消息往返由 2-RTT 减少到 1-RTT，达到与 TLS1.3 类似的效果。

​    另外，**椭圆曲线也要选择高性能的曲线，最好是 x25519**，次优选择是 P-256。对称加密算法方面，也可以选用“AES_128_GCM”，它能比“AES_256_GCM”略快一点点。

在 Nginx 里可以用“ssl_ciphers”“ssl_ecdh_curve”等指令配置服务器使用的密码套件和椭圆曲线，把优先使用的放在前面。

#### 证书优化

​    除了密钥交换，握手过程中的证书验证也是一个比较耗时的操作，服务器需要把自己的证书链全发给客户端，然后客户端接收后再逐一验证。

​    这里就有两个优化点，一个是**证书传输**，一个是**证书验证**。

​    **服务器的证书可以选择椭圆曲线（ECDSA）证书而不是 RSA 证书**，因为 224 位的 ECC 相当于 2048 位的 RSA，所以椭圆曲线证书的“个头”要比 RSA 小很多，即能够节约带宽也能减少客户端的运算量，可谓“一举两得”。

​    客户端的证书验证其实是个很复杂的操作，除了要公钥解密验证多个证书签名外，因为证书还有可能会被撤销失效，客户端有时还会再去访问 CA，下载 CRL 或者 OCSP 数据，这又会产生 DNS 查询、建立连接、收发数据等一系列网络通信，增加好几个 RTT。

**CRL（Certificate revocation list，证书吊销列表）由 CA 定期发布，里面是所有被撤销信任的证书序号，查询这个列表就可以知道证书是否有效。**

​    但 CRL 因为是“定期”发布，就有“时间窗口”的安全隐患，而且随着吊销证书的增多，列表会越来越大，一个 CRL 经常会上 MB。想象一下，每次需要预先下载几 M 的“无用数据”才能连接网站，实用性实在是太低了。

​    所以，**现在 CRL 基本上不用了，取而代之的是 OCSP（在线证书状态协议，Online Certificate Status Protocol），向 CA 发送查询请求，让 CA 返回证书的有效状态。**

但 OCSP 也要多出一次网络请求的消耗，而且还依赖于 CA 服务器，如果 CA 服务器很忙，那响应延迟也是等不起的。

​    于是**又出来了一个“补丁”，叫“OCSP Stapling”（OCSP 装订），它可以让服务器预先访问 CA 获取 OCSP 响应，然后在握手时随着证书一起发给客户端，免去了客户端连接 CA 服务器查询的时间。**

#### 会话复用

​    到这里，我们已经讨论了四种 HTTPS 优化手段（硬件优化、软件优化、协议优化、证书优化），那么，还有没有其他更好的方式呢？

​    我们再回想一下 HTTPS 建立连接的过程：**先是 TCP 三次握手，然后是 TLS 一次握手。这后一次握手的重点是算出主密钥“Master Secret**”，而主密钥每次连接都要重新计算，未免有点太浪费了，如果能够把“辛辛苦苦”算出来的主密钥缓存一下“重用”，不就可以免去了握手和计算的成本了吗？

​    这种做法就叫“**会话复用**”（TLS session resumption），和 HTTP Cache 一样，也是提高 HTTPS 性能的“大杀器”，被浏览器和服务器广泛应用。

​    会话复用分两种，第一种叫“**Session ID**”，就是**客户端和服务器首次连接后各自保存一个会话的 ID 号，内存里存储主密钥和其他相关的信息。当客户端再次连接时发一个 ID 过来，服务器就在内存里找，找到就直接用主密钥恢复会话状态，跳过证书验证和密钥交换，只用一个消息往返就可以建立安全通信。**

<img src="https://img2020.cnblogs.com/blog/473210/202005/473210-20200506222915202-1308186510.png" alt="img" style="zoom:67%;" />



#### 会话票证

​    “Session ID”是最早出现的会话复用技术，也是应用最广的，但它也有缺点，服务器必须保存每一个客户端的会话数据，对于拥有百万、千万级别用户的网站来说存储量就成了大问题，加重了服务器的负担。

​    于是，又出现了第二种“**Session Ticket**”方案。

​    **它有点类似 HTTP 的 Cookie，存储的责任由服务器转移到了客户端，服务器加密会话信息，用“New Session Ticket”消息发给客户端，让客户端保存。**

重连的时候，客户端使用扩展“**session_ticket**”发送“Ticket”而不是“Session ID”，服务器解密后验证有效期，就可以恢复会话，开始加密通信。

​    这个过程也可以在实验环境里测试，端口号是 442，URI 是“https://www.chrono.com:442/28-1”。

​    **不过“Session Ticket”方案需要使用一个固定的密钥文件（ticket_key）来加密 Ticket，为了防止密钥被破解，保证“前向安全”，密钥文件需要定期轮换，比如设置为一小时或者一天。**

#### 预共享密钥

​    “False Start”“Session ID”“Session Ticket”等方式只能实现 1-RTT，而 TLS1.3 更进一步实现了“**0-RTT**”，原理和“Session Ticket”差不多，但在发送 Ticket 的同时会带上应用数据（Early Data），免去了 1.2 里的服务器确认步骤，这种方式叫“**Pre-shared Key**”，简称为“PSK”。

![img](https://img2020.cnblogs.com/blog/473210/202005/473210-20200506222958357-394714070.png)



 但“PSK”也不是完美的，它为了追求效率而牺牲了一点安全性，容易受到“重放攻击”（Replay attack）的威胁。黑客可以截获“PSK”的数据，像复读机那样反复向服务器发送。

解决的办法是只允许安全的 GET/HEAD 方法（参见[第 10 讲](https://time.geekbang.org/column/article/101518)），在消息里加入时间戳、“nonce”验证，或者“一次性票证”限制重放。

小结

可以有多种硬件和软件手段减少网络耗时和计算耗时，让 HTTPS 变得和 HTTP 一样快，**最可行的是软件优化**；

**应当尽量使用 ECDHE 椭圆曲线密码套件**，节约带宽和计算量，还能实现“False Start”；

**服务器端应当开启“OCSP Stapling”功能，避免客户端访问 CA 去验证证书；**

**会话复用的效果类似 Cache，前提是客户端必须之前成功建立连接，后面就可以用“Session ID”“Session Ticket”等凭据跳过密钥交换、证书验证等步骤，直接开始加密通信。**



Q：你能比较一下“Session ID”“Session Ticket”“PSK”这三种会话复用手段的异同吗？

A：相同点：都是会话复用技术；区别： Seesion ID：会话数据缓存在服务端，如果服务器客户量大，对服务器会造成很大压力 Seeion Ticket：会话数据缓存在客户端 PAK：在Seesion Ticket的基础上，应用数据和Session Ticket一起发送给服务器，省去了中间服务器与客户端的确认步骤




### 29 丨 我应该迁移到HTTPS吗？

#### 迁移的顾虑

​    据我观察，阻碍 HTTPS 实施的因素还有一些这样、那样的顾虑，我总结出了三个比较流行的观点：“慢、贵、难”。

​    所谓“慢”，是指惯性思维，拿以前的数据来评估 HTTPS 的性能，认为 HTTPS 会增加服务器的成本，增加客户端的时延，影响用户体验。

​    其实现在服务器和客户端的运算能力都已经有了很大的提升，性能方面完全没有担心的必要，而且还可以应用很多的优化解决方案（参见[第 28 讲](https://time.geekbang.org/column/article/111287)）。根据 Google 等公司的评估，**在经过适当优化之后，HTTPS 的额外 CPU 成本小于 1%，额外的网络成本小于 2%，可以说是与无加密的 HTTP 相差无几。**

​    所谓“贵”，主要是指证书申请和维护的成本太高，网站难以承担。

​    这也属于惯性思维，在早几年的确是个问题，向 CA 申请证书的过程不仅麻烦，而且价格昂贵，每年要交几千甚至几万元。

​    但现在就不一样了，为了推广 HTTPS，很多云服务厂商都提供了一键申请、价格低廉的证书，而且还出现了专门颁发免费证书的 CA，其中最著名的就是“**Let****’s Encrypt**”。

​    **所谓的“难”，是指 HTTPS 涉及的知识点太多、太复杂，有一定的技术门槛，不能很快上手。**

​    这第三个顾虑比较现实，HTTPS 背后关联到了密码学、TLS、PKI 等许多领域，不是短短几周、几个月就能够精通的。但实施 HTTPS 也并不需要把这些完全掌握，只要抓住少数几个要点就好，下面我就来帮你逐个解决一些关键的“难点”。

#### 申请证书

​    要把网站从 HTTP 切换到 HTTPS，首先要做的就是为网站申请一张证书。

​    大型网站出于信誉、公司形象的考虑，通常会选择向传统的 CA 申请证书，例如 DigiCert、GlobalSign，而中小型网站完全可以选择使用“Let’s Encrypt”这样的免费证书，效果也完全不输于那些收费的证书。

不过我必须提醒你几个注意事项。

​    第一，**申请证书时应当同时申请 RSA 和 ECDSA 两种证书，在 Nginx 里配置成双证书验证，这样服务器可以自动选择快速的椭圆曲线证书，同时也兼容只支持 RSA 的客户端。**

​    第二，如果申请 RSA 证书，私钥至少要 2048 位，摘要算法应该选用 SHA-2，例如 SHA256、SHA384 等。

​    第三，出于安全的考虑，“Let’s Encrypt”证书的有效期很短，只有 90 天，时间一到就会过期失效，所以必须要定期更新。你可以在 crontab 里加个每周或每月任务，发送更新请求，不过很多 ACME 客户端会自动添加这样的定期任务，完全不用你操心。

 搞定了证书，接下来就是配置 Web 服务器，在 443 端口上开启 HTTPS 服务了。

这在 Nginx 上非常简单，只要在“listen”指令后面加上参数“ssl”，再配上刚才的证书文件就可以实现最基本的 HTTPS。

|      | listen        443 ssl;                                 |
| ---- | ------------------------------------------------------ |
|      |                                                        |
|      | ssl_certificate    xxx_rsa.crt; #rsa2048 cert          |
|      | ssl_certificate_key  xxx_rsa.key; #rsa2048 private key |
|      |                                                        |
|      | ssl_certificate    xxx_ecc.crt; #ecdsa cert            |
|      | ssl_certificate_key  xxx_ecc.key; #ecdsa private ke    |

为了提高 HTTPS 的安全系数和性能，你还可以强制 Nginx 只支持 TLS1.2 以上的协议，打开“Session Ticket”会话复用：

|      | ssl_protocols        TLSv1.2 TLSv1.3; |
| ---- | ------------------------------------- |
|      |                                       |
|      | ssl_session_timeout     5m;           |
|      | ssl_session_tickets     on;           |
|      | ssl_session_ticket_key   ticket.key;  |

 密码套件的选择方面，我给你的建议是以服务器的套件优先。这样可以避免恶意客户端故意选择较弱的套件、降低安全等级，然后密码套件向 TLS1.3“看齐”，只使用 ECDHE、AES 和 ChaCha20，支持“False Start”。

|      | ssl_prefer_server_ciphers  on;                               |
| ---- | ------------------------------------------------------------ |
|      |                                                              |
|      |                                                              |
|      | ssl_ciphers  ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-CHACHA20-POLY1305:ECDHE+AES128:!MD5:!SHA1; |

如果你的服务器上使用了 OpenSSL 的分支 BorringSSL，那么还可以使用一个特殊的“等价密码组”（Equal preference cipher groups）特性，它可以让服务器配置一组“等价”的密码套件，在这些套件里允许客户端优先选择，比如这么配置：

|      | ssl_ciphers                                                  |
| ---- | ------------------------------------------------------------ |
|      | [ECDHE-ECDSA-AES128-GCM-SHA256\|ECDHE-ECDSA-CHACHA20-POLY1305]; |

#### 服务器名称指示

​    配置 HTTPS 服务时还有一个“虚拟主机”的问题需要解决。

在 HTTP 协议里，多个域名可以同时在一个 IP 地址上运行，这就是“虚拟主机”，Web 服务器会使用请求头里的 Host 字段（参见[第 9 讲](https://time.geekbang.org/column/article/100513)）来选择。

​    但**在 HTTPS 里，因为请求头只有在 TLS 握手之后才能发送，在握手时就必须选择“虚拟主机”对应的证书，TLS 无法得知域名的信息，就只能用 IP 地址来区分。所以，最早的时候每个 HTTPS 域名必须使用独立的 IP 地址，非常不方便。**

那么怎么解决这个问题呢？

   这还是得用到 TLS 的“扩展”，给协议加个**SNI**（Server Name Indication）的“补充条款”。它的作用和 Host 字段差不多，客户端会在“Client Hello”时带上域名信息，这样服务器就可以根据名字而不是 IP 地址来选择证书。

|      | Extension: server_name (len=19)  |
| ---- | -------------------------------- |
|      | Server Name Indication extension |
|      | Server Name Type: host_name (0)  |
|      | Server Name: www.chrono.com      |

Nginx 很早就基于 SNI 特性支持了 HTTPS 的虚拟主机，但在 OpenResty 里可还以编写 Lua 脚本，利用 Redis、MySQL 等数据库更灵活快速地加载证书。

#### 重定向跳转

​    现在有了 HTTPS 服务，但原来的 HTTP 站点也不能马上弃用，还是会有很多网民习惯在地址栏里直接敲域名（或者是旧的书签、超链接），默认使用 HTTP 协议访问。

​    所以，我们就需要用到第 18 讲里的“重定向跳转”技术了，把不安全的 HTTP 网址用 301 或 302“重定向”到新的 HTTPS 网站，这在 Nginx 里也很容易做到，使用“return”或“rewrite”都可以。

|      | return 301 https://$host$request_uri;       # 永久重定向     |
| ---- | ------------------------------------------------------------ |
|      | rewrite ^ https://$host$request_uri permanent;  # 永久重定向 |

​    但这种方式有两个问题。一个是重定向增加了网络成本，多出了一次请求；另一个是存在安全隐患，重定向的响应可能会被“中间人”窜改，实现“会话劫持”，跳转到恶意网站。

不过有一种叫“**HSTS**”（HTTP 严格传输安全，HTTP Strict Transport Security）的技术可以  消除这种安全隐患。HTTPS 服务器需要在发出的响应头里添加一个“**Strict-Transport-Security**”的字段，再设定一个有效期，例如：

|      | Strict-Transport-Security: max-age=15768000; includeSubDomains |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

​    这相当于告诉浏览器：我这个网站必须严格使用 HTTPS 协议，在半年之内（182.5 天）都不允许用 HTTP，你以后就自己做转换吧，不要再来麻烦我了。

​    **有了“HSTS”的指示，以后浏览器再访问同样的域名的时候就会自动把 URI 里的“http”改成“https”，直接访问安全的 HTTPS 网站。这样“中间人”就失去了攻击的机会，而且对于客户端来说也免去了一次跳转，加快了连接速度。**

​    比如，如果在实验环境的配置文件里用“add_header”指令添加“HSTS”字段：

|      | add_header Strict-Transport-Security max-age=15768000; #182.5days |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

那么 Chrome 浏览器只会在第一次连接时使用 HTTP 协议，之后就会都走 HTTPS 协议。





## 六飞翔篇（4讲）

### 30 丨 2特性概览

Google 率先发明了 SPDY 协议，并应用于自家的浏览器 Chrome，打响了 HTTP 性能优化的“第一枪”。

随后互联网标准化组织 IETF 以 SPDY 为基础，综合其他多方的意见，终于推出了 HTTP/1 的继任者，也就是今天的主角“HTTP/2”，在性能方面有了一个大的飞跃。

#### 为什么不是 HTTP/2.0

互联网标准化组织 IETF 决定 HTTP 协议不再使用小版本号（minor version），只使用大版本号（major version），从今往后 HTTP 协议不会出现 HTTP/2.0、2.1，只会有“HTTP/2”“HTTP/3”

#### 兼容 HTTP/1

​    由于 HTTPS 已经在安全方面做的非常好了，所以 HTTP/2 的唯一目标就是改进性能。

​    但它不仅背负着众多的期待，同时还背负着 HTTP/1 庞大的历史包袱，所以协议的修改必须小心谨慎，兼容性是首要考虑的目标，否则就会破坏互联网上无数现有的资产，这方面 TLS 已经有了先例（为了兼容 TLS1.2 不得不进行“伪装”）。

那么，HTTP/2 是怎么做的呢？

​    因为必须要保持功能上的兼容，所以 **HTTP/2 把 HTTP 分解成了“语义”和“语法”两个部分，“语义”层不做改动，与 HTTP/1 完全一致（即 RFC7231）。比如请求方法、URI、状态码、头字段等概念都保留不变**，这样就消除了再学习的成本，基于 HTTP 的上层应用也不需要做任何修改，可以无缝转换到 HTTP/2。

​    特别要说的是，与 HTTPS 不同，HTTP/2 没有在 URI 里引入新的协议名，仍然用“http”表示明文协议，用“https”表示加密协议。

 在“语义”保持稳定之后，**HTTP/2 在“语法”层做了“天翻地覆”的改造，完全变更了 HTTP 报文的传输格式**。

#### 头部压缩

​    首先，HTTP/2 对报文的头部做了一个“大手术”。

HTTP/1 里可以用头字段“Content-Encoding”指定 Body 的编码方式，比如用 gzip 压缩来节约带宽，但报文的另一个组成部分——Header 却被无视了，没有针对它的优化手段。

​    由于报文 Header 一般会携带“User Agent”“Cookie”“Accept”“Server”等许多固定的头字段，多达几百字节甚至上千字节，但 Body 却经常只有几十字节（比如 GET 请求、204/301/304 响应），成了不折不扣的“大头儿子”。更要命的是，成千上万的请求响应报文里有很多字段值都是重复的，非常浪费，“长尾效应”导致大量带宽消耗在了这些冗余度极高的数据上。

​    所以，HTTP/2 把“**头部压缩**”作为性能改进的一个重点，优化的方式你也肯定能想到，还是“压缩”。

   不过 HTTP/2 并没有使用传统的压缩算法，而是开发了专门的“**HPACK**”算法，**在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还釆用哈夫曼编码来压缩整数和字符串，可以达到 50%~90% 的高压缩率。**

#### 二进制格式

你可能已经很习惯于 HTTP/1 里纯文本形式的报文了，它的优点是“一目了然”，用最简单的工具就可以开发调试，非常方便。

​    但 HTTP/2 在这方面没有“妥协”，决定改变延续了十多年的现状，不再使用肉眼可见的 ASCII 码，而是向下层的 TCP/IP 协议“靠拢”，全面采用二进制格式。

**这样虽然对人不友好，但却大大方便了计算机的解析**。原来使用纯文本的时候容易出现多义性，比如大小写、空白字符、回车换行、多字少字等等，程序在处理时必须用复杂的状态机，效率低，还麻烦。

​    而二进制里只有“0”和“1”，可以严格规定字段大小、顺序、标志位等格式，“对就是对，错就是错”，解析起来没有歧义，实现简单，而且体积小、速度快，做到“内部提效”。

以二进制格式为基础，HTTP/2 就开始了“大刀阔斧”的改革。

​    **它把 TCP 协议的部分特性挪到了应用层，把原来的“Header+Body”的消息“打散”为数个小片的二进制“帧”（Frame），用“HEADERS”帧存放头数据、“DATA”帧存放实体数据。**

这种做法有点像是“Chunked”分块编码的方式（参见[第 16 讲](https://time.geekbang.org/column/article/104456)），也是“化整为零”的思路，   但 HTTP/2 数据分帧后“Header+Body”的报文结构就完全消失了，**协议看到的只是一个个的“碎片”**。

![img](https://img2020.cnblogs.com/blog/473210/202005/473210-20200507215609693-1329635124.png)



#### 虚拟的“流”

消息的“碎片”到达目的地后应该怎么组装起来呢？

​    HTTP/2 为此定义了一个“**流**”（Stream）的概念，**它是二进制帧的双向传输序列**，同一个消息往返的帧会分配一个唯一的流 ID。你可以想象把它成是一个虚拟的“数据流”，**在里面流动的是一串有先后顺序的数据帧，这些数据帧按照次序组装起来就是 HTTP/1 里的请求报文和响应报文。**

​    因为“流”是虚拟的，实际上并不存在，所以 HTTP/2 就可以在一个 TCP 连接上用“**流**”同时发送多个“碎片化”的消息，这就是常说的“**多路复用**”（ Multiplexing）——**多个往返通信都复用一个连接来处理**。

​    **在“流”的层面上看，消息是一些有序的“帧”序列，而在“连接”的层面上看，消息却是乱序收发的“帧”。多个请求 / 响应之间没有了顺序关系，不需要排队等待，也就不会再出现“队头阻塞”问题，降低了延迟，大幅度提高了连接的利用率。**

为了更好地利用连接，加大吞吐量，HTTP/2 还添加了一些控制帧来管理虚拟的“流”，实现了优先级和流量控制，这些特性也和 TCP 协议非常相似。

​    HTTP/2 还在一定程度上改变了传统的“请求 - 应答”工作模式，**服务器不再是完全被动地响应请求，也可以新建“流”主动向客户端发送消息。**比如，在浏览器刚请求 HTML 的时候就提前把可能会用到的 JS、CSS 文件发给客户端，减少等待的延迟，这被称为“**服务器推送**”（Server Push，也叫 Cache Push）。

#### 强化安全

HTTP/2 是建立在“HPack”“Stream”“TLS1.2”基础之上的，比 HTTP/1、HTTPS 复杂了一些。

![img](https://img2020.cnblogs.com/blog/473210/202005/473210-20200507215646913-409821179.png)



端口使用的是“8443”而不是“443”。这是因为 443 端口已经被“www.chrono.com”的 HTTPS 协议占用，Nginx 不允许在同一个端口上根据域名选择性开启 HTTP/2，所以就不得不改用了“8443”。





### 37丨CDN：加速我们的网络服务

在应用领域，还缺一个在外部加速 HTTP 协议的服务，这个就是我们今天要说的 CDN（Content Delivery Network 或 Content Distribution Network），中文名叫“**内容分发网络**”。

#### 什么是 CDN？

​    这个时候 CDN 就出现了，它就是**专门为解决“长距离”上网络访问速度慢而诞生的一种网络应用服务**。

​    从名字上看，CDN 有三个关键词：“**内容**”“**分发**”和“**网络**”。

​    先看一下“网络”的含义。CDN 的最核心原则是“**就近访问**”，如果用户能够在本地几十公里的距离之内获取到数据，那么时延就基本上变成 0 了。

​    所以 CDN 投入了大笔资金，在全国、乃至全球的各个大枢纽城市都建立了机房，部署了大量拥有高存储高带宽的节点，构建了一个专用网络。这个网络是跨运营商、跨地域的，虽然内部也划分成多个小网络，但它们之间用高速专有线路连接，是真正的“信息高速公路”，基本上可以认为不存在网络拥堵。

​    有了这个高速的专用网之后，CDN 就要“分发”源站的“内容”了，用到的就是在[第 22 讲](https://time.geekbang.org/column/article/108313)说过的“**缓存代理**”技术。使用“推”或者“拉”的手段，把源站的内容逐级缓存到网络的每一个节点上。

​    于是，用户在上网的时候就不直接访问源站，而是访问离他“最近的”一个 CDN 节点，术语叫“**边缘节点**”（edge node），其实就是缓存了源站内容的代理服务器，这样一来就省去了“长途跋涉”的时间成本，实现了“网络加速”。

资源按照是否可缓存又分为“**静态资源**”和“**动态资源**”。所谓的“静态资源”是指数据内容“静态不变”，任何时候来访问都是一样的，比如图片、音频。所谓的“动态资源”是指数据内容是“动态变化”的，也就是由后台服务计算生成的，每次访问都不一样，比如商品的库存、微博的粉丝数等。

​    很显然，只有静态资源才能够被缓存加速、就近访问，而动态资源只能由源站实时生成，即使缓存了也没有意义。不过，如果动态资源指定了“Cache-Control”，允许缓存短暂的时间，那它在这段时间里也就变成了“静态资源”，可以被 CDN 缓存加速。

套用一句广告词来形容 CDN 吧，我觉得非常恰当：“**我们不生产内容，我们只是内容的搬运工。**”

#### CDN 的负载均衡

​    我们再来看看 CDN 是具体怎么运行的，它有两个关键组成部分：**全局负载均衡**和**缓存系统**，对应的是 DNS（[第 6 讲](https://time.geekbang.org/column/article/99665)）和缓存代理（[第 21 讲](https://time.geekbang.org/column/article/107577)、[第 22 讲](https://time.geekbang.org/column/article/108313)）技术。

全局负载均衡（Global Sever Load Balance）一般简称为 GSLB，它是 CDN 的“大脑”，主要的职责是当用户接入网络的时候在 CDN 专网中挑选出一个“最佳”节点提供服务，解决的是用户如何找到“最近的”边缘节点，对整个 CDN 网络进行“负载均衡”。

缓存系统是 CDN 的另一个关键组成部分，相当于 CDN 的“心脏”。如果缓存系统的服务能力不够，不能很好地满足用户的需求，那 GSLB 调度算法再优秀也没有用。

两个 CDN 的关键概念：“**命中**”和“**回源**”。

   “命中”就是指用户访问的资源恰好在缓存系统里，可以直接返回给用户；“回源”则正相反，缓存里没有，必须用代理的方式回源站取。

​    相应地，也就有了两个衡量 CDN 服务质量的指标：“**命中率**”和“**回源率**”。命中率就是命中次数与所有访问次数之比，回源率是回源次数与所有访问次数之比。显然，好的 CDN 应该是命中率越高越好，回源率越低越好。现在的商业 CDN 命中率都在 90% 以上，相当于把源站的服务能力放大了 10 倍以上。

#### 小结

CDN 构建了全国、全球级别的专网，让用户就近访问专网里的边缘节点，降低了传输延迟，实现了网站加速；

GSLB 是 CDN 的“大脑”，使用 DNS 负载均衡技术，智能调度边缘节点提供服务；

缓存系统是 CDN 的“心脏”，使用 HTTP 缓存代理技术，缓存命中就返回给用户，否则就要回源。





### 38丨WebSocket：沙盒里的TCP

准确地说，“WebSocket”是一种基于 TCP 的轻量级网络通信协议，在地位上是与 HTTP“平级”的。

#### 为什么要有 WebSocket

​    不过，已经有了被广泛应用的 HTTP 协议，为什么要再出一个 WebSocket 呢？它有哪些好处呢？

​    其实 WebSocket 与 HTTP/2 一样，都是为了解决 HTTP 某方面的缺陷而诞生的。HTTP/2 针对的是“队头阻塞”，而 WebSocket 针对的是“请求 - 应答”通信模式。

​    那么，“请求 - 应答”有什么不好的地方呢？

​    “请求 - 应答”是一种“**半双工**”的通信模式，虽然可以双向收发数据，但同一时刻只能一个方向上有动作，传输效率低。更关键的一点，它是一种“被动”通信模式，服务器只能“被动”响应客户端的请求，无法主动向客户端发送数据。

​    虽然后来的 HTTP/2、HTTP/3 新增了 Stream、Server Push 等特性，但“请求 - 应答”依然是主要的工作方式。这就导致 HTTP 难以应用在动态页面、即时消息、网络游戏等要求“**实时通信**”的领域。

​    在 WebSocket 出现之前，在浏览器环境里用 JavaScript 开发实时 Web 应用很麻烦。因为浏览器是一个“受限的沙盒”，不能用 TCP，只有 HTTP 协议可用，所以就出现了很多“变通”的技术，“**轮询**”（polling）就是比较常用的的一种。

​    简单地说，轮询就是不停地向服务器发送 HTTP 请求，问有没有数据，有数据的话服务器就用响应报文回应。如果轮询的频率比较高，那么就可以近似地实现“实时通信”的效果。

 但轮询的缺点也很明显，反复发送无效查询请求耗费了大量的带宽和 CPU 资源，非常不经济。

#### WebSocket 的特点

​    WebSocket 是一个真正“**全双工**”的通信协议，与 TCP 一样，客户端和服务器都可以随时向对方发送数据，而不用像 HTTP“你拍一，我拍一”那么“客套”。于是，服务器就可以变得更加“主动”了。一旦后台有新的数据，就可以立即“推送”给客户端，不需要客户端轮询，“实时通信”的效率也就提高了。

​    **WebSocket 采用了二进制帧结构，语法、语义与 HTTP 完全不兼容，但因为它的主要运行环境是浏览器，为了便于推广和应用，就不得不“搭便车”，在使用习惯上尽量向 HTTP 靠拢，这就是它名字里“Web”的含义。**

​    服务发现方面，WebSocket 没有使用 TCP 的“IP 地址 + 端口号”，而是延用了 HTTP 的 URI 格式，但开头的协议名不是“http”，引入的是两个新的名字：“**ws**”和“**wss**”，分别表示明文和加密的 WebSocket 协议。

​    WebSocket 的默认端口也选择了 80 和 443，因为现在互联网上的防火墙屏蔽了绝大多数的端口，只对 HTTP 的 80、443 端口“放行”，所以 WebSocket 就可以“伪装”成 HTTP 协议，比较容易地“穿透”防火墙，与服务器建立连接。

![img](https://img2020.cnblogs.com/blog/473210/202005/473210-20200524222600341-694359041.png)

 第一个字节的第一位“**FIN**”是消息结束的标志位，相当于 HTTP/2 里的“END_STREAM”，表示数据发送完毕。一个消息可以拆成多个帧，接收方看到“FIN”后，就可以把前面的帧拼起来，组成完整的消息。

​    “FIN”后面的三个位是保留位，目前没有任何意义，但必须是 0。

​    第一个字节的后 4 位很重要，叫**“Opcode**”，操作码，其实就是帧类型，比如 1 表示帧内容是纯文本，2 表示帧内容是二进制数据，8 是关闭连接，9 和 10 分别是连接保活的 PING 和 PONG。

​    第二个字节第一位是掩码标志位“**MASK**”，表示帧内容是否使用异或操作（xor）做简单的加密。目前的 WebSocket 标准规定，客户端发送数据必须使用掩码，而服务器发送则必须不使用掩码。

​    第二个字节后 7 位是“**Payload len**”，表示帧内容的长度。它是另一种变长编码，最少 7 位，最多是 7+64 位，也就是额外增加 8 个字节，所以一个 WebSocket 帧最大是 2^64。

​    长度字段后面是“**Masking-key**”，掩码密钥，它是由上面的标志位“MASK”决定的，如果使用掩码就是 4 个字节的随机数，否则就不存在。

其实 WebSocket 的帧头就四个部分：“**结束标志位 + 操作码 + 帧长度 + 掩码**”，只是使用了变长编码的“小花招”，不像 HTTP/2 定长报文头那么简单明了。

 而报文内容经过掩码，不是直接可见的明文，但掩码的安全强度几乎是零，用“Masking-key”简单地异或一下就可以转换出明文。

#### WebSocket 的握手

​    和 TCP、TLS 一样，WebSocket 也要有一个握手过程，然后才能正式收发数据。

这里它还是搭上了 HTTP 的“便车”，利用了 HTTP 本身的“协议升级”特性，“伪装”成 HTTP，这样就能绕过浏览器沙盒、网络防火墙等等限制，这也是 WebSocket 与 HTTP 的另一个重要关联点。

​    WebSocket 的握手是一个标准的 HTTP GET 请求，但要带上两个协议升级的专用头字段：

**“Connection: Upgrade”，表示要求协议“升级”；**

**“Upgrade: websocket”，表示要“升级”成 WebSocket 协议。**

​    另外，为了防止普通的 HTTP 消息被“意外”识别成 WebSocket，握手消息还增加了两个额外的认证用头字段（所谓的“挑战”，Challenge）：

**Sec-WebSocket-Key：一个 Base64 编码的 16 字节随机数，作为简单的认证密钥；**

**Sec-WebSocket-Version：协议的版本号，当前必须是 13。**

 服务器收到 HTTP 请求报文，看到上面的四个字段，就知道这不是一个普通的 GET 请求，而是 WebSocket 的升级请求，于是就不走普通的 HTTP 处理流程，而是**构造一个特殊的“101 Switching Protocols”响应报文，通知客户端**，接下来就不用 HTTP 了，全改用 WebSocket 协议通信。（有点像 TLS 的“Change Cipher Spec”）

​    WebSocket 的握手响应报文也是有特殊格式的，要用字段“Sec-WebSocket-Accept”验证客户端请求报文，同样也是为了防止误连接。

​    具体的做法是把请求头里“Sec-WebSocket-Key”的值，加上一个专用的 UUID “258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，再计算 SHA-1 摘要。

 客户端收到响应报文，就可以用同样的算法，比对值是否相等，如果相等，就说明返回的报文确实是刚才握手时连接的服务器，认证成功。

#### 小结

​    浏览器是一个“沙盒”环境，有很多的限制，不允许建立 TCP 连接收发数据，而有了 WebSocket，我们就可以在浏览器里与服务器直接建立“TCP 连接”，获得更多的自由。

不过自由也是有代价的，WebSocket 虽然是在应用层，但使用方式却与“TCP Socket”差不多，过于“原始”，用户必须自己管理连接、缓存、状态，开发上比 HTTP 复杂的多，所以是否要在项目中引入 WebSocket 必须慎重考虑。

HTTP 的“请求 - 应答”模式不适合开发“实时通信”应用，效率低，难以实现动态页面，所以出现了 WebSocket；

WebSocket 是一个“全双工”的通信协议，相当于对 TCP 做了一层“薄薄的包装”，让它运行在浏览器环境里；

WebSocket 使用兼容 HTTP 的 URI 来发现服务，但定义了新的协议名“ws”和“wss”，端口号也沿用了 80 和 443；

WebSocket 使用二进制帧，结构比较简单，特殊的地方是有个“掩码”操作，客户端发数据必须掩码，服务器则不用；

WebSocket 利用 HTTP 协议实现连接握手，发送 GET 请求要求“协议升级”，握手过程中有个非常简单的认证机制，目的是防止误连接。